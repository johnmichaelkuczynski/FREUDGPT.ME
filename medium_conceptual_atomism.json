[
  {
    "id": "CATOM-001",
    "text": "A doctrine known as “content-externalism” is widely taken to provide a correct analysis of mental content. A doctrine known as the Computational Theory of Mind (CTM) is widely taken to provide a correct analysis of mental operations. These doctrines support each other. The present work is divided into two parts. In Part I (Chapters 1-12) it is argued that content externalism is false, but that a related doctrine known as “semantic externalism” is correct. An alternative to content-externalism is proposed. In Part II (Chapters 13-25) xxx it is argued that CTM is false. Special attention is paid to the concept of syntactic form. It is seen that CTM involves a misunderstanding of this concept, and that this misunderstanding is embedded in misunderstandings that are reinforced by content-externalism.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-002",
    "text": "Let W and W* be two different possible worlds satisfying the following conditions. In W, Max sees rock R at time t. In W*, Twin-Max sees rock R* at the same time. R is numerically distinct from R*. But apart from that, there are no differences between W and W*. (It follows that Max and Twin-Max are numerically identical.) So even though R and R* are numerically distinct, they nonetheless look the same, and have the same mass, shape, and so on. And even though Max is looking at one rock, whereas Twin-Max is looking at some other rock, the physiological disturbances that result in the one case are qualitatively identical with those that result in the other. Of course, Max and Twin-Max do not have exactly the same relational properties. For example, Max’s visual experience at time t is caused by R, not R*, and Twin-Max’s corresponding experience is caused by R*, not R. Nonetheless, Max and Twin are obviously extremely similar. So long as we consider the regions of space-time occupied by their bodies, there is nothing that distinguishes Max from Twin-Max. If there is an electron-jump in the region occupied by Max, there is a qualitatively identical electron-jump in the region occupied by Twin-Max. According to a widely held doctrine, Max’s perceptions and subsequent thoughts don’t have the same contents as Twin-Max’s corresponding perceptions and thoughts. Here is the reasoning behind this claim:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-003",
    "text": "Max’s visual perception is veridical exactly if R has certain properties, it being irrelevant whether R* has those properties. And Twin-Max’s visual perception is veridical exactly if R* has certain properties, it being irrelevant whether R has those properties. Similarly when Max thinks that rock is lovely, his thought is correct exactly if R is lovely, it being irrelevant whether R* is lovely. And when Twin-Max thinks that rock is lovely, his thought is correct exactly if R* is lovely, it being irrelevant whether R is lovely. Therefore Max’s R-perception and subsequent thoughts don’t have the same truth-conditions, or therefore the same contents, as Twin-Max’s R*-perception and subsequent-thoughts. Leaving aside facts about the origins of their conditions, Max and Twin-Max are qualitatively identical. So it is solely in virtue of the fact that they xxx are embedded in different environments that they have perceptions and thoughts with different contents. Thus, in at least some cases, a mental state’s content is fixed, at least in part, by facts about the origins of that state. Two brain-states can be qualitatively identical, leaving aside facts about their causal origins, and yet have different contents. What a person (or creature) is thinking is constitutively dependent on facts about his environment, the same being true of the information encoded in his sense-perceptions.[1] The doctrine just described is known as “content externalism.” The present work is concerned with content-externalism (among other things). We will argue that it is false. Content-externalism must at all costs be distinguished from another doctrine that we will refer to as “semantic externalism.” Semantic externalism",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-004",
    "text": "A continuation of our story about Max and twin-Max will help us define the term “semantic externalism.” Max later tells people about R, referring to it as “Rocko.” Because Max is an eminent person, “Rocko” becomes part of the English language. So people who have never seen R sometimes refer to it as “Rocko.” They say things like: “the rock in your backyard is smaller than Rocko” and “Rocko is the most beautiful rock I have ever seen.” Thus, in W, “Rocko” refers to R. Everything that we just said about Max is true mutatis mutandis of Twin-Max. So, in W*, “Rocko” refers to R*. Here is what semantic externalism says about this situation. In W, an utterance of “Rocko weighs over five lbs” is true exactly if R weighs over five lbs, it being irrelevant whether R* weighs over five lbs. In general, for any predicate phi, an utterance in W of ┌Rocko has phi┐ is true exactly if the same is true of the singular proposition R has phi, it being irrelevant whether R* has phi. For exactly similar reasons, an utterance of ┌Rocko has phi┐ in W* is true exactly if R* has phi, it being irrelevant whether R has that property (Salmon 1986, Kaplan 1989, Soames 2001, 2004). Content-externalism and semantic-externalism are distinct doctrines.[2] The first is a doctrine about what people think. The second is a doctrine about what our words mean. As we will see, a failure to distinguish between these two doctrines has led to much confusion in contemporary thought. We will find that semantic-externalism is unqualifiedly true, even though content-externalism is (so I will argue) unqualifiedly false. There are many well-known apparent problems with semantic-externalism. For example, if semantic-externalism is right, then “Hesperus=Hesperus” has precisely the same literal meaning as “Hesperus=Phosphorous.” But surely these sentences must have different meanings, given that one of them is trivial whereas the other is non-trivial. We will find that this problem, and others like it, vanish when we take a few basic facts into account – in particular, the fact that one must always exploit background semantic and non-semantic knowledge to compute the meanings of sentence-tokens that one encounters. Some apparent problems with content-externalism",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-005",
    "text": "As we have already seen, there is much to be said for content-externalism. It is a datum that, notwithstanding their similarities, Max and Twin-Max are seeing, and subsequently thinking about, different rocks. So it seems a datum that the contents of Max’s mental states are, to that extent, different from the content’s of Twin-Max’s mental states. Finally, there is no way to explain these differences except in terms of the fact that Max’s mental states don’t have the same origins as Twin-Max’s. These differences have no intra-cranial basis, and must therefore be sought in what is extra-cranial, i.e. in what is external. But there is a problem. So long as we confine ourselves to the regions occupied by their bodies, there is nothing that distinguishes Max from Twin-max. It immediately follows that they are physically identical. And unless we take the dubious measure of saying that their minds engulf remote regions of space larger than those encompassed by their bodies[3], it also follows that they are psychologically identical.[4] So to the extent that it must be understood along content-externalist lines, mental content is without any psychological significance: what a person is thinks, believes, and doubts is irrelevant to how that person is psychologically. But it would seem to be a truism that two people differ psychologically if they differ in respect of what they believe, think, or doubt. As we will see, some authors reject this supposed truism on the grounds that it conflicts with content-externalism. But it is prima facie to the discredit of that doctrine that it has such a revisionist consequence. Before moving on, we should consider a possible externalist rejoinder to the argument just given:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-006",
    "text": "It is easy to show that this response has consequences too revisionist to accept. Because light travels at a finite speed, one often sees stars that went out of existence long ago. Given this, suppose that, instead of being nearby rocks, R and R* are qualitatively identical, but numerically distinct, stars that went out of existence 100 million years ago. In that case, the objector’s response amounts to this: at least some portion of Max’s mind was around 100 million years ago. But that is straightforwardly false. There were no human minds back then. This point can be generalized. One sees states of affairs, not objects. You don’t just see Smith. Rather, you see a dated situation that has Smith as a component. Because light travels at a finite speed, anything that you see has since ceased to exist, and anything that is contemporaneous with your visual perception is, at most, a successor or continuation of the state of affairs that you are seeing. Since content-externalism makes the thing you are seeing into a veritable constituent of the content of your perception, it follows that the objector’s response drains all of your perceptions of any content. Given that our perceptions obviously do have content, we may conclude that Max and Twin-Max are psychologically and physically identical, contrary to what the objector says. Some apparent problems with content-externalism (continued)",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-007",
    "text": "Suppose that Max does, whereas Twin-Max does not, believe that there is a nearby ATM machine that is spitting out hundred dollar bills. There will be an immediate difference between Max and Twin-Max in regards to what they feel, what they want, and what they do. Max will, whereas Twin-Max will not, experience a crisis of conscience (“should I take money that is not mine?”). Max will, whereas Twin-Max will not, repress his feelings of guilt at taking the money. Max does, whereas Twin-Max does not, develop a feeling of self-loathing, which is defensively cloaked under a veneer of excessive self-confidence. And so on. In this case, we have a situation where Max’s mental content clearly differs from Twin-Max’s. That initial difference quickly ramifies into others, and Max and Twin-Max forever cease to have parallel lives. To see why this is a problem for the content-externalist, let us return to the previous scenario – the one where the only differences between Max and Twin-Max coincide with, or derive from, the fact that the one person saw R while the other saw R*. In that scenario, the alleged difference in content doesn’t lead to any lack of parallelism. Even if we concede to the content-externalism that Max and Twin-Max have different psychological contents, those contents are perfectly parallel. For reasons of a purely methodological nature, that perfect parallelism is suspicious. We are reminded of Poincare’s famous thought-experiment. Let W and W* be two different universes. (These needn’t coincide with the two homonymously named universes previously discussed.) At time t, everything in W undergoes a tenfold increase in size. Apart from that, W and W* are qualitatively identical. Is there any difference between W and W*? Poincaré famously said “no”, and his answer was vindicated by later developments in both physics and logic. Because the changes that occurred in W were perfectly uniform, the relational properties of events in the one world remain identical with those of events in the other world. Thus, I am twice as tall as my niece in W iff I am twice as tall as she is in W*. If my pants are too tight in W, then they are too tight by exactly the same amount in W*. It is obvious that these points generalize without limit. There is thus no conceivable way of differentiating between W and W*, and the statement “I am in W,...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-008",
    "text": "You are begging the question. Max and Twin-Max don’t remain in lock-step. Max has dreams about R, whereas Twin-Max has dreams about R*. Max wants to build a miniature replica or R, whereas Twin-Max wants to build a miniature replica of R*. And these differences do ramify into others. Given that both Max and Twin-Max believe that there are no square circles, Max comes to believe either R* weighs over five lbs or there are square circles whereas Twin-Max comes to believe: either R weighs over five lbs or there are square circles. So contrary to what you said, we don’t have one difference: we have a whole pattern of differences.[7] The content-externalist wishes to show that, because Max’s perception results from R as opposed to R*, his mental content is qualitatively different from Twin-Max’s. All of the differences cited by the objector presuppose that this is the case. So the differences cited by the objector in defense of the content-externalist’s position presuppose the truth of that position, and thus don’t provide any independent support it.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-009",
    "text": "A theory is a way of modeling data. In philosophy, these data usually consist of intuitions. For example, we all have the intuition that killing infants is evil; and any viable ethical theory must either validate that intuition or it must show that, relative to intuitions of an even more fundamental kind, it can be explained away. It is a datum that some of Max’s thoughts are made true by facts about R, whereas Twin-Max’s corresponding thoughts are made true by facts about R*. It is also a datum that there are certain apparent similarities between Max’s R-thoughts and Twin-Max’s R*-thoughts. Content-externalism provides one model of such data. Content-internalism provides a different model of that data.[8] (By “content-internalism” I mean the doctrine that content-externalism is false.) These days most philosophers believe that content-externalism is correct. In other words, most philosophers believe that, because of the differences between W and W*, Max and Twin-Max differ in respect of the identity of the information encoded in their sense-perceptions and subsequent thoughts. For the reasons given a moment ago, it seems very reasonable to believe that there is a kind of representational content that Max and Twin-Max have in common, and that this common content is not affected by the differences between their two worlds. Following convention, we will refer to that kind of content (supposing that it exists) as “narrow content” (Loar 1985, Jackson and Pettit 2004c). So supposing that x and y are qualitatively identical, leaving aside facts about the origins of their conditions, x and y cannot differ in respect of the narrow contents of their perceptions and thoughts. Of course, all content-internalists believe that there is such a thing as narrow-content, and so do some content-externalists. Such content-externalists are forced to advocate a “two-tiered” or “two-dimensional” conception of mental content. We will refer to this position as “soft content-externalism.”[9] A number of eminent content-externalists deny that there is such a thing as narrow-content. Of these, the most prominent are probably Tyler Burge, Gareth Evans, and John McDowell. We will refer to this position as “hard-line content-externalism.” In this work I will argue that both forms of content-externalism are quite false. I will also argue that semantic externalism is entirely correct. We will see that many of the grounds for content-externalism vanish as soon as that doctrine is sharply distinguished from semantic externalism. Jerry Fodor (1998) is a hard-line externalist...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-010",
    "text": "But Fodor’s primary reason for accepting conceptual atomism is not that content-externalism demands it. His primary reason is that he accepts CTM and, as Fodor himself cogently argues, the truth of CTM depends on that of atomism. (Fodor (1968, 1975) accepted CTM before content-externalism even came into existence.) In Chapters 13-22 we will argue that CTM is not viable and that the arguments for it are fallacious. Let us briefly outline what we will say. For the sake of argument, suppose that CTM is right. In other words, suppose that thinking does consisting in “computing.” A question immediately arises: What exactly does the word “compute” mean in this context? Right now, I could compute a sum – I could add 134 to 397. But that kind of computation obviously presupposes various cognitive faculties, and thus cannot underlie cognition. Fodor is aware of this, and he defines the word “computation” in a way that, he believes, does not render CTM viciously circular. A computation, he says, is a “formal operation on symbols” (Fodor 1987: 19). It is an operation that is causally driven by the forms, not the meanings, of the symbols involved. A machine can respond to the form of the expression “23+15” in such a way that it produces the right output. No thinking is needed to perform a purely formal operation. Given that computing is a purely formal operation, it follows that there is no vicious circularity in supposing that thinking is computing (Fodor 1981: 13-17, Fodor 1987: 18-20). An immediate consequence of CTM – indeed, the very essence of it - is that thinking is not content-driven (Fodor 1987: 19). Of course, such a position initially strikes us as very odd. I believe that Bill fell off of a tall building, and this leads me to believe that he is now injured or deceased. Surely this is an example of a content-driven sequence of mental states. So supposing that we do think in symbols, it is very hard to believe that the semantic properties of those symbols are causally inert. But Fodor (1987, 1990) has produced an argument that, if cogent, shows why we mustn’t put too much stock in this particular criticism of CTM. The purely formal properties of symbols can be coordinated with their representational properties in such a way that all of the relevant phenomena are easily explained – e.g. the fact that, if...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-011",
    "text": "There are a number of points to make in response to the argument just outlined. I will now only outline these points, since they will be discussed at length later on. Supposing that a computation is understood to be a “form-driven” operation, we must ask: what is meant by the term “form”? Sometimes Fodor says that what he has in mind is syntactic form. So Fodor’s position becomes: a computation is a syntax-driven operation. Is this claim feasible? Before we can answer this question, we must note that the term “syntax” is ambiguous: what linguists mean by it isn’t what mathematical logicians mean by it. Let us now see if either disambiguation of the term “syntax” validates Fodor’s position. According to a linguist, the sentences:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-012",
    "text": "have similar (or identical) syntactical structures. What does this mean? It means that they have similar derivation-trees. And this means, very roughly, that the way in which the one sentence is assigned the meaning that it has resembles the way in which the other sentence is assigned the meaning that it has. In general, the syntax of a sentence lies not in what it means, but in how it means what it means. Syntax is meaning-how. (Semantics is meaning-what.) The concept of syntax is therefore not a meaning-innocent notion. So supposing, as Fodor does, that thinking is an operation on expressions, syntax-driven operations are meaning-driven. They are driven by a sensitivity not to what the operands mean, but to how they mean what they mean. Sensitivity to meaning-how, no less than sensitivity to meaning-what, presupposes a heavy cognitive arsenal. It is therefore not tenable to suppose that syntax-driven operations could be cognitively foundational. Let us give a different version of the argument just outlined. The term “wet” is not interchangeable with the expression “the property of wetness.” After all, “one shouldn’t drive on wet roads” is meaningful, whereas “one shouldn’t drive on the property of wetness roads” is not. If you know only that the term “wet” denotes or expresses a certain property, and do not know the syntactic properties of that expression, then you are ignorant of a crucial aspect of its meaning. Syntax is combinatorial (or recursive) semantics. One knows the syntax of a complex expression when knows the combinatorial semantic properties of its constituents. Equivalently, one knows the syntax of an expression when one knows how its meaning is derived from those of its constituents – when, in other words, one knows its derivation tree. An operation is syntax-driven iff it is driven by a sensitivity to combinatorial semantics. Since such an operation can be carried out only where there is already an awareness of meaning, it is not an option to hold that such operations form the foundation of our cognitive lives. The linguist’s disambiguation of the term “syntax” thus fails to validate Fodor’s position. Let us now see if Fodor’s position is validated by the mathematical logician’s disambiguation of that term. First of all, how are the two disambiguations different? Most linguists would say that",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-013",
    "text": "The linguist sees “or” as being in the same syntactic category as “and.” From his standpoint, (1) and (2) are no more syntactically different than “Bob is tall” and “Bob is short.” But the mathematical logician says that, because (2) has an “or” in the place where (1) has an “and”, those sentences are in different syntactic categories. What is the basis of this (apparent) disagreement? When a mathematical logician says that a sentence S, belonging to language L, is “syntactically true”, he means that it is a theorem or consequence of the semantic rules of L that S is true.[14] And when a mathematical logician says that two sentences S and S* have the same syntax, he means that they are interchangeable from a proof-theoretic standpoint. Equivalently, S1 and S2 have the same “syntax” iff….S1…is syntactically true iff the same is true of…S2….(So, for example, if there is some sentence S3 such that S1→S3 is a theorem and S2→S3 is not, then S1 is syntactically different from S2.) It is a theorem of the rules of English semantics that (1) is true, but not that (2) is true. Indeed, it is a theorem of those rules that (2) is false. Even though the mathematical logician’s disambiguation of the term “syntax” is different from the linguist’s, the former poses the same problems for Fodor’s analysis as the latter. On both disambiguations, a sentence’s syntax lies in how it means what it means. Of course, the linguist and the logician don’t have quite the same thing in mind when they think about how a sentence is assigned the meaning that it has. The latter is concerned with non-psychological notions such provability; the former is concerned with psychological notions such as comprehension and learnability. But in both cases, a sentence’s syntax lies in a relationship that holds between the semantic rules of the relevant language and the sentence’s meaning. So given either disambiguation of the term “syntax”, syntax-driven operations are meaning-driven. This immediately entails that Fodor’s position is a non-starter",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-014",
    "text": "Given this sense of the word “syntax”, if some syntax-driven entity accepts each of “Smith is ill” and “Smith doesn’t smoke”, it is just as likely to transition to (^) as it is to transition to (^^). But this clearly doesn’t correspond to the transitions that a rational person would make. So the linguist’s definition of “syntax” fails to validate the idea that thinking consist in syntax-driven operation. According to the mathematical logician, (^) and (^^) do have different syntactic structures. Indeed, from the mathematical logician’s viewpoint, the “syntax” of a sentence is by definition identical with its logical form. So it would seem that this disambiguation of the term “syntax” would validate Fodor’s analysis. But this is not so. Relative to this reading of the term “syntax”, syntax tracks logical form only if the language in question satisfies conditions that would make that language useless in the way of mediating rational thought. In that sense of the word “syntax”, an utterance of “that [pointing to Smith] is identical with that [pointing to Jones]” has the same syntax as an utterance of “that [pointing to Smith] is identical with that [pointing once again to Smith].” So a purely syntax-driven entity wouldn’t be capable of registering the profound logical differences between these two utterances. Since it is obvious that human beings can do so, it follows that, in this sense of the word “syntax”, we aren’t syntax-driven entities (Kuczynski 2006b). What we just said about “that” is true of “here”, “now”, “this”, “over there”, and any other context-sensitive expression. Syntax can be coordinated with logical form only where there is no context-sensitivity. So supposing that we think in a language whose syntactic structures are coordinated with their logical forms, it follows that those sentences have no context-sensitive component and that, consequently, one isn’t capable of thinking things like it is now 3:00 p.m. or that guy is Jones. Since we obviously do have such thoughts, our thoughts are not mediated by a language of the kind just described. Syntax as morphology Sometimes when Fodor talks about sentential “form”, he is referring to the property of having a certain shape. He is referring to form in a purely geometrical sense (Fodor 1987: 18-20). But this disambiguation of the word “form” doesn’t validate the contention that thought is syntax-driven or, therefore, that it is meaningfully described as computational. Syntax is not morphology. Syntax...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-015",
    "text": "But there is a problem with CTM, and also with content-externalism, more fundamental than any thus far mentioned. Suppose that brain-state B realizes a condition of believing that Socrates was bald. There is no doubt that B has causal properties; it has a certain shape, a certain mass, and consists of particles with positive and electric charges, and so forth. But if content-externalism is right, then B’s having a certain representational content – its encoding the proposition that Socrates was bald – is causally inert. From the viewpoint of causation and explanation, B’s having that property is as irrelevant as its having the property of being a thing x such that x is either a circle or not a circle (Jackson and Pettit 2004: 46-48, Kuczynski 2006c). Content-externalism threatens the very existence of mental content. Where the occupants of the spatiotemporal are concerned, existence and causality are practically indistinguishable. Fodor (1968) himself makes this point very clearly,[15] and so does Jaegwon Kim (1993: 348). A state of affairs that has no causal powers is no state of affairs at all. Since content-externalism strips mental content of causal powers, it denies its existence. John McDowell argues that content-externalism is compatible with the causal efficacy of the mental.[16] But McDowell’s argument is a straightforward non-starter, as we will see in a moment. Fodor sees clearly that, if content-externalism is right, no brain-state has causal powers in virtue of its representational properties; i.e. he sees that content-externalism strips content of causal efficacy. (That is why, in his view, it is the “syntactic structures” of brain-states, not their semantic (representational) properties, that do all the causal work.) But Fodor seems not to see that this jeopardizes the very existence of representational, and therefore mental, properties. Like McDowell, Frank Jackson and Phillip Pettit hold that content-externalism is consistent with the causal potency of the mental (Jackson and Pettit 2004-2004c). But their argument is very different from McDowell’s, and has considerably more merit. Their argument is based on a distinction between what they call “program-causality” and “efficient-causality.” They argue that content-externalism allows representational states of affairs (e.g. a brain-state’s being a belief that Plato was wise) to be program-causes, even though it doesn’t allow them to be efficient-causes. I believe that the Jackson-Pettit analysis of causality is accurate and that the distinction between program-causality and efficient-causality is of the highest importance. But their worthy analysis of...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-016",
    "text": "(D) For any context C, if there somebody x in C is a uniquely salient overbearing and generally unsavory man standing next to a uniquely salient painting y, then a token in C of “that overbearing and generally unsavory man standing over there next to that atrocious painting is a professor of anthropology” means: x is a professor of anthropology. When one hears a token of (A), one has to work through (D). Anyone who knows (D) will know that an utterance of (A) will not be true unless, in the context of utterance, somebody x is a uniquely salient overbearing and generally unsavory man standing next to a uniquely salient atrocious painting y, and x is a professor of anthropology. So even though what a token of (A) literally means is (B), and thus doesn’t involve the concepts of being unsavory or over-bearing, what such a token communicates to someone does concern these very concepts. Because of the information that one must work through in order to assign the right proposition to a token of (A), what such a token communicates is very different from what it literally means. I will refer to information conveyed in this way as “pre-semantic implicature.” We will find that what we just said about tokens of (A) is true, to some degree or other, of all sentences. In connection with this, we will find that pre-semantic implicatures are exponentially more powerful than the post-semantic implicatures studied by Grice. Let us now briefly say what is meant by (2) and (3). Consider the sentence:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-017",
    "text": "This sentence is true because Benjamin Franklin invented bifocals. So Franklin’s inventing bifocals is the truth-maker of (S). But the meaning of (S) obviously isn’t: Franklin invented bifocals. After all, even though it is false, “somebody invented bifocals, but Franklin did not invent bifocals” is not self-contradictory.[17] What we just said about sentences is true of perceptions and thoughts. When I look at an ice-cube, what makes my perception veridical is that there are various H2O-molecules in a certain configuration in a certain region of space-time. So the truth-maker of my perception is given by some proposition having the form: in region R, there are various molecules consisting of hydrogen and oxygen atoms, and those molecules are interrelated in such and such a manner. But what my perception tells me isn’t given by such a proposition. So the content of my perception doesn’t involve the concepts molecule, oxygen, or hydrogen. In his landmark work the Varieties of Reference, Gareth Evans put forth deep and original analyses of conception, semantic content, and the relationship between the two. I believe that, by combining Evans’ insights with (1)-(3), we are able to produce models of both semantic and cognitive content that satisfy two important requirements. First, those models enable us to hold onto all of the pre-theoretic intuitions that are prima facie inconsistent with consent-externalism. For example, those models enable us to hold onto our intuition that, in at least some cases, our beliefs about our own minds are characterized by a kind of certainty and incorrigibility that could not possibly characterize our beliefs about the external world. (As we will see, content-externalism has a hard time accommodating this datum.) Second, those models enable us to account for the important fact, stressed (but misunderstood) by content-externalism, that our concepts of spatiotemporal objects have an ineliminable causal component. Evans’ notion of a “cognitive map” is going to play a crucial role in our analysis of conception. We will also find important applications for Evans’ important distinction between “conceptual” and “non-conceptual” content. Evans’ idea of a de re sense (Evans 1985: Chapter 10) – which came to have an important place in McDowell’s work (McDowell 1998: Chapters 10-13) – will also be discussed at length. We will find that it is an incoherent synthesis of a number of deep insights.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-018",
    "text": "I would like to end this introduction by substantiating a point made earlier. As previously noted, John McDowell argued that content-externalism is consistent with the fact that the mental is causally efficacious. Let w* be a world that is just like ours except that w* contains XYZ, instead of H2O. (In this context, take “world” to mean “planet.”) Let Smith be a person of our world, and let Smith* be Smith’s doppelganger in w*. In our world, Smith’s perception of a glass of H2O causes him to reach for that glass. In w*, Smith*’s perception of causes him to reach for that glass. Here is what, according to McDowell, is going on. McDowell says that Smith’s perception has a different content from Smith*’s. There is some glass x such that the content of Smith’s perception does, whereas the content of Smith*’s perception does not, have x has a constituent; and there is some glass y such that the content of Smith*’s perception does, whereas the content of Smith’s perception does not, have y has a constituent. Further, there is some natural kind N – namely, H2O -- such that the content of Smith’s perception does, whereas the content of Smith*’s perception does not, have N has a constituent. Finally, there is some natural kind N* – namely, XYZ -- such that the content of Smith*’s perception does, whereas the content of Smith*’s perception does not, have N* has a constituent. We’ve already seen some reason to believe that these contentions are wrong, and involve a conception of perceptual content that is rendered incoherent by its failure to distinguish a number of relevantly different notions – in particular, the distinction between data and meta-data, the distinction between literal and cognitive meaning, and the distinction between content and truth-maker. But let us leave that aside for now, and continue with McDowell’s analysis. According to McDowell, it is patently obvious why content-externalism is consistent with the fact that the mental has causal powers. In virtue of having glass x, as opposed to glass y, for its content, Smith’s perception has causal powers not had by Smith*’s perception. Smith’s perception does, whereas Smith*’s perception does not, causes somebody to reach for glass x. And in virtue of having glass y, as opposed to glass x, for its content, Smith*’s perception has causal powers not had by Smith’s perception. Smith*’s perception does, whereas Smith’s perception...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-019",
    "text": "Let us begin by considering a statement made by Jon Barwise (1989: 26): When I look around I cannot see a single thing-it-itself, some sort of ideal physical object stripped of its properties and its relations with other objects. What I do see is a scene, a complex of objects having properties and bearing relations to one another. The properties and relations are every bit as important to what I see as the idealized thing-in-itself. In fact, what really counts is the whole complex of objects-having-properties-and-bearing-relations which constitutes the scene.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-020",
    "text": "One sees states of affairs. One does not see objects simpliciter. This must be understood aright. Obviously one does see objects. That is a datum. But one sees objects by seeing the states of affairs in which they are embedded. You don’t just see Fido. You see an object with certain properties (e.g. it has a certain color fur and a certain number of legs), in a certain location. That location is, in its turn, visually represented to you in relational terms: Fido – or, strictly speaking, the state of affairs in which he is embedded – is given to you as being under the piano, next to Toonces the cat. Everything that we just said about Fido is true mutatis mutandis of these objects. One doesn’t see Toonces. One sees an object with certain morphological, chromatic, and kinematic properties. One sees a four-legged creature with black with white spots, moving about in such and such a manner. Before drawing what I believe to be some of the consequences of these points, I would like to make a distinction. Barwise rightly says that you don’t ever see a bare thing-in-itself: whenever something is given to you in visual perception, it is given to you as having various properties and standing various relations vis-à-vis other objects. But there are two ways to interpret this point. We can take it to mean:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-021",
    "text": "(*) and (**) are inconsistent with each other. If there is any possibility of a thing’s being visually represented to one as a bare particular -- even as a bare particular that happens to be surrounded, so to speak, by various instances of properties and relations -- then it is ipso facto false to say that things must be represented as being propertied and interrelated. So if (*) is right, then (**) is false. Given that sense-perception is necessarily predicational, it follows that there is no prospect of a thing’s being visually represented as a bare particular and that (**) is therefore the right thesis. In perception you are not given a bare particular alongside instances of properties and relations. You are just given those instances. Sense-perceived particulars are represented to you in terms of instances of properties and relations. When you see Fido, the content of your visual perception (so far as it can be put into words) is not given by a noun (“Fido”), but by a sentence (“at this point in time, in a certain place, there is a creature that has four legs and beige fur…”). For you to see Fido is for Fido to be described to you. Perception is description. Here an anticipation is in order. Later we will find that the content of a perception is not a proposition, even though the content of any perception can, at least up to a point, be given by a proposition. But this doesn’t affect the substance of our points about perception. The information encoded in any sense-perception is descriptive and existential in nature. The content of that perception is given information that affirms the existence of situations satisfying certain conditions and that, in so doing, describes objects. A consequence is that, so far as that information can be verbalized, it is given by existence-claims (“there is a four-legged animal with beige fur, sitting underneath the piano…”), and not by mere nouns (“Fido”). We will often refer speak of this information as consisting in “propositions.” But this is simply an expository device – the word “information” can always be substituted for “proposition”, provided the needed grammatical changes are made – and it mustn’t be supposed that we are taking it for granted that perceptual content is propositional in nature. On the contrary, we will go to great lengths later (Chapters 22-23) to show that it is...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-022",
    "text": "At the moment, we may set aside the question whether natural languages in fact contain semantic rules like (S). (Our discussion of (S) will itself help us settle that empirical question.) The import of (S) is this. Tokens of “Smith” are not “connotative” or “descriptive.” For a token of “Smith is tall” to be true, it is necessary and sufficient that Smith be tall; and it is irrelevant whether Smith has any properties other than that of being tall. Put more formally, there is some x such that a token t of “Smith is tall” means is true iff x is tall. So, for some x, a token of “Smith is tall” encodes the “singular proposition” x is tall. But we must distinguish (S) itself from one’s knowledge of (S). Unless people know (S), at least at some level, that semantic rule is of no use in helping people communicate with one another. After all, if people do not at some level know (S), then they cannot use that rule to produce and understand statements. With these points in mind, let us ask a very basic question: How does one learn (S)? There are a few of different ways, and we will soon discuss all of them. But right now we may focus on the most fundamental one. Smith is right in front of you. Your companion points to him, and says “that guy – the one right over there, standing next to the water-fountain – is Smith.” Here there is some x such that the semantic rule you are learning is simply this:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-023",
    "text": "Now that you know (S), you can understand, and meaningfully produce, sentences of the form ┌…Smith…┐Your knowledge of (S) is thus implicated in your being able to understand and intelligently use expressions of that form. (By an “intelligent” use of an expression I mean one that embodies an understanding of what it means. People do, whereas parrots do not, intelligently say “it’s cold out today.”) But here we come to a crucial point. In order for you to know (S), you have to know to be able to affix that label to the right person; you have to know who Smith is, at least on one delineation of that expression. Of course, you do know who Smith is, and you do know whom the word “Smith” labels. You know this on the basis of the ostensive definition discussed in the last paragraph: you saw Smith, and were told that “Smith” labels him. But what was the content of the visual experience through which Smith was represented to you? For reasons that we discussed a little while ago, you didn’t just see Smith. You didn’t see a “bare thing in itself.” Of course, you did see Smith. But what was visually represented to you, in your seeing him, was not a bare thing-in-itself, but was rather an object having a certain morphology (e.g. he had a certain number of limbs, and the musculature of an athlete), certain kinematic properties (e.g. it was picking up a tennis-ball), certain (relative) spatio-temporal properties (it was next to a certain water-fountain in Topeka, Kansas, on a certain Saturday in April…). So even though (S) itself is descriptively threadbare, the information through which (S) was made known to you was replete with descriptive articulations. Consequently, you must access (S) through such information. Semantically, “Smith” simply labels Smith. But you grasp (S) by having a mental state whose content given by some proposition like:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-024",
    "text": "Let us extend these points by telling a story. In terms of appearance, Mary and Twin-Mary are completely indistinguishable. (Here we are supposing that Mary and Twin-Mary are actual twins, and thus live in the same world.) Thus, to know that you were in the presence of the one as opposed to the other, you would either have to converse with her or study her behavior for an extended period of time. You are acquainted with both of them and thus have concepts of both. One day you see someone whom you know to be either Mary or Twin-Mary. There is, of course, nothing in your visual perception that tells you whether you are seeing the one as opposed to the other. But, let us suppose, the person whom you are seeing is in fact Mary. Here the content-externalist takes a bold position. He says that Mary herself is part of the content of your visual perception (Burge 1982, McGinn 1986, Kaplan 1989). Given this, suppose that, holding everything else constant, it had been Twin-Mary whom you were seeing. In that case, says the content-externalist, your perception would have had a different content. Let us begin by articulating the reasoning behind the content-externalist’s position. Suppose that you see Mary (as opposed to Twin-Mary) sipping tea from a porcelain cup. Let V be this perception. V is veridical exactly if Mary has those properties, it being irrelevant what Twin-Mary or any other Mary look-alike is doing. Since pieces of information are individuated by their truth-conditions, it follows that any visual perception with different truth-conditions wouldn’t encode the same information as V, even if the two sense-perceptions were phenomenologically identical; and it also follows that there is no perception with the same content as V* in any possible world where Mary doesn’t exist. Since mental states are individuated by their contents, it follows that V exists only in worlds where Mary exists. The relationship between V and Mary is constitutive. Mary is a constituent of V’s content and her existence is thus metaphysically necessary for V’s existence. V is no more capable of existing in a Mary-free world than water can exist in an oxygen-free world. This suggests that Mary herself – the flesh and blood object, not some Fregean concept thereof – is a component not only of the content of your visual experience, but of that experience itself. Given obvious...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-025",
    "text": "Consider a world W* satisfying the following conditions. W* is just like our world except that, at the relevant time, it is Twin-Mary, and not Mary, who is sitting on the couch in front of you sipping tea. Let V* be the visual experience that you have under those circumstances. Given only this much, it would seem arbitrary to say that V and V* are numerically different visual experiences; for given only this much, it is perfectly possible that V* in the same way as V from the very same causal processes, and that (leaving aside what the content-externalist says about those perceptions), both are qualitatively in all respects. But the content-externalist is forced to say that V* is numerically different from V. After all, she says that V and V* have different contents, since the one does, while the other does not, have Mary as a part of its content. So given that content-bearing entities are individuated by their contents, the content-externalist compelled to adopt the dubious position that V and V* are numerically distinct. It should be pointed out that no less an externalist than Tyler Burge (1982) insists that mental entities have their representational contents essentially and that it is therefore absurd to suppose that a perception could have a content different from the one it actually had. On this matter, I am in complete agreement with Burge. The content-externalist’s position is inconsistent with basic facts about what it is for one piece of information to entail another. We’ve seen that the statement X and Y are the same information is equivalent with the statement for any piece of information Z, Z can be inferred from X in manner M iff Z can be inferred from Y in manner M. V and V* satisfy this condition: nothing can rationally be inferred from V itself that cannot be inferred from V* itself (or vice versa); and nothing that can be inferred from the one is to be inferred in a different way, i.e. via a different series of deductions, from the way in which it is to be inferred from the other. The content-externalist’s typical response to this sort of point is as follows:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-026",
    "text": "But we’ve already seen why this point is a non-starter: it involves a failure to distinguish the information encoded in our perceptions from the information that, with the assistance of background knowledge, we derive from our perceptions. The content-externalist’s position involves a failure to distinguish between content and truth-maker. V is a perception of Mary, as opposed to Twin-Mary, not because Mary is a constituent of V’s content, but because some fact about Mary is V’s truth-maker. As we’ve discussed, V tells you not that Mary is sitting in a certain place sipping tea, but that some woman (or, at any rate, some entity with the morphology characteristic of a woman) has those properties. There is indeed a woman satisfying that description and, under the present circumstances, that woman is Mary. But there are counterfactual scenarios where some fact about Twin-Mary would be the truth-maker of that same content. The relationship between causality and content",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-027",
    "text": "For a visual experience to be a perception of x, x must be part of the state of affairs that causes that experience. But given only that x satisfies that condition, it doesn’t follow that x per se is a constituent of the content of that experience. The content of a visual experience is, as we’ve emphasized, indistinguishable from what the experience tells you; and this, in its turn, is indistinguishable from what you can rationally infer from V, taken by itself. By itself, no visual experience can tell you that it is x specifically – as opposed to some x-look-alike – that caused it; there is no way that, by itself, any could perception could encode such differential information. This is easily established on generically logical grounds. What your visual experience, taken by itself, tells you is going to be a function solely of facts about the physical properties of the situation right in front of you. (Indeed, it is going to be a function of a rather small subset of those properties.) So if one of constituents of that situation is replaced with something numerically distinct but qualitatively identical, there is no way for your experience to register that substitution. Suppose that x1, x2….xn are all qualitatively identical but numerically distinct objects. The character of your visual experience reflects only those aspects of the situation that are preserved in the light-rays that hit your retinas; and, for any i and any j, those aspects are invariant with respect to intersubstitutions of xi and xj. Your visual experience, taken by itself, cannot possibly register the fact that it is x3, as opposed to x24, that you are seeing.[22] So given the nature of visual experience, there is no way that your visual experience, by itself, could discriminate between its being Mary in front of you and its being Twin-Mary in front of you. So if we plausibly identify the content of your visual experience with what that experience tells you; and if we plausibly identify what it tells you with what you may logically infer from it (or, at least, with a certain proper part of what you may logically infer from it); then we must say that Mary is no more a part of your visual experience than Twin-Mary or any other Mary-impostor. Given this last point, if we are to avoid theoretical arbitrariness, we must say that...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-028",
    "text": "We can show how radical and counter-intuitive the content-externalist’s position is by following his own reasoning to its logical conclusion.[23] Once again, let V be a visual perception of Mary sitting on a couch holding a tea-cup. The essence of the content- externalist’s view is that Mary herself is a constituent of V’s content. But, of course, the same is supposed to be true each of the individual objects in the situation that is seen. So if that doctrine is right, the just mentioned sofa is a veritable component of V’s content, and so is the just mentioned sofa, and so is the cat sitting on that sofa – and so on. Given this, let V1 be a perception that is just like V with this one qualification: the sofa represented by V (as defined a pages back) has been replaced with a qualitatively identical, but numerically distinct, sofa. Now let V2 be a perception that is just like V1 except that the tea-cup represented in V1 has been replaced with a qualitatively identical, but numerically distinct, tea-cup. Repeat this procedure until each of the objects represented by V – each bit of yarn, each carpet-fiber -- has been replaced with a qualitatively identical, but numerically distinct object, and let Vn be the resulting perception. The similarity between V and Vn is not purely phenomenological. An artist who experienced V and painted what he saw would ceteris paribus produce a painting qualitatively identical with that produced by an artist who experienced Vn and then painted what he saw. Further, there is some one description D such that, in virtue of having either V or Vn, one would be warranted in affirming D. (D would be along the lines of: there is a woman with such and such properties sitting on a sofa holding a tea-cup…) It is clear that V and Vn a great deal of representational content in common. But content-externalism cannot accommodate this obvious fact. For the content-externalist, every one of the replacements we described would constitute a change in representational content. Numerically different objects, qualitatively different contents. A corollary is that V and Vn have the same content only to the extent that the objects represented by the one are numerically identical with those represented by the other. So, according to the content-externalist, V and Vn have no content in common. But intuition recoils at such a...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-029",
    "text": "In his landmark work Naming and Necessity, Kripke made a strong case for (2). (Like most contemporary philosophers, I believe that Kripke’s arguments are decisive.[27]) On this basis many have rejected (1), believing it to be incompatible with (2). I would like to show that (1) and (2) are not incompatible. Let us start with a quick summary of some of the relevant points in Naming and Necessity. According to Russell (1918, 1948), “Socrates” is synonymous with a definite description; this might be “the greatest philosopher to have died of hemlock poisoning.” To understand the word “Socrates”, and thus to understand sentences of the form “…Socrates…”, one must obviously know the semantics of “Socrates; and one must therefore know that “Socrates” is synonymous with that definite description. Consequently, anyone who uses the word “Socrates” with understanding is able to produce a description that applies to Socrates and Socrates alone. In general, if one knows the semantics of a referring term, then one knows some description that applies uniquely to the referent of that term. Supposing that x is the referent of “Gilgamesh”, if I understand what is meant by sentences like “Gilgamesh was wise” or “Gilgamesh lives a long time ago”, then I know of some description that singles out x. If I know of no such description, then I cannot really know what is meant by such sentences. Supposedly, Kripke demolished this view. Consider any description that Socrates uniquely satisfies. Here is an example: “the greatest philosopher to have died of hemlock-poisoning.” One can understand sentences of the form ┌…Socrates…┐ without knowing that the referent of “Socrates” consumed hemlock. One can understand “Socrates was wise” without knowing that “Socrates” picks out somebody who uniquely satisfies the description: greatest philosopher to have died of hemlock-poisoning. This point holds for any description that singles out Socrates. Consider the description: “the person who figures as the protagonist in most of the platonic dialogues.” One can understand the sentence “Socrates was wise” without having the slightest idea that he was a protagonist in any philosophical dialogues. Given any description D that applies uniquely to Socrates, one can understand “…Socrates…” without knowing that D applies to the referent of “Socrates.”[28] This point has many apparent consequences. Some of these are semantic in nature. Others are epistemological. Here is one of the semantic consequences. “Socrates” is not synonymous with any definite description. Given any description...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-030",
    "text": "Kripke’s argument has other apparent consequences, both for semantics and epistemology. Let us start with a question: Why does “Socrates” refer to Socrates and not (for example) Plato? Russell’s answer was this: “Socrates” is synonymous with a description that is true of Socrates and Socrates alone. Kripke made a powerful case against this answer. So how does Kripke answer our question? His answer is that “Socrates” refers to Socrates because a certain kind of causal relation holds between tokens of “Socrates” and Socrates himself (or, more exactly, states of affairs involving Socrates).[29] The following story will help us further explicate Kripke’s views on this topic. Somebody – let us refer to that person as “Smith” -- saw Socrates. Socrates’ presence thus caused Smith to have certain visual experiences. Smith then gave a name to Socrates. (Let us idealize away from the fact that, for cultural reasons, that is probably not how Socrates was named.) Smith was able to pass that name along to people who did not themselves see, or otherwise sense-perceive, Socrates. Of course, for Smith to pass along that name to someone, that person had to be causally connected to Smith. The process just described is repeated over and over. Let us suppose that I am the 521st installment in a sequence of events like the one described.[30] Smith’s original term for Socrates may well have undergone phonetic distortion. What I have been left with is the sound (or sound-type) “Socrates”, which may well probably very different in terms of phonetics from the term that Smith used. But that is not relevant here. What is relevant is that, when I produce instances of that sound-type, my words refer back to Socrates precisely because I am connected to Socrates by way of a chain like the one just described. When I say “Socrates”, my words refer to Socrates because they are causally connected to him in a certain way. In general, if an expression E refers to an object O, that is in virtue of the fact that tokens of E stand in a certain causal relation to states of affairs involving O.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-031",
    "text": "But, in a certain class of cases, one is able to acquire the ability to use a referring term without ever having been given either an ostensive or descriptive definition of it. Suppose that you and two other people (Smith and Jones) are talking. All of a sudden Smith and Jones start talking about somebody named “Argo.” They never say who “Argo” refers to. They never say: “Argo was the president of our fraternity back in college” or “Argo was my divorce lawyer; and by sheer coincidence he’s Smith’s racquetball partner.” They do not ostensively define “Argo, since he is not present. Smith and Jones simply prattle on about “Argo”, and you are too polite to ask them who that person is. Nonetheless, as Gareth Evans (1985: Chapter 1) pointed out, it seems that, even under these circumstances, you can use the word “Argo” in a meaningful way. You can say “it sounds as though Argo is a text-book case of somebody with borderline-personality disorder”; and you can ask questions like “did Argo mean to do that to you, or was it just an accident?” So, on the face of it, it seems that you can acquire the ability to use “Argo” in a meaningful way without ever having been given an ostensive or descriptive definition of it. When you say “it sounds as though Argo is an evil person”, you are using the expression “Argo” with understanding; you are not in the same category as a parrot that mindlessly produces those same sounds. It thus appears that you can simply “pick up” the ability to use “Argo”, and names generally: there needn’t be an ostensive or descriptive definition.[31] Let us take stock. There seem to be three ways that a proper name N can be inducted into one’s lexicon:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-032",
    "text": "(i) one can be given an ostensive definition of N; (ii) one can be given a descriptive definition of N; or (iii) one can just “pick up” the use of N.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-033",
    "text": "Given this, it is easily shown that that one’s learning what an expression refers to always involves one’s learning some description that singles out its referent. All of (i)-(iii) collapse into (ii). Let us start by considering category (i). Suppose that somebody ostensively defines “Socrates” for me. I see somebody haranguing a mob. My companion says: “that person is named ‘Socrates’.” Under this circumstance, I know that there is some individual x such that x uniquely has certain properties, and I know that “Socrates” refers to x. Ostensive definitions work by way of knowledge of uniquely individuating descriptions. Somebody points to some person (or object) O and says: “that guy is named ‘Fred’.” For the definition to work – i.e. in order for you to learn to what (or whom) “Fred” refers – you must have some way of singling out the person ostended. Suppose your companion points in a certain direction and says “that is Fred”, but there are thirty different equally salient objects. In that case, the definition won’t work, since you aren’t able to pick out the right object. Now suppose that there are thirty numerically different, but (leaving aside location) qualitatively identical men in a certain place. Your companion Bob goes up to one of them, put his hand on his shoulder, and says:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-034",
    "text": "Even though the person just named is qualitatively just like many others, you know of some description that applies to him and to no one else. You know the following proposition to be true: there is some individual x such that x is uniquely a person whom Bob just picked out – such that x uniquely has the property that Bob just put his hand on x’s shoulder – and “Fred” names x. This time Bob’s definition works. It works only because you know of some existence claim that Fred, and Fred alone, satisfies. The description is not one that tells you much about what kind of person Fred is. In fact, that description doesn’t tell you anything about how Fred is psychologically or (leaving aside facts about spatio-temporal location, and leaving aside also the information encoded in your perception concerning Fred’s appearance) physically different from other people. The description in question gives you enough information to cognitively single out Fred, and it gives you little beyond that. But that is neither here nor there. In this context, there is only one important point, namely: your knowing what “Fred” refers to depends essentially on your knowing the truth of some proposition of the form: somebody x uniquely has phi and “Fred” names x. This is not to deny that your knowing what “Fred” refers to involves your having some kind of causal connection to Fred. You do have some kind of causal connection to Fred: you see him, and this involves your being causally connected to him. You acquire the ability to use the word “Fred” in consequence of (among other things, I will argue) this causal connection. So your subsequent uses of “Fred” refer to Fred in virtue of this causal connection (among other things). But the causal connection is a component of your knowledge of a uniquely individuating description. In the story just told, that description was (at least approximately): “there is some object x over there such that, a moment ago, Fred put his hand on x’s shoulder and said: ‘this guy is named “Fred”’.” The relevant causal connection between you and Fred corresponds to the context-sensitive terms in that statement. (These are the expressions in italics.) We will see that in any case where a causal connection between X and Y is constitutive of X’s concept of Y, that connection is embedded in X’s knowledge of...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-035",
    "text": "Your picking up the word “Argo” doesn’t involve your learning the truth of some claim of the form: exactly one person x is a cad, and “Argo” refers to x. Such a claim is false, given that there are many cads. Your picking up “Argo” involves your learning the truth of some claim of the form: on such and such occasion, exactly one person x is being described as a cad, and “Argo” refers to x. We must take care to make one other distinction. Smith himself never uttered an existence claim of the form: there is some x such that x uniquely has phi and “Argo” refers to x. Smith himself never uttered an existence claim of the form: on occasion t, I (Smith) referred to somebody x as a cad and “Argo” refers to x. Smith said only “Argo is a cad.” But the information that you are given, by virtue of being in discussion with Smith, is not confined to what Smith himself says. When Smith says “Argo is a cad”, the information that is encoded in his words is quite threadbare. But even though what Smith was saying might have been minimal, the information you have about Smith’s saying it is enormous. You know when and where Smith performed that speech-act, and you have much other non-trivial information about it: and that information does suffice to give you the right kind of uniquely individuating description. There is no vicious circularity in this account.[32] Smith personally met Argo. He learned the meaning of “Argo” through an ostensive definition. Maybe Smith himself gave Argo the name “Argo.” (For cultural reasons, this is not likely. But that is not relevant.) In any case, Smith saw Argo, and then learned (or possibly stipulated) that the person he was seeing was named “Argo”. You meet Smith. You have a conversation with him. On some specific occasion within that conversation, Smith says “Argo was a cad.” You thus know that, on that occasion, there is somebody x such that Smith is describing x and x alone as a cad, and that “Argo” is the term Smith is using to refer to x. The uniquely individuating description that you subsequently associated with “Argo” is not: the unique person x such that x is named “Argo.” Rather, it is: the unique person x such that, on such and such occasion, Smith was describing x...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-036",
    "text": "The descriptive information is given wide-scope with respect to the “refers to” operator. So if Smith was a unique zipper-inventor, then “Julius was a millionaire” means Smith was a millionaire. That sentence does not mean: somebody x uniquely invented the zipper and x was a millionaire. “Julius” is a name, not a quantifier. You and Charlie don’t know who “Julius” refers to. But it does refer to somebody. On the face of it, it certainly seems as though you can use it significantly: you can, with understanding, say things like “Julius was probably a talented inventor” and “Julius must be worth a fortune”. Some authors, e.g. Kaplan (1968) and Donnellan (1974), have said that, under the circumstances, you cannot say things like “Julius must be worth a fortune” and really mean them. This is controversial. (I will soon argue that it is true.) But what is clear is that if you and I can use the term “Julius” with understanding, it is only because we know some true claim of the form: somebody x uniquely has phi, and “Julius” refers to x. Here, of course, phi is the property of inventing the zipper. I do not wish to be misunderstood. A case can be made (and soon will be made) that unless you know who invented the zipper, you don’t know which proposition is semantically encoded in “Julius must be worth a fortune”, or in any other sentence of the form ┌…Julius…┐ What you actually know is some meta-linguistic proposition like: for some object O, the sentence “Julius must be worth a fortune” is true exactly if O must be worth a fortune. Since you don’t know which exact person invented the zipper, you don’t know who “Julius” refers to; and you therefore don’t know which proposition is encoded in that sentence. But, at the same time, you have metalinguistic knowledge about “Julius must be worth a fortune” which, in some respects, simulates real understanding of it. In everyday life there are many cases where we seem to be adding a name to our lexicon in manner (ii). Suppose little Timmy has never heard the name “Shakespeare” before. You say to him: “Shakespeare is the person who wrote Romeo and Juliet.” Here it seems that the three year old is appropriating the name “Shakespeare” in manner (ii); for what you are telling him is, in effect: there is some x...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-037",
    "text": "What is literally meant by “Shakespeare was bald” is simply Shakespeare was bald, and is not: somebody x uniquely wrote Hamlet and x was bald. To avoid running afoul of Kripke’s correct points, we must take care to give the relevant operators – ┌refers to__┐, ┌is the semantic rule for__┐ – narrow scope. We must make sure that they are safely to the right of potential descriptive, and therefore modal, contaminants. We’ve seen that whenever you learn the semantics of a name, it is through descriptive information. But you give the descriptive content wide-scope. That is why you don’t regard ┌N has phi┐ as analytic, or as true in all possible worlds. The semantic information is given narrow-scope; the epistemological information is given wide-scope; and that is why you have all the right modal intuitions. Dummett (1973: 110-151) argues for wide-scope descriptivism. In his view, “Socrates was necessarily bald” means: there was some x such that x was a unique great philosopher to drink hemlock and necessarily: x was bald. It is pretty clear that this doctrine is false.[36] “Socrates was bald” doesn’t entail “somebody drank hemlock.” Dummett’s analysis deals with some of Kripke’s modal points, but not with Kripke’s compelling point that there is no analytic connection between “Socrates was bald” and “somebody drank hemlock.” It is to be emphasized that (S2) is true only because, in it, the “the semantic rule for ‘Shakespeare’ is this:” operator is given narrow scope, so that no descriptive information falls within its clutches. By being careful about where we put that operator, we avoid any kind of descriptivism, and our analysis remains Kripke-friendly. The problem of forgotten start-up descriptions",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-038",
    "text": "be a true proposition. Of course, what makes it true is that some particular thing O has phi. The truth of any generalization supervenes on the truth of some singular proposition. Let us refer to O as the “verifier” of (^). Consider the claim “somebody is bald.” This is true because particular people are bald – because Bob and Fred are bald. Bob and Fred are verifiers of “somebody is bald.” An existence claim can have many verifiers. (False existence claims have none.) A true existence claim of the form “somebody uniquely has phi” has exactly one verifier. With this terminology in place, we can easily state a formidable objection to our analysis. One typically forgets the existence-claim through which one added a name to one’s lexicon. One typically forgets the first time one heard “Shakespeare” or “Aristotle”; one often forgets one’s first meeting of a person. Given this, one is tempted to say:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-039",
    "text": "(e1) there is now somebody x such that I am now sense-perceiving and focusing on x, and who is wearing a bowler hat, and “Fred” names x. Let us suppose that, a minute or so after “Fred” is ostensively defined for you, you go up to him and start talking. You now have a new uniquely individuating description of him. There are a number of reasons for this. First of all, the mere lapse in time between your current situation – your now talking with Fred – and the initial ostensive definition by itself guarantees that you will have a new uniquely individuating description of him. At time t, e1 was your uniquely individuating description. But because that time has now passed, e1 has been replaced. By itself, the mere passage of time replaces e1 with:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-040",
    "text": "This process can continue ad infinitum. One’s ability to think about and refer to something can only be started up by one’s acquiring knowledge of the right kind of existence-claim. Typically, that specific claim is forgotten. But it is replaced by another existence claim that interlocks with the first. That second one may, in its turn, be replaced by a third; the third by a fourth; and so on. Thus, contrary to what the objector says, the ability to think about, and refer to, an external object always involves possession of a uniquely individuating description that applies to it. The concept of recognition",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-041",
    "text": "The objector says that there can be “pure”, i.e. non-descriptive, conceptions of objects. But conception is surely not so innocent; and this becomes clear when we consider the phenomenon of recognition. To recognize something is not, at least not merely, to register the truth of a bare identity proposition – a proposition of the form O=O. To register the truth of Smith is Smith is not, by itself, to recognize anything; and to recognize something is not (merely) to register the truth of O=O. Recognition is obviously replete with knowledge of descriptive content. When you recognize the man in the distance as the man who insulted you at the restaurant, a great deal of descriptive, and therefore existential, knowledge is involved. You know that there is some x such that x insulted me at the restaurant…You also see that there is some y in the distance such that…Your recognizing the man in the distance as the man from the restaurant involves your “integrating” these pieces of information. You see that both descriptions – man in the distance and man from the restaurant – connect somehow; you see that there is some one thing such that both descriptions apply to it. In other words, you recognize the truth of some existential claim like: there is some x such that x is a man who insulted me at the restaurant and is also a man in the distance whom I am now seeing. Once it is granted that recognition involves putting together different pieces of existential-descriptive information, it becomes highly plausible to see recognition as consisting in one’s registering the truth of the kind of existence-claim described a moment ago. The alternative is to see recognition as stripped of any descriptive content. But this is not psychologically (or, I think, epistemologically) plausible. These points about recognition confirm our analysis of conception. When you recognize something, what is happening is that two conceptions converge. Your recognizing the man in the distance as the man from the restaurant involves your putting together different pieces of descriptive information; it involves your realizing that some one conception (the awareness you are having now, of the man in the distance) and some other conception (the one you have of some lout whom you dealt with at a certain restaurant) both pick out some one thing. If conceptions were “pure”, i.e. were non-descriptive and therefore non-existential, then the...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-042",
    "text": "According to Russell, for me to have a conception of O, I must know the truth of some existence claim of the form x uniquely has phi that O satisfies. So, like us Russell, advocates a strictly descriptive conception of conception (except where sense data and universals are concerned). But Russell on the basis of this correct view, Russell put forth some doctrines that are highly questionable. The purpose of this section is to determine, in light of the points thus far developed in this work, just what is right about Russell’s position and also what is wrong about it. Russell famously distinguished between knowledge by description and knowledge by acquaintance.[39] According to Russell, one’s knows something by description if one knows some existence claim that it uniquely satisfies; and one knows something “by acquaintance” if one has some kind of non-descriptive and, in generally, completely direct awareness of it. Russell thus concludes that one cannot be acquainted with any constituent of the external world. The only spatiotemporal entities with which one can be acquainted, according to Russell, are contents of one’s immediate consciousness (e.g. sensations, images).[40] For this reason, Russell comes to the conclusion that it isn’t possible for anyone (with the possible exception of Socrates himself) to grasp propositions of which Socrates is a constituent. Russell believes that if x is an external spatiotemporal entity – a spatiotemporal entity that is not a constituent of one’s own consciousness -- then one cannot grasp any singular proposition of the form x has phi. Put another way, in Russell’s view, one cannot grasp any proposition that de re concerns Socrates or any other external object. I will argue that ultimately Russell is wrong. But the operative word here is “ultimately”; and the reasons why Russell is now generally held to be wrong have little or no real force against his views.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-043",
    "text": "There is no such thing as a “pure”, descriptively innocent grasp of anything external. It follows that (*) cannot be grasped except by way of (**). This is obviously similar to Russell’s view. Russell chose to express this view by saying that one cannot grasp (*). I choose to express it by saying that the way one grasps (*) is by grasping (**). But this difference is purely verbal.[41] Russell made a point that has not been given its due in contemporary epistemology. There does seem to be a fundamental difference between the way I know about my own pains and tickles and the way I know about external objects. Suppose that I am having some pain x, and at that very moment, I believe the proposition x is unpleasant and I wish it would go away. It doesn’t seem possible that, if x were not to exist, I would be capable of having that very thought. After all, x is a constituent not only of the proposition I am grasping, but also of my grasping of it. By contrast, an external object can never be a constituent of one’s awareness of it. This is the case even when one directly sees or otherwise perceives Socrates, as the following story makes clear. Tom is in possible world W1 and he sees Socrates. V1 is the purely psychological component of that perception. Socrates doesn’t exist in world W2. But W2 is otherwise just like W1. So supposing that V2 is Tom’s visual experience W2, it obviously follows that V1 and V2 are numerically identical. Of course, the distal cause of V1 is Socrates, whereas the distal cause of V2 is (let us say) some android who resembles Socrates. But the immediate biological antecedents of V1 are numerically identical with immediate biological antecedents of V2. More generally, both experiences are embedded in the same way in the history of the same organism. It would thus be highly counter-intuitive to deny that they were numerically identical. Also, V2 and V1 are identical in respect of their phenomenologies and also in respect of their causal properties. (Some content-externalists would say that they have different causal properties. But we’ve already seen why that position is a non-starter.) Let us now use the word “perception” to denote the kind of phenomenologically pregnant experience that if veridical would have a real-world object. So, in this context, a...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-044",
    "text": "We’ve already seen, at length, why this line of thought is not tenable. Now we can see the power of Russell’s position. Let A be some awareness of mine, and let O be the object of that awareness. As we’ve been emphasizing, if O is not a component of A, then there is a counterfactual world where A exists but O does not. But if O is a component of A, then there is no counterfactual world where A exists but O does not. So, in that case, O’s existence is necessary for A to have the causal properties that make it what it is. Given this, suppose that you are having a headache and you think to yourself: I wish this headache would go away. Let T be that thought (in this context the word “thought” refers to a certain kind of mental entity), and let H be the headache in question. It seems reasonable to say that T couldn’t possibly exist in a world where H did not exist. In connection with this, it seems that H is not only the object of T, but that it is itself a component of T. So given any world w there H doesn’t exist, there isn’t anything identical with T. Given any world where H doesn’t exist, there is nothing that is causally relevantly enough like T in respect of its to be T. Now we can close Russell’s argument (or, rather, our extension of it). Spatiotemporal events are individuated by their causal properties – but not by all of those properties. Any two non-simultaneous ipso facto have some causal connections. Given any event E involving some brontosaurus, E has some causal relation to everything I do. (These causal relations are not of great explanatory value, but they still exist.) But there are epistemically possible worlds where E does not occur but where my life is exactly as it is here. So spatiotemporal states of affairs are individuated by a certain privileged subset of those causal properties. (I will not attempt to give a precise definition of that subset.) Let A be an awareness that has some external object O for its object; and let C1…Cn be the causal properties individuative of A. There is a possible world where O doesn’t exist but where something x has all of C1…Cn, i.e. there is a world where A exists but where...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-045",
    "text": "Because the argument that will be given in this section is quite complicated, I would like to outline it before giving it in full. First of all, by a “singular proposition”, I mean one that has a constituent of the external world as a component. The truth of any singular proposition supervenes on that of some purely general proposition. In other words, given any proposition that has some constituent of the external world as a constituent, the truth of that proposition supervenes on the truth of some proposition that is purely descriptive – a proposition whose only constituents are universals (properties and relations). One can be acquainted with a proposition of that kind. Therefore, one can be acquainted with a proposition whose truth depends on that of some singular proposition. Indeed, what we call “singular propositions” just are general propositions of the kind in question. So, ultimately, one can be acquainted with singular propositions. For reasons that we will see, one is not often acquainted with such a proposition. In fact, acquaintance with such a proposition is probably a practical impossibility. It might even be a nomic impossibility, given interference-effects and the like. But, contrary to what Russell argues, it is not absurd to suppose that one might be acquainted with such a proposition. Let us now state the argument just outlined. We have some inclination to think of objects – e.g. rocks, trees, people – as being the basic constituents of the spatiotemporal world. This viewpoint is encouraged, though probably not wholly caused, by the fact that expressions denoting objects are semantically simple. Among the ultimate, semantically simple expressions composing a sentence, one typically finds expressions like “Socrates”, “Plato”, and the like. And in cases where expressions denoting objects have semantic complexity – e.g. “that rock over there”, “the inventor of bifocals” – that semantic complexity serves the purpose of picking out the relevant individual, not of delineating its structure. So expressions denoting objects are either semantically simple or what they complexity they have has nothing to do with the structure of the relevant object. And this surely reinforces a pre-existing tendency to think in terms of, and cognitively divide the world into, objects. But, of course, rocks, trees, and people are not the ultimate constituents of reality. To be sure, the term “ultimate constituent of reality” is a vague one, and whether x falls in its extension depends...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-046",
    "text": "The expression-type “you are tall” isn’t true or false. It is different tokens of it that are true or false. Where sentences containing indexicals are concerned, it is de rigueur to distinguish between type-meaning and token-meaning. (An “indexical” is a systematically context-sensitive component, e.g. “I”, “you”, “this”, “that”, “here”, “now.”) It follows that the distinction between sentence-types and sentence-tokens must be made universally. An utterance of “Smith is in kitchen” at t may be true while such an utterance at t* is false. This means that those utterances encode different propositions. But how his is this possible? After all, “Smith is in kitchen” appears not to contain an indexical component. That sentence is tensed, and because of the tense-marker what a token of it expresses is a function, in part, of the time of the tokening. Given any sentence-type containing a tensed verb – and this means any sentence-type belonging to natural language – the semantic content of that type is not a proposition, but is rather a function that assigns propositions to its tokens. Of course, in some cases, tense is obviously irrelevant. The tense-marker in a token of “two plus two equals four” is idle. But this is easily explained along pragmatic lines: the tense-marker may be ignored, given the obvious mathematical (not semantic) fact that temporal considerations are irrelevant to the truth-conditions of arithmetical propositions. Considerations of uniformity urge us to accept this explanation. It would be arbitrary, and also unnecessary, to say that the tense-marker in “two plus two equals four” has a different semantics from the tense-marker in “John swims every day.” In artificial extensions of natural language, one may encounter tenseless sentences. At least arguably, a written token of “2+2=4” has no tense. But considerations of uniformity demand we see the expression-type as encoding, not a proposition, but a function that assigns a proposition to tokens of that type. Sentence-types are platonic entities; sentence-tokens are spatiotemporal. We’ve seen that, where natural language is concerned, it is sentence-tokens, not sentence-types, that bear propositions. Given this, suppose we said that the expression-type “2+2=4” had a proposition for its semantic content. In that case, we would be saying that the property of being proposition-bearing was sometimes a property of the spatiotemporal and other times was a property of the platonic. But such a proposal would bifurcate the notion of literal meaning, given how deep the division is...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-047",
    "text": "Before moving on, let us discuss why the distinction between sentence-types and sentence-tokens is relevant to a work on conception. Let T be a token of “that boorish uncultured man over there (the one who’s been dominating the conversation with his unfunny jokes for the last hour) is a spy”, and suppose that Smith is the man in question. Let T* be a token of “that erudite and illuminating gentleman next to the fireplace – the one who has been discoursing in such a brilliant, and yet unassuming fashion for the last ten minutes – is a spy.” As before, suppose that Smith is the man in question. As we’ve noted, Kaplan (1989) argued compellingly that T and T* encode the very same proposition, namely Smith is a spy. So there is some individual x (namely Smith) such that, at the level of semantics, each of T and T* encodes a proposition that is true just in case x is tall. At first it seems as though Kaplan’s analysis must be wrong, given that T and T* communicate different, and non-equivalent, propositions. But in Chapter 1, we showed why Kaplan’s analysis is perfectly consistent with this fact. Notice that our explanation made heavy use of the distinction between type-semantics and token-semantics. One assigns the right meaning to T and T* on the basis of a knowledge of the relevant expression-types. So one works through type-meaning to ascertain token-meaning. As a result, what is communicated by a sentence-token is a function, at least in part, of type-meaning. A consequence is that two tokens that have the very same propositions for their literal meanings may communicate very different propositions. As we will soon see, what we just said about sentence-tokens containing demonstrative-expressions is true of sentence-tokens containing definite descriptions and, indeed, of all sentence-tokens. If we keeping in mind the distinction between type-meaning and token-meaning, a number of otherwise unexplainable facts fall into place; and, as we will now see, if we don’t keep that distinction in mind, we are forced to adopt some counterintuitive and even incoherent views.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-048",
    "text": "is non-trivial and also contingent. Much of what is generally believed about substitutivity is in need of serious revision, given what we have said thus far in this work. As we’ve seen, a token T of",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-049",
    "text": "Such a difference will occur if Smith has no knowledge of any sculpture of a dancing walrus or of anything involving the novel War and Peace.[45] Obviously the apparent difference in truth-value between sT and sT* correlates with the apparent difference in meaning between T and T*. But the latter difference is merely apparent, as we saw. The same is therefore true of the former. Each of sT and sT* encodes the bare singular proposition: Smith thinks that x is tall. In any case, given the points made in connection with the apparent (but non-actual) differences in meaning between T and T* (and between t and t*…), there is no difficulty explaining why what is communicated by sT may differ in truth-value from what is communicated by sT*. When we take into account the information through which one must compute the literal meanings of sT and sT*, it becomes clear why those tokens would inevitably convey very different propositions – that one of them would convey or suggest that the addressee knew of the existence of a dancing-walrus sculpture, while the other would not. Once we take pre-semantics into account, there is no need to assume any difference in meaning, or therefore in truth-value, between sT and sT*. Further, if we were to posit such a difference, in order to explain the apparent differences between in truth-value between those tokens, our explanation would be superfluous. Indeed, it would be in conflict with an incompatible, but adequate, explanation. What we see, then, is that many apparent substitution-failures involve no change in literal meaning (or, therefore, truth-value), and are to be understood pragmatically. More specifically, they are to be understood in terms of pre-semantics. Let us extend now this line of thought by considering the controversial topic of definite descriptions. Once again consider the sentence:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-050",
    "text": "So supposing that x is a unique phi at a given time, a token at that time of ┌the phi┐ has individual x for its sole semantic content; and no concept of x -- no Fregean sense or Russellian description – is any part of what is literally meant by such a token. If (*) is right, then a token of any sentence of the form: ┌the phi has psi┐ would either have the bare singular proposition x has psi (for the appropriate value of x), or it would fail to encode a proposition. It would mean x has psi if there were, at the time of utterance, a unique psi; and it would have no proposition for its literal meaning if there were no such individual. At the same time, for the reasons given earlier, such a token would convey the existence-claim: something x uniquely has phi; moreover, x has psi. So such a token would convey exactly the proposition that, according to Russell, is its literal meaning. The supposition that definite descriptions are singular, directly referential expressions is entirely consistent with the facts about cognitive significance that motivate Russell’s theory. In fact, that supposition explains those very facts, given the distinction between semantics and pre-semantics.[47] If (*) gives the general semantic rule for definite descriptions, then the semantics of “the richest man in America” will be given by the rule:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-051",
    "text": "Anyone who understands such a token works through that rule. So such a person knows that, in order for a token of that sentence to be correct, there must (at the time of tokening) be somebody x who is uniquely a richest man in America and, further, that any such person must be smart. So to explain why occurrences of (2) and (7) have the cognitive significances that they in fact have, it isn’t necessary to deny that occurrences of “the richest man in America” and other definite descriptions are singular terms; and it therefore isn’t necessary to suppose that such occurrences are quantifiers. So far as it seems necessary to take such a view, it is because 666 one is operating within a one-dimensional semantic system and 666 is therefore operating on the assumption that (***) and (****) are the relevant semantic rules.[49] Let us sum up. Given the distinction between semantics and pre-semantics, and between token- and type-meaning, the thesis that occurrences of definite descriptions are singular terms is easily reconciled with the facts concerning what is conveyed by sentences containing such occurrences. Given this, we can easily reconcile the supposition that definite descriptions are singular terms with the apparent difference in truth-value between:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-052",
    "text": "Given that occurrences of 2 convey 2P, even on the assumption that tokens of definite description are directly referential, it is no wonder that s2 should be capable of conveying s2NS. There is no reason why the occurrences of “Smith thinks that” in tokens of s2 shouldn’t be capable of having different degrees of scope – no reason to think that, for reasons of pragmatics, those occurrences could be given either wide-scope or narrow-scope, depending on the specifics of the context of tokening. Indeed, it would be artificial to suppose that contextual-pragmatic factors didn’t have such an effect. So our analysis explains why occurrences of s2 can communicate s2NS, without having that for their literal meaning. The “wide-scope” reading of s2 is given by s7P. We’ve already explained why tokens of s2 can convey s7P. Incidentally, the reason that s2NS is referred to as the “narrow-scope” reading is that, in it, the epistemic operator (“Smith thinks”) is given narrow-scope with respect to the existential quantifier. So the epistemic operator falls within the scope of the existential quantifier, and thus has a smaller scope than the latter. s7P is referred to as the “wide-scope” reading for the same reason mutatis mutandis. There is thus no need to advocate Russell’s theory to explain the relevant facts about cognitive significance, i.e. about what is conveyed by sentence-occurrences of the form ┌…the phi…┐ This completely undercuts Russell’s theory, at least so far as that theory’s raison d’être is that it accounts for what is communicated by sentence-tokens containing definite descriptions.[51] But not only is Russell’s theory unnecessary. It is demonstrably false. We must begin by distinguishing between semantic and conceptual analysis. A semantic analysis of an expression identifies its literal meaning. A conceptual analysis gives an analysis of that proposition itself, i.e. it identifies a proposition that is logically equivalent with the one that is literally meant, but is more perspicuous in respect of its inferential structure.[52] Given this distinction, there are two possible interpretations of Russell’s theory. We can say that he is doing semantic analysis (identifying literal meanings) or that he is doing conceptual analysis. Let us consider both interpretations, starting with the first. Consider the thesis that (2) is synonymous with (2P). For two sentences to be synonymous is, by definition, for them to have exactly the same literal meaning. It is not easy to find two distinct sentences that have...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-053",
    "text": "In general, it is very clear that, in a context where an utterance of ┌the phi has psi┐ would show linguistic incompetence, its Russellian paraphrase (┌something x uniquely has phi; moreover x has psi┐) would show linguistic competence. And, of course, the very same argument mutatis mutandis shows that, in a context where an utterance ┌the phi has psi┐ would show linguistic competence, its Russellian analogue (┌something x uniquely has phi; moreover, x has psi┐) would show linguistic incompetence. If (2) and (2P) were synonymous, then the differences between them would be as innocuous as the differences between a Southerner’s and a Northerner’s pronunciations of a given sentence. Alternatively, those differences would be as innocuous as the difference between “Smith is an enemy” and “Smith is a foe.” But (2) and (2P) are very much not interchangeable. In fact, it would be hard to think of a single context where the one would be appropriate if the other were. This cannot be chalked up to pragmatics since their non-interchangeability is rooted in facts about linguistic competence, and not in facts about sensitivity (or a lack thereof) to situational nuances.[53] A story may clarify this last point. You say to an employee: “your performance here has been less than exemplary; and I think it would be a good idea if you started clearing your desk.” Of course, what you are conveying is: you’re fired. But the employee is so unintelligent that he takes your words literally. He responds to your statement by saying (he is not attempting to be ironic or humorous):",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-054",
    "text": "The employee has shown a kind of incompetence. But it is not linguistic incompetence. He understood the literal meanings of your words perfectly well. But somebody who says (2) where (2P) is appropriate, or vice versa, is displaying linguistic incompetence. They haven’t mastered the relevant grammatical rules for those expressions. There are many contexts where uttering the one sentence would be linguistically inappropriate – where it would show that the speaker needed to take more English-classes (supposing that he were not intentionally flouting the rules of English semantics) – and where uttering the other would not. Linguistic deficiencies are, by definition, non-pragmatic. Pragmatics is the interface of literal meaning and context. A “pragmatic deficiency”, such as that evinced by the employee, does not show a failure to have internalized the relevant literal meanings, but instead shows a failure to see how those meanings interact with facts about culture, psychology, and the like. Somebody who says ┌somebody x is a unique phi; moreover, x has psi┐ where the right statement is ┌the phi has psi┐, or vice versa, is showing grammatical-semantic incompetence. It was brought up long ago (by Searle (1979) and also, I am told, by Kripke in unpublished lectures[54]) that the Theory of Descriptions is decidedly implausible when it comes to questions and imperatives. If Russell’s theory is right, then:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-055",
    "text": "If we insist on eliminating all of the definite descriptions in (8), there are three other disambiguations of that sentence. But for our purposes, we can focus on (8WS) and (8NS). The problems for Russell’s theory that we uncover in connection with these two sentences apply with extra force to more strict Russellian paraphrases of (8), such (8DWS). As Searle (1979) observed, it is hard to believe that, on any disambiguation, an utterance of (8) expresses an order that you make there be somebody standing in a certain place. Further, there are obviously many contexts where an utterance of (8WS) would show a dearth of linguistic competence and where an utterance of (8) would show no such dearth. For similar reasons, it is hard to believe that, on any disambiguation, (8) is synonymous with (8NS). In uttering (8), you certainly don’t seem to be asserting that there is a unique man in a certain location. As Strawson (1951) said, you seem to be presupposing it, not affirming it. This is confirmed by the fact that an utterance of (8NS) would show a dearth of linguistic competence in contexts where an utterance of (8) would show no such dearth. It is therefore hard to believe that (8) is under any circumstances synonymous with (8NS). Advocates of Russell’s theory argue that, so far as (8) strikes us as not being synonymous with (8NS) and (8WS), it is because we are mistaking pragmatic epiphenomena for literal meaning.[55] They argue that, after we root out the contextual factors that mediate between literal and understood meaning, Russell’s theory turns out to be in perfect accordance with the data.[56] But given that synonymous sentences ipso facto have precisely the same meanings, it is hard to see how replacing (8) with either (8NS) or (8WS) could be so far from innocuous; it is hard to see how doing so could turn a reasonable sounding utterance into an extremely strange sounding one, or how it could turn an instance of linguistic competence into one of linguistic incompetence. It is hard to see how replacing (8) with either of those other sentences is comparable to replacing “enemy” with “foe” or “heather” with “gorse.” To say that two expressions are synonymous is to make a very strong claim. Obviously intersubstituting synonymous expressions has phonetic consequences. (Tokens of “foe” sound different from tokens of “enemy.”) But it is hard to see...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-056",
    "text": "or some other, quantified generalization that is logically equivalent with each of (i)-(iii). But what we said about (2P) is true of each of these other sentences. Consider (ii), for example. Replacing an occurrence of (ii) with an occurrence of (2), or vice versa, would frequently produce a linguistically (and not just a pragmatically) inappropriate utterance where there was previously linguistically appropriate one (or vice versa). The same is true of (1) and (3) and of any other sentence that clearly expresses a quantified generalization.[59] Frege’s view",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-057",
    "text": "Frege (1892) held that definite descriptions are singular terms. But Frege’s theory is less defensible than Russell’s. Russell’s theory happens to be false of English (or so I have argued), and is thus empirically false. But it is not an incoherent theory. The same cannot be said of Frege’s theory. Frege (1892) rightly believed in what has come to known as the “principle of compositionality”[60]: the meaning of a complex expression is a function of the meanings of its constituents. A specific version of this principle relates to reference: the referent of a complex referring term is a function of the referents of its parts. (For the record, my view is that both principles are unqualifiedly correct.[61]) Let us start with our paradigm:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-058",
    "text": "This raises an important question. If the literal meaning of (2) is logically equivalent with (2P), why isn’t “the richest man in America” simply a quantifier? If Frege is right about (2), then (2) says nothing more and nothing less than (2P). In general, if Frege is right about ┌the phi┐, then ┌the phi has psi┐ is true exactly if phi is uniquely instantiated and any instance of it has psi. So any sentence of the form ┌the phi has psi┐ -- or, equivalently, of the form ┌….the phi…┐ -- answers the question ┌how many phi’s are psi’s? ┐ But in that case, ┌the phi┐ is a text-book case of a quantifier. “No person is smart” answers the question “how many people are smart?”; so do “some person is smart”, “three people are smart”, and so on. That is why “some person”, “no person”, and so on, are quantifiers.[63] If Frege is right, then “the person over there is smart” answers that very same question. (It gives the answer: “there is exactly one person over there, and any such person is smart.”) So it isn’t clear how Frege’s position amounts to anything less than the idea that “the man” (or “the richest man in America”) is a quantifier.[64] In any case, given a reasonable understanding of what a quantifier is, it is unclear why, on Frege’s view, definite descriptions are not quantifiers. Frege must deny the veritable truism a quantifier is an expression that, when conjoined with a predicate phi, answers the question ┌how many phi’s are there? ┐ It follows that Frege’s view is only as plausible as the denial of this truism. It is not hard to find support for this position. In the aftermath of Kripke, we have good reason to believe that, for some x (identical, let us suppose, with Bill Gates), the literal meaning of (2) -- or, strictly speaking, tokens thereof -- is simply:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-059",
    "text": "encodes the very same proposition as (2LM), provided that the demonstrative expression refers to Bill Gates (or to whomever the richest man in America happens to be). More generally, we have seen that a proper noun or demonstrative expression E refers to O exactly if, in virtue of having the form ┌E has phi┐, a sentence-token encodes a proposition that is true exactly if O has phi – it being irrelevant what other properties O has. So we have seen that, at least where proper nouns and demonstratives are concerned, reference is mere labeling. It isn’t describing or conceptualizing: it is mere picking out. Given this, suppose that Frege is right. Suppose that the occurrence in (2) of “the richest man in America” refers to Bill Gates, but that (2) is logically equivalent with (2P). Notice that Bill Gates is not a constituent of (2P). What is such a constituent is some concept that he uniquely falls under. Further, notice that Bill Gates is a constituent of the proposition literally meant by:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-060",
    "text": "So if Frege is right about definite descriptions, then there are two fundamentally different kinds of reference. There is the kind where, in virtue of containing a referring term, 666 a sentence encodes a proposition that has the referent of that term as a veritable constituent. (This would be Kripke-Kaplan “direct reference.”) And there would also be the kind of reference where it is not the case that, in virtue of containing a referring term, 666 a sentence encodes a proposition that has the referent of that term as a veritable constituent. (This would be Frege-style “indirect” reference.”) If a sentence contained an expression E that “referred” in the latter sense to O, that sentence would, in virtue of that fact, encode a proposition had as a constituent, not O itself, but some concept C that O uniquely instantiated; and that proposition would be to the effect that C was uniquely instantiated. If E “refers” to O, in the Fregean indirect sense of “reference”, then there is some concept C such that O uniquely instantiates C, and the proposition meant by ┌E has phi┐ is to the effect that C is uniquely instantiated, and any instance of C has phi. So that proposition would provide the very information provided by the proposition that, according to Russell’s theory, is meant by ┌t666he C has phi. ┐ But, in that case, it is deeply unclear why E isn’t simply a Russell-style generalized quantifier. For example, if Frege is right, then because it contains an occurrence of “the richest man in America”, (2) provides exactly the same information as (2P). But there would also be a kind of reference where this condition was not met. “Bill Gates” uncontroversially refers to Bill Gates. But (1) is not logically equivalent with (2P). The information provided by (1) is not is not the same as that provided by any quantified generalization. (This is subject to a qualification that we will discuss in a moment.) At the same time, if Frege is right about definite descriptions, then (2) has a great deal in common with (2P). Both answer exactly the same question, namely: how many richest men in America are there and are they smart? Further, if Frege is right, the semantic rule for (2) is: “the richest man America is smart” is true iff there is exactly one richest man in American, and any such person...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-061",
    "text": "Direct reference is not the same thing as rigid designation. Consider a demonstrative expression, e.g. “that man over there.” It refers to different people on different occasions. A fortiori it refers to different people in different worlds. It is thus a text-book case of an expression whose referent varies depending on the circumstances, and would thus seem to be a paradigm of non-rigid designation. But it is directly referential. In response, one might argue that “that man over there” is a rigid designator, on the grounds that it refers directly. But this would either be a purely terminological move – and a confusing one at that – or a case of begging the question. The referent of “Bill Gates” is not context-sensitive. Given the rules of English semantics, its reference is fixed. “Bill Gates” is also paradigm-case of a rigid designator.[66] The referent of “that man over there” is context-sensitive. Given only the rules of English semantics, its reference is not fixed.[67] If we say that “that man over there” is a rigid-designator, then we are saying that rigidity and non-rigidity are not to be understood in terms of easily ascertained and uncontroversial facts about context-sensitivity, and that they are to be understood in terms of extremely controversial and hard to ascertain facts about the constituencies of propositions. If we say that “that man over there” is rigid, on the grounds that it is directly referential, then the terms “rigid” and “non-rigid” cannot be used without prejudging the outcomes of highly theoretical semantic and metaphysical debates, and they thus cease to have any descriptive utility. So it is not a reasonable option to define “rigid” as “directly referential.” “Rigid” must continue to be defined as “such that what it refers to does not depend on the context of utterance.” But even if we set these points aside, it isn’t clear why “non-rigid designation” isn’t just a kind of quantification. Suppose that “the richest man in America” is a “non-rigid designator” and that Frege is right to think that (2) and (2P) are logically equivalent. In that case, given the arguments already presented, it isn’t clear why “non-rigid designation” isn’t just a form of quantification. In any case, as we’ve seen, “non-rigid designation” would have very little in common with any clear-cut case of reference, and it would have much in common with quantification. As we saw, if Frege is right...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-062",
    "text": "refer to the sense of the sense that it ordinarily has. But, as Davidson (1980b: 93-108) points out, this view is deeply implausible. It seems ad hoc to suppose that the occurrence of “the first person to make a fortune by selling personal computers” refers to one thing in (12), a different thing in (11), and a third thing in (1).[69] There is another problem. What is the sense of the sense of the sense of “the first person to make a fortune by selling personal computers”? The sense associated with “the first person to make a fortune by selling personal computers” is not hard to identify: it is presumably the concept (unique) first person to make a fortune by selling personal computers. But the sense (or mode of presentation) of that sense (not to mention the 666 sense of that sense of that sense) is not so easy to identify. In fact, there is demonstrably no such thing as the sense of that sense (or of the sense of that sense). Any given spatiotemporal entity can be given through infinitely many different senses. As Russell (1905) put it, “there is no backward road from sense to denotation.” If the same is true of concepts, then there is no such thing as the sense of the sense of sense associated with “the first person to make a fortune by selling personal computers.” Frege would then have to pick some specific sense out of these infinitely many. But it is hard to see how any such selection could be anything other than arbitrary, and could possibly correspond to some fact about English-semantics. To block this, Frege would have to say either (a) that he was not concerned with the actual semantics of English or (b) that, given any concept, there is some one sense through which it must be grasped. Let us consider each option. (b) is false. A given concept can be grasped in different ways, i.e. through different “modes of presentation.” In fact, this is a point that Frege himself emphasizes in the Foundations of Arithmetic (Frege 1884), and we may borrow one of Frege’s own examples to illustrate it. Consider the concept of the number zero. There are different ways of thinking about that concept. It can be thought of as the concept that is instantiated only by the predecessor of one or the concept that is instantiated...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-063",
    "text": "In the previous chapter, we saw how a failure to distinguish token-meaning (semantics) from type-meaning (pre-semantics) has led to some highly implausible semantic views. We also saw how reasonable alternatives to those views are generated if that distinction is taken into account. In this chapter, we will see how some erroneous theories about modality and conception result from a failure to distinguish semantics from what might be called “pre-pre-semantics.” Throughout this chapter we must keep in mind our point that it is always sentence-tokens that bear propositions, and that sentence-types never do so. The semantic content of sentence-type “Socrates is tall” is a rule that assigns a proposition to any given token of that type. That is why different tokens of that type can have different truth-values. (Of course, any two tokens of “one and one make two” have the same truth-value. But is to be explained in terms of the non-semantic fact that mathematical reality doesn’t change; it is not to be explained by supposing that the present-tense marker is semantically ambiguous between temporal and non-temporal meanings.[71]) As we saw, Kripke (1972) made it clear that “Hesperus” and “Phosphorous” are not quantifiers and that they are not disguised descriptions. Kripke made a related point that we have not explicitly discussed, namely: proper names (e.g. “Hesperus”, “Socrates”) are rigid designators. In other words, given the semantics of English, it is fixed what those expressions (or, strictly speaking, their tokens) refer to. Let us develop this point. (To expedite discussion, I will speak as though expression-types refer. The inaccuracies created by this way of speaking are easily eliminated.) Imagine a world W where Al Gore, as opposed to George W. Bush, is U.S. President in 2006. Given only that (in 2006) people in W refer to Gore as “the U.S. president”, it does not follow that there is a language in W whose semantic rules differ at all from those of English. But suppose that, in at least one of the languages in W, “Hesperus” refers to Mars, as opposed to Venus. In that case, we can conclude that there is some language in W that does not have precisely the same semantic rules as English. A language that is just like English except that, in it, “Plato” refers to Socrates and “Socrates” refers to Plato, does not have precisely the same semantic rules as English. Strictly speaking, that language isn’t...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-064",
    "text": "Frege’s position is not different from Russell’s, at least not in any way that is relevant in this context.[73] We know from Kripke that Frege and Russell were wrong. “Hesperus” is not a description, and “Hesperus”, unlike “the first celestial body to appear in the evening sky”, rigidly refers to Venus. Of course, the same is true of “Phosphorous.” Each of the referring terms in (2) is a label; and the structure of the proposition encoded in (2) is not a quantified, Russell-style generalization. Rather, that proposition has the form x=y. There is one last point to make before we can close Kripke’s argument. The relation of identity holds necessarily.[74] Nothing could possibly fail to be itself. Nothing could have been a numerically different object . This point can be established formally. Suppose that x is only contingently identical with y. Obviously x isn’t contingently identical with x. So if x is only contingently identical with y, then y has some property that x does not have (y has, and x lacks, the property of being contingently identical with x). So by Leibniz’s Law, x and y must be distinct. When it holds, identity holds necessarily. Any true statement of the form x=y is necessary. Let us now close Kripke’s argument. (2) expresses a true proposition of the form x=y. That proposition holds necessarily, given what we said in the previous paragraph. But (2) is obviously an a posteriori statement. It expresses a synthetic, not an analytic, claim. Empirical work was needed to establish the truth of (2). There are thus necessary a posteriori truths. Not all necessity is analytic (or a priori).",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-065",
    "text": "So what is conveyed by (2) will be exactly what Russell thought (wrongly) to be its literal meaning. What is conveyed by (2) is not a singular proposition of the form a=b. (I am switching variables for obvious reasons.) What is conveyed is a descriptively rich existence-claim. But, for reasons that we’ve discussed, what is literally meant is confined to the underlined part of (III). And you know this. You know it for exactly the reasons that you know that the literal meaning of a token of “Hesperus is lovely” is confined to the underlined part of (HLG) – or, more exactly, that it is what is confined to a certain specialization of the propositional-form corresponding to the underlined part. Of course, that underlined part is necessarily true. As we discussed, any genuine identity claim holds necessarily, if it holds at all. But we don’t have any a posteriori necessary truth here. Astronomical work was needed to ascertain the truth expressed by (III). That proposition is entirely contingent. Tokens of (2) do indeed encode necessary truths. For what is literally meant by such tokens is a true proposition of the form a=b. But what is a posteriori is not what is literally meant by (2) or tokens thereof, but is rather what is communicated by such tokens. What is a posteriori is the information through which you access the literal meaning of tokens of (2). And that information is contingent. The literal meaning of (2), on the other hand, is analytic. That literal meaning is given by a singular proposition of the form x=y. Because we are dealing with a singular proposition, we are dealing with a structure that comprises the object x and the object y. We are not dealing with a structure that comprises senses or descriptions of x or of y. Apart from the concept of equality, only x and y – the objects, not any concepts thereof – make it into that proposition. Since x is identical with y, some one object occupies the place that (in our notation) corresponds to the occurrence of the “x” and the occurrence of the “y.” And because, for the reasons just given, that object alone – without the accompaniment of any sense or description or concept – is what occupies that place, the proposition in question has the form x=x; and any proposition of that form is analytic. Of...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-066",
    "text": "In the previous chapter, we saw how, where definite descriptions and demonstratives are concerned, a failure to distinguish semantics from pre-semantics had led to some questionable doctrines. In this chapter, we have seen yet another example of that phenomenon. But here it becomes important to distinguish two very different kinds of pre-semantics. The semantics of the expression-type “that man over there is tall” is given by a rule that assigns the singular proposition x is tall to a token t of that expression, provided that t occurs in a context where somebody x is a unique contextually salient bald man. Because one must work through type-meaning to compute token-meaning, what is communicated is not (merely) x is tall but is rather: somebody x is uniquely a contextually salient bald man; moreover, x is bald. Because of this, many semantic theories – e.g. those of Frege and Russell – involve a failure to distinguish type-semantics from token-semantics. But the rule for “Hesperus” has nothing to do with the kind of descriptive information encoded in existence-claims like:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-067",
    "text": "We’ve already discussed why the expression-type “Hesperus” doesn’t refer to anything: for some x (Venus) its semantic content is a rule (a constant function) that assigns x to its tokens. Through the information borne by (HE), you learn the semantic content of the type “Hesperus.” That content is given by (HST). On the basis of your knowledge of (HST), you learn what is meant by specific tokens of “Hesperus” and, thus, what is meant by particular tokens of “Hesperus is lovely”, “Hesperus is a planet, not a star”, and the like. So as a whole, (HE) doesn’t state the semantics of the expression-type “Hesperus”: only the underlined portion does that, as we’ve seen. Rather, (HE) states the information through which you learn the semantic content of the expression-type “Hesperus.” That content, in its turn, assigns a semantic content to tokens of that expression. So if token-meaning is semantics, and type-semantics is pre-semantics, then what you learn through (HE) is pre-pre-semantics. Frege and Russell both thought that “Hesperus” had, for at least part of its meaning, some concept like last celestial object to disappear from the morning sky. This view involves several confusions. First, there is no such thing as “Hesperus” simpliciter. There is “Hesperus”, the expression-type, and there are tokens of that type. For some x, the semantic content of that expression-type is given by the proposition: tokens of “Hesperus” refer to x; and x itself is the content of such tokens. One must learn the semantic content of “Hesperus”, the expression-type, through some highly descriptive claim – some claim like (HE). As a result, what is communicated by a token of “Hesperus is lovely” is some descriptively rich existence-claim. So in terms of what it communicates, any token of “Hesperus is lovely” will, in virtue of containing an occurrence of “Hesperus”, communicate a proposition involving some concept like last celestial object to disappear from the morning sky. But that concept has nothing to do with the literal meaning of that sentence-token. Nor does it have to anything to do with the literal meaning of that sentence-type. So nothing having to do with that concept has to do with the semantics or even the pre-semantics of that token (at least not if, by “pre-semantics”, we mean what is meant by the corresponding type). Rather, that concept is part of the pre-pre-semantics of that token. The concept last celestial object to...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-068",
    "text": "Frege’s theory a conflation of three different concepts Here we need to qualify a point a just made. As we saw earlier, one often forgets the information through which one initially learned the semantics of an expression. I learn who “Smith” refers to under the following circumstance. At a certain time, in a certain place, I see a person with such and such properties; my companion points to Smith and says “that guy is Smith.” For reasons already discussed, what is relayed to me is not 666 some singular proposition of the form “Smith” names x, but is rather one of the form: at a given time and place, somebody x has such and such properties and “Smith” refer to x (or, tokens of “Smith” refer to x). Of course, I may forget that particular existence-claim and still be able to think about and refer to Smith. But so far as this possible, that is because my knowledge of that particular existence-claim has been replaced with a different one that interlocks with the first (or with a third one that interlocks with the second…). As we saw in Chapters 2 and 3, I must work through that existence-claim – that second or third or fourth…claim – to compute the meaning of “Smith is a professor” (or, by exactly similar reasoning, to computer the meaning of “Hesperus is a planet”). That existence-claim is, of course, no part of the meaning of a token of “Smith is a professor.” Nor, obviously, is it any part of the semantic content of the corresponding-type. That existence-claim constitutes the information through which I access the semantics of the corresponding type. (For some x, that semantics is given by the rule: tokens of “Smith is a professor” are true iff x is a professor.) And on the basis of my knowledge of that rule, I compute the meaning of a given xxx token of that sentence-type. So the concept person having such and such properties is no part of the semantics of any token of “Smith” or of the semantics of the corresponding type (so it is no part of the pre-semantics, in the strict sense, of such a token). Rather, that concept is, at most, part of the pre-pre-semantics of a token of “Smith” and it is, at most, part of the pre-pre-semantics of a token of “Smith is tall”, “Smith is a professor”, and...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-069",
    "text": "Kaplan’s point contains a deep insight, and it is correct as far as it goes. But it doesn’t go far enough. Frege didn’t just hold that demonstratives and definite descriptions have sense; he didn’t just hold that “non-rigid” designators have sense. He held that proper nouns, like “Socrates” and “Hesperus”, have sense. The character-content distinction isn’t really applicable to such expressions. In any case, even if it is applicable, it doesn’t explain why tokens of “Hesperus is Phosphorous” communicate non-trivial propositions. There is some x such that the semantic content of the expression-type “Hesperus” is tokens of “Hesperus” refer to x and such that the semantic content of the expression-type “Phosphorous” is tokens of “Phosphorous” refer to x. We could say that these rules are the “characters” of those expressions. But those rules are not sufficiently different to explain why tokens of ┌Hesperus has phi┐ convey propositions concerning the concept last celestial body to disappear from the morning sky or why tokens of ┌Phosphorous has phi┐ convey propositions concerning the concept first celestial body to appear in the evening sky. Those “characters” cannot even begin to explain the facts relating to the cognitive significances of such tokens. So while Kaplan is quite right to say that Frege’s notion of sense conflates character and content – type-meaning and token-meaning – that is not all that it conflates. It false conflates the information through which one computes type-meaning with type-meaning. Thus Frege’s analysis involves a conflation, not of two, but of three different notions: semantics (token-meaning), pre-semantics (type-meaning), and pre-pre-semantics (the information through which one computes type-meaning and, on that basis, token-meaning). To illustrate our criticism of Frege’s analysis, we chose to consider to a case where reference was learned ostensively. Of course, one doesn’t have to learn what “Hesperus” refers to through an ostensive definition; indeed, this isn’t likely to be how one learns that. But everything that we’ve said about cases of ostensive learning carries over to cases of non-ostensive learning. As we saw, it is always through a descriptive-existential claim that one learns what an expression E means: it is through some piece of information having the form: there is some object x having such and such properties, and tokens of E refer to x. Given this, everything that we said about cases where one learns the meaning of “Hesperus” ostensively holds in cases where one learns that meaning...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-070",
    "text": "As we’ve seen, a token of “Hesperus is lovely” may convey a very different proposition from a token of “Phosphorous is lovely.” Given what Kripke (1972) and Soames (2001, 2003) say, it is probably not an option to hold that those tokens differ in literal meaning. And it isn’t necessary to do so. It is necessary only to distinguish literal meaning from the information through which it is ascertained. It is necessary only to distinguish semantics from pre-semantics (and from pre-pre-semantics). An exactly parallel line of thought reinforces the views on extensionality that we put forth in the previous chapter. A token of “John believes that Hesperus is lovely” may communicate a proposition that differs in truth-value from the proposition that is communicated by a token of “John believes that Phosphorous is lovely.” Given what Kripke and Soames say, it isn’t an option to hold that those tokens differ in literal meaning. And it isn’t necessary to do so: that difference in truth-value is to be explained along lines similar to those used to explain the apparent difference in meaning between “Hesperus is lovely” and “Phosphorous is lovely.” Yet another threat to extensionality turns out to involve a conflation of semantics and pre-semantics (and pre-pre-semantics). Given what Kaplan (1989) says, a token of “he is tall” and “you are tall” have the same literal meaning if the occurrence of “he” co-refers with the occurrence of “you.” In Chapter 1, we explained why Kaplan’s view is consistent with the fact that those tokens convey very different propositions. A token of “John believes that you are tall” may convey a proposition that differs in truth-value from the proposition conveyed by a token of “John believes that you are tall.” But given obvious extensions of what we said in Chapter 1, that is perfectly consistent with the supposition that those tokens have the same proposition for their literal meaning. And given what Kaplan (1989) says, it is probably necessary to suppose that they have the same literal meaning. Yet another threat to extensionality is neutralized. There is no shortage of authors who think that truth-value can be changed by intersubstituting co-referring definite descriptions, and who thus think that not all contexts are extensional.[75] The arguments in favor of that view are exact analogues of the arguments in favor of the view that truth-value by can be changed by intersubstituting two co-referring proper names...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-071",
    "text": "Some authors (Donnellan 1974, Kaplan 1989) hold both that we can refer to things to which we are not causally connected and that we must be causally connected to a thing in order to think about it. They have dealt with this situation by saying that we don’t grasp the proposition semantically encoded in N1. We are not causally connected to Brown, at least not in the right way. Therefore we cannot think about him, and thus cannot grasp the proposition that is literally meant by (N1). Given what we’ve said in Chapter 3, this reasonable-seeming view should be reconsidered. (I say “reconsidered”, not “rejected”, because there is a certain truth in it, as I will try to show in this chapter.) In many cases, our ability to think about a thing involves our having a certain causal relation to that thing. But we’ve seen that, in every such case, the causal connection between subject and object is simply an ingredient in the subject’s knowledge of the right kind of uniquely individuating description. Your acquiring a concept of Fred by seeing him consists in your acquiring knowledge of an existence claim of which Fred is the unique verifier. If you acquire a concept of Fred by being told about him, or by hearing about him, that too consists in your acquiring knowledge of an existence claim of which Fred is the unique verifier. In all cases, then, knowledge of a thing consists in knowledge of a uniquely individuating description that applies to that thing. In some cases, a causal connection between subject and object is an ingredient in that knowledge. But it is never the causal connection per se that constitutes conception; it is always knowledge of a uniquely individuating description. Obviously we can know of a uniquely individuating description that applies to Brown (Newman1). So given only what we said in the last paragraph, it seems wrong, or at least arbitrary, to say that we can think about Socrates but that we cannot think about Newman 1. For the very thing that enables us to think about Socrates would seem to be present in the case of Newman 1.[78]",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-072",
    "text": "Nonetheless, there is a significant difference between the sort of concept that we have of Newman 1, on the one hand, and the sort of concept that we have of Socrates or of those with whom we are personally acquainted. Donnellan (1974), Evans (1982), and others are not entirely wrong to put those concepts in different categories. And Donnellan and Evans are right to see the relevant difference between them as lying in the fact that, in the one case but not the other, a causal connection between subject and object is involved. A proper understanding of this issue is to be found in an insight of Evans’. The argument I’m about to give is not exactly Evans’ own. But it owes much to his insights.[79] Evans (1982: 65) held that, in order for x to be able to have thoughts about y, x must have a “discriminating conception” of y. Unlike us, Evans did not hold that such knowledge consists in knowledge of a uniquely individuating description of the kind described earlier. But, like us, he rejected the idea that, by itself, a causal connection between x and y could possibly enable x to have thoughts about y. (He referred to the idea that, by itself, such a connection could realize conception as the “photograph model.”) And, like us, Evans held that, although such a causal connection has an important role within conception, it must be embedded within knowledge of a certain kind if there is to be any concept. What, according to Evans, is the nature of that knowledge? Evans (1982: 143-191, 1985: 291-321) rightly says that spatiotemporal individuals are distinguished from one another by their locations (in both space and time). Of course, Socrates is not individuated by the fact that, at some specific moment, he is in some specific place. In other words, he is not who is he is in virtue of the fact that at time t he is in place p. After all, he might have been somewhere else at that time. (In fact, given any time t during which Socrates existed, if Socrates was at place p at t, Socrates might have been somewhere other than p.) But every spatiotemporal individual has unique space-time co-ordinates; and for this reason, and others, it seems reasonable to suppose that distinguishing one individual from the next consists in, or at least involves, having some conception...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-073",
    "text": "I am going to give an Evans-inspired answer to this last question. (But even though it is Evans-inspired, my answer is not one that Evans himself provides. In fact, given his other views, it is not one that he could provide.) First of all, spatiotemporal relations are causal relations. E1 temporally precedes E2 iff there is a possible causal process (e.g. a light-ray) that begins with E1 and ends with E2 (Reichenbach 1958, Sklar 1974, Salmon 1984). Indeed, it would make no sense to say that two events were part of the same temporal order unless either (i) they were connected by a (possible) causal sequence or (ii) each of them connected by such a sequence to some third event. Further, it would make no sense to say that two events were part of the same space unless either (i*) they were connected by some (possible) causal sequence or (ii*) they were both connected by some sequence to some third event (Reichenbach 1958, Sklar 1974, Salmon 1984). Although recent, and extremely sophisticated, developments in theoretical physics were needed to force these facts on our consciousness, it is hard to believe that we have not always known them at some intuitive level. Any person’s mind recoils at the idea of two events having temporal or spatial relations but being necessarily causally divorced both from each other and from any third event. Spatiotemporal relations are inseparable from causal relations. It seems reasonable to believe that, at some cognitive level, everyone has an awareness of the intimate connections between spatiotemporal location, on the one hand, and causality, on the other. Indeed, it seems reasonable, if not mandatory, to suppose that an awareness of this constitutes a vital part of our “conceptual scheme” – of our way of processing the disturbances of our sensory surfaces and, subsequently, of our way perceptually and cognitively the world. Of course, this knowledge is not discursive, or even conscious.[81] But we wouldn’t expect it to be conscious, given that this knowledge is constitutive of the apparatus that generates perceptions and other contents of consciousness. This knowledge is part of our cognitive framework; it is not a cognitive production. Anything that is generated by consciousness, or a fortiori by discursive thought, presupposes that framework. So the knowledge in question is not to be found at the level of conscious or, more generally, personal mentation.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-074",
    "text": "We thus have three facts to work with. First, spatiotemporal relations are closely bound up with causal relations. Second, at some level, everybody knows this. Third, spatiotemporal individuals are distinguished from one another by their spatiotemporal co-ordinates. Before we can close the argument, there is a fourth point to make. Ultimately, one’s cognitive “map” of the world is egocentric. In this respect, cognitive maps (so-called) are fundamentally different from the maps produced by cartographers and astronomers. While there is a sense in which maps of the latter kind are egocentric, it is entirely different from the sense in which cognitive maps are egocentric. Right now let us say exactly how the maps produced by professional map-makers are egocentric. In a moment, we will see why the egocentricity of such maps is of a much more superficial kind than that characteristic of cognitive maps. Even if you are an extremely knowledgeable geographer or astronomer, you must ultimately understand the location of a given country, or a given galaxy, in terms of something which is given to you ostensively (perceptually). The difference between somebody who is knowledgeable about geography and somebody who is not is that the former is able to put his concept of this place [the place where I, the knowledgeable geographer, am] into a much wider context than the person who doesn’t know anything about geography. Nobody understands the layout of Earth’s surface (or of the Solar System or of the Cosmos…) in completely non-egocentric terms. The astronomer (or geographer) can integrate his thoughts of the form …this place [the one I am occupying right now]…into a much wider body of information than the astronomically (or geographically) uninformed. But, in the end, the astronomer must begin with some kind of purely perceptual, and thus egocentric, interface with his environment. So every cognitive map of the world, no matter how panoramic it ends up becoming, begins with the egocentric phenomenon of sense-perception. Whenever one locates an event in space-time, one does so in terms that are ultimately egocentric. From these points, it follows that an event’s (or object’s) spatiotemporal relations to one another are nearly enough indistinguishable from its causal relations to one (or, at least, from a certain subset of its causal relations to one). To locate an object in space time – to establish its spatio-temporal position relative to one – is to know of some causal connection...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-075",
    "text": "Let us briefly recall what we said about (*). Let us suppose that Smith is the person referred to as “this guy” in (*). (We will set aside the issue of why is being referred to as “Fred.”) We saw in Chapter 3 that, in virtue of knowing the truth of utterance of (*), you (a) know the truth of some existence-claim that Smith uniquely satisfies; you (b) are at the receiving end of a very special kind of causal-process (one that Dretske (1982) would describe as “information-transmitting”) that begins with Smith; and, most importantly, you (c) have a concept of Smith. (**) is not like this. Suppose that Smith is the tallest spy and that Jones knows the truth of (**). We would be reluctant to say, on those grounds alone, that Jones had a concept of Smith in virtue of knowing (**).[83] At the same time, in virtue of knowing E, x does know some claim that Smith uniquely satisfies. It is not the case that, in virtue of knowing (**), Jones is causally connected, in a significant way, with Smith. (He is not, to use Kaplan’s (1968) expression, en rapport with Smith.) But it is the case that, in virtue of knowing (*), one is causally connected with Smith. So the difference between having and lacking a concept can come down to down the presence or absence of a certain kind of causal connection.[84] But philosophers of an externalist turn of mind over-react to this. They say, or at least gravitate towards the position, that concepts are to no degree descriptive and are to be understood in strictly causal terms (Fodor 1998, Dretske 1982). They say that concepts are related to their objects in basically the same way that discolorations on a photographic plate are related to the events that caused those discolorations. In any case, the latter relationship is taken as a kind of model of the former. But we’ve seen why, in addition to being radically counterintuitive, this reaction is demonstrably false.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-076",
    "text": "The right reaction, I propose, is to say this. To have a concept of an object is not just to know the truth of some claim of the form something uniquely has phi that x satisfies. This is part of the story, but not the whole of it. The existence-claim in question must be such that in virtue of knowing it, one is able to integrate the verifier of that claim into one’s cognitive map of the world. It is not the case that, in virtue of knowing (**), Jones has the kind of information about that thing that would enable him to integrate Smith into his cognitive map. That is why a knowledge of (**) does not give one a concept of Smith. It is the case that, in virtue of knowing (*) (or the relevant occurrence thereof), Jones has the kind of information about that thing that would enable him to integrate Smith into his cognitive map. That is why a knowledge of (*) does give one a concept of Smith. xxx In general, for x to have a concept of y is for x to know the truth of some existence claim E such that (i) y uniquely satisfies E and that (ii) x’s knowing E involves his being embedded in a certain kind of causal relationship with y and, finally, such that (iii) in virtue of knowing E, x is able to assign a location to y in his “cognitive map.” How this analysis applies to objects that are not directly known through sense-perception",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-077",
    "text": "Of course, there are cases where x’s concept of y is not derived from a perception of y itself. Consider my concept of Socrates. By itself, that concept gives me no information about Socrates’ spatiotemporal co-ordinates relative to me. So, by itself, that concept doesn’t tell me how Socrates fits into my cognitive map. But this does not ultimately pose any problem for our analysis of conception. Suppose that my concept of Socrates consists in my knowing existence claim E*. For reasons we discussed in Chapter 3, E* will be such that, in virtue of my knowing it, I will be in a specific sort of causal relation to Socrates. I will be at the receiving end of what some philosophers refer to as an “information-transmitting”[85] sequence S beginning with Socrates and ending with myself. So even though my knowledge of E* does not by itself enable me to integrate Socrates into my cognitive map, in virtue of knowing E*, I nonetheless have the information I need to effect that integration. Because my knowing that description involves my being in a very specific sort of causal relation to Socrates – albeit one that may be very long and circuitous – my knowing that description puts me in a position to integrate Socrates into my cognitive map. So, after a fashion, Kaplan (1968), Dretske (1982), and Fodor (1990) are right. To have a concept of Socrates, I do need to be at the end of a certain kind of causal process that begins with Socrates. But contrary to what Fodor holds, this is because my concept of Socrates consists in knowing some existence-claim E such that, first, Socrates uniquely satisfies E and such that, second, in virtue of knowing E, I am causally connected (in the just mentioned way) with Socrates. So my causal connection with Socrates is a mere constituent of my concept of him. My having that connection is a pre-condition for my grasping a certain description that Socrates satisfies; and my concept of Socrates is identical with my knowledge of that description, and not with that causal connection. The reason why a causal connection is necessary is that, without it, I cannot integrate any descriptive knowledge that I have of Socrates into my “cognitive map” of the world. Let me now define that term: the motivation for much of what was just said will emerge in the process...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-078",
    "text": "By a “cognitive map”, I am not referring to a theoretical distillation of scientific findings concerning the locations of individuals in the space-time manifold. Every creature having a minimum of cognitive sophistication – every creature capable of perception and action – is able to orient itself with respect to other individuals in its immediate environment, and is thus able to represent objects and states of affairs as having locations, in both space and time, relative to itself.[86] This ability is not the result of empirical inquiry. Rather, it is a pre-condition for such inquiry. Indeed, it is hardly distinguishable from a creature’s ability to have the perceptions through which empirical knowledge is acquired. Since the cognitive processes mediating perception are sub-personal, the same is true of the cognitive map in question. There is a marked difference between, on the one hand, the cognitive maps that underlie our most basic dealings with the world and, on the other hand, the maps that cartographers and astronomers produce. Consider a map of the surface of the Earth. If that map is to give you any information, you must be able to correlate some item on that map with some location that is given to you directly. You must be able to have a thought of the form “this place [referring to the place one is occupying] is there on the map” (Evans 1982: Chapter 6). In general, to interpret a map, you need some kind of a reference-point in your own perceptual experience. You need to have some independent grasp of at least one of the places represented by the map. Otherwise the map gives you, at most, the locations of the items depicted on it with respect to each other, but not with respect to you. And in that case, of course, the “map” in question isn’t a map at all, at least not from your viewpoint, since it cannot tell you where you are on the map. So to understand any map – even one of the kind that cartographers and astronomers produce – you must be able to correlate at least some point on that with an indexical or “egocentric” understanding of your own. Nonetheless, the maps of cartographers are fundamentally different from your cognitive map. The difference is that, notwithstanding what we just said, the former are fundamentally non-egocentric, whereas the latter is fundamentally egocentric. As long as you...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-079",
    "text": "It is true that, in virtue of knowing the truth of (****), Jones has knowledge that would give him a maximally precise fix on the spatiotemporal location of Smith. But it is relative to the non-egocentric maps created by cartographers that Jones’ knowledge of (****) would give him this information. It is not relative to the egocentric map that is fundamental to our cognitive dealings with the world. Our analysis says that knowledge of (****) constitutes a concept of Smith only if, in virtue of having that knowledge, one can integrate Smith into one’s cognitive map. So this objection misses the mark. Why the causal story, rightly understood, does not help content-externalism",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-080",
    "text": "We’ve seen that, in at least some cases, a causal connection between x and y is integral to x’s concept of y. This might be seen as giving credibility to content-externalism. But this would not be the right reaction to have. Suppose that, on some occasion, Jones sees Smith and, strictly on that basis, forms a concept of him. Let C be that concept. C is as clear-cut and extreme a case as there is to be found of a concept’s having a causal component; from a content-externalist’s viewpoint, C is a paradigm. Even in a situation where Smith doesn’t exist, Jones could have a mental state that is identical with C in respect of content and (what follows) in respect of causal properties. Jones could have C even if Smith didn’t exist. We’ve already seen why. The content of C does not have the form: Smith has phi. It has the form there is something x having such and such properties over in that place…So the content of C is not object-involving with respect to Smith. That content is given by an existence claim which, under the circumstances, Smith uniquely satisfies. There is thus no reason why C couldn’t exist even if Smith didn’t. So even though, in virtue of having C, Jones is causally connected to Smith in a very specific way, C consists in Smith’s having knowledge of a description that Jones uniquely satisfies and that is not object-involving with respect to Jones. Of course, the kind of concept that, in the story just told, Smith has of Jones is, for content-externalist, a paradigm-case of a concept. So the falsity of content-externalism is evident even when we consider the concepts that best conform to its analysis. Chapter 7 Concepts as knowledge of series of interlocking existence-claims",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-081",
    "text": "Thus, for reasons of a strictly logical nature, the existence claim through which I access Bob must change. The changes in question merely register the change in my chronological perspective, so to speak, on Fred – just as the changes in the sensory image through which I see the house register the changes in my spatial perspective on the house.[89] There is another reason why one’s ability to think about x involves dropping certain existence claims and replacing them with others. As we discussed, one typically forgets the existence claim through which one initially accesses an object. I have absolutely no recollection my first encounter with my friend Larry or of the lamp I am now seeing. As we saw earlier, one’s having a concept of an object involves having knowledge of a series of interlocking existence-claims. One’s knowledge of a given existence-claim can be dropped without destroying the concept, so long as that knowledge is replaced by knowledge of a new existence-claim that interlocks appropriately with the first. Here is an example. I meet Fred by learning the truth of (1). A few days pass, and my knowledge of (1) has thus been replaced with a knowledge of (2). I then see Fred and recognize him on the basis of this knowledge. This time Fred is wearing a loud sportcoat and an oversized bow-tie. So he is given to me through some existence claim like:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-082",
    "text": "Now that I can access Fred through (3), I can drop my knowledge of (2). Here is where we must go beyond what we have previously said about concepts. We don’t want to say that I used to have one concept of Fred, and I now have a different one. Thus, we don’t want to say that my concept of Fred used to be identical with a knowledge of (2) and is now identical with a knowledge of (3). Such a view simply wouldn’t be true to our way of speaking. It would be like saying that I am not literally identical with the person I was yesterday, since I am now wearing different clothes. The concept I now have of Fred is numerically identical with the concept I had of him a few days ago. So, strictly speaking, a concept is not identical with knowledge of a uniquely individuating description of the sort previously described. To have a concept of x is to have knowledge of a series of existence claims E1…En such that, for each i, x uniquely satisfies Ei and such that Ei+1 interlocks, in the way previously described, with Ei. In fact, even this is really only an approximation. To produce a more precise analysis of conception, we must begin to state the qualifications to which the analysis just proposed is subject. First of all, as we’ve stressed, the relevant existence-claims cannot merely be such that they are satisfied uniquely by x. They must be such that, for each i, in virtue of knowing Ei, one has the kind of uniquely individuating knowledge that enables one to integrate x into one’s “cognitive map.” As we’ve seen, this means that, in virtue of knowing Ei, one has a mental state that is caused, in a rather specific way, by x (or, more accurately, some state of affairs comprising x). Second, it obviously isn’t necessary that there be any time at which the subject knows all of E1…En. The whole point of our analysis is to accommodate the fact that one can know all but one of them while still having a concept of x. In light of these points, a more correct statement of our analysis of conception would be this: one has a concept of x at time t, iff there is some sequences of existence claims E1…En such that E1…En interlock in the way previously...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-083",
    "text": "We’ve seen that, in order to be able to think about x, one must be able to cognitively single x out, and this involves having “discriminating knowledge” of x, to borrow an expression of Gareth Evans. But having such knowledge is different from knowing x’s identity. I can have a concept of x without knowing who or what x is. Evans made this point clearly. Let us assimilate that point into the structure constituted by our analysis. Suppose that, for five years, I live next a man whom I know as “Bob.” I am on good terms with Bob, and we occasionally have an amicable cup of coffee together. During such get-togethers, we exchange no substantive information, and I thus learn little about Bob. One day I am at the beach with a friend, and I see Bob. Pointing to Bob, my companion asks me “do you know who that person is?” In this context, the answer is “yes.” I recognize the man at the beach as my next door neighbor. But a few weeks later, two stern-faced F.B.I. agents come to my door. They aggressively tell me that “Bob” is the head of the world’s largest drug-cartel and that he has also been selling weapons to various para-military organizations around the world. Of course, I didn’t know any of this, and I want to make it clear to the agents that I had no part in Bob’s malfeasance. So I say “I had no idea who he was.” In saying this, I am telling the truth. I really had no idea who my next door neighbor was; I had no idea that he was such a evil-doer. So there is some x such that I am truthfully telling the F.B.I. agents that I do not know who x is. But how can this be? After all, when I was at the beach I truthfully said, pointing to Bob, “yes, I know who that is.” So, in that context, there is some y such that I am truthfully telling my companion that I do know who x is. The problem is that x is identical with y. So it would seem to follow there is some object z such that I do know who z is, and such that it is not the case that I know who z is. A paradox. But there is no paradox. There is some...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-084",
    "text": "Now we must broach a nest of issues relating to Gareth Evans’ important work on conception. Up to a point, Evans’ system coincides with ours. Evans is careful to distinguish semantics from epistemology. He is a direct reference theorist. In his view, there is some x such that “Socrates was bald” encodes the singular proposition x was bald. Like us, Evans believes that, at the level of semantics, “Socrates” is completely non-descriptive and is a mere label. At the same time, Evans is very aware that this singular proposition cannot be grasped in a vacuum – that it must be grasped through other information. He is aware this intermediary information is replete with descriptive content. In this respect, his system coincides with ours. There are other important similarities between our system and Evans’. Like us, Evans rejects the idea that conception can be understood in strictly causal terms. So he rejects the idea, advocated by Fodor, that concepts are related to their objects in more or less the same way that the discolorations on a photographic plate are related to the events that caused those discolorations. He thus rejects what he aptly refers to as “the photograph model” of conception.[90] Like us, Evans believes that for x to have a concept of y (where y is a spatiotemporal individual) is to have knowledge of a certain kind. In Evans’ view, x must have “uniquely discriminating knowledge” of y. This means that x must know of at least one respect in which y is different from all other individuals. But, at this point, Evans’ system diverges from ours in a number of important respects. First, according to Evans, it is not generally true that x’s having a concept of y consists in x’s having knowledge of such an existence claim. Evans concedes that, in some cases, this is what conception consists in. But he does not think that it always, of even generally, consists in this. So Evans agrees with us that x’s having a concept of y consists in x’s being able to cognitively y distinguish from all other individuals. But Evans thinks that this ability does not, at least not as a rule, consist in x’s knowing some existence claim that y uniquely satisfies.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-085",
    "text": "Why does Evans think that, in general, a concept of y does not consist of knowledge of an existence claim that y uniquely satisfies? First of all, he believes that demonstrative identification is not a kind of descriptive identification. His reasoning is best introduced through a bit of fiction. I am looking at Smith, and I am not looking at any other person. Prior to this, I had no concept of Smith. I am thus acquiring a concept of Smith from this perception. At this time, Smith is the sole person who is .00000565 light-years from me. Even though Smith satisfies the existence claim there some somebody x such that, at time t, x is .00000565 light-years from JM, I obviously don’t think of Smith in those terms – nothing having to do with light-years is any part of my concept of Smith. Of course, Smith’s being that distance from me is an important fact about my concept of Smith; it is an important fact about my acquisition of that concept. But that fact isn’t represented within my concept, at least not in the sense that my concept incorporates knowledge of some existence claim describing that fact. So, Evans concludes, when we distinguish facts about our concepts from facts about what is represented within them, we see that there is no warrant for a descriptivist analysis of concepts acquired through demonstrative identification. [91]",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-086",
    "text": "Obviously the basic distinction Evans is making is correct. Not every fact about a concept is represented within that concept. (My having a concept of Napoleon involves many facts involving electrons. But the concept electron is no part of the content of that concept.) But Evans’ application of this truth seems incorrect. Look at some object – at (say) some tree in your vicinity. So far as it can be expressed in language, the content of that perception is not, as we’ve seen, given by any noun-phrase; it isn’t given by “a tree” or “that tree” or anything of the sort. So far as it can be put in words, that content is given by a sentence; and that sentence is existential in character. We have seen that, in general, our perceptions make us aware of objects by apprising us of existence-claims that those objects satisfy. Given this fact, Evans’ argument immediately implodes. As we will now see, this fact also undermines some important component of Evans’ analysis of conception.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-087",
    "text": "Evans says that demonstrative-thoughts – the thoughts that prompt one to produce sentence-tokens like “that tree over there is lovely” and “you are a scoundrel” – are “Russellian” with respect to the objects that are demonstratively identified. (In this context, “thought” means “cognitive episode”, not “proposition.”) What does this mean? It means that the content of the thought behind an utterance of “you are a scoundrel” that is addressed to Smith has Smith as a constituent, the same being true mutatis mutandis of the thoughts behind “that tree is lovely” and all other non-empty utterances containing demonstrative expressions. (By a “non-empty” utterance, I mean one that doesn’t contain any terms that are supposed to have a referent but don’t in fact have one, e.g. an occurrence of “that man over there” in a context where there is no man in the place in question.) Here it is important to make a distinction. We have argued that Smith himself is a constituent of the literal meaning of an utterance of “you are a scoundrel” that is addressed to him. Evans agrees with us about that. But we have also argued that Smith is not a constituent of the content of any thought that you have. Evans sharply disagrees with us about that. He is saying that, under the circumstances just described, Smith himself is a constituent of the content of a thought of yours. On the basis of this view, Evans draws an extraordinary and, I will argue, false view about mental representation. Suppose you are looking at Smith and are thinking the thought that, under those circumstances, would lie behind an utterance of yours of: “that guy is tall.” Let T be that thought, and let S be the situation just described. (T is not meant to be the proposition that is semantically encoded in an utterance that you would make in S. T is the thought behind such an utterance.) Now consider a hypothetical situation S* that is qualitatively just like S except that, in S*, you are hallucinating, and there is no man in the place at which you are looking. So in S*, you aren’t seeing Smith. Apart from some air molecules, the relevant part of space is completely empty. According to Evans, in S*, you don’t have T. So, in S*, your mental state (leaving aside facts about its external causes) is just like your mental...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-088",
    "text": "Let us now discuss a corollary of Evans’ view. Let S** be a situation that is just like S except that, in S**, it is Brown you are seeing, not Smith. (So, in S**, you are not hallucinating.) Of course, given how we’ve set things up, it follows that, in S**, Brown appears to you in exactly the way in which, in S, Smith appears to you. Here is Evans* view. There is some thought T** such that, in S**, you are having T** and such that, in S, you are not having T**, where T** is a thought that is Russellian with respect to Brown. For reasons exactly similar to those given in connection with S*, Evans’ view here is false. There is no thought that you are having in S** that you are not also having in S and also in S*. Why does Evans believe that demonstrative thoughts are Russellian? His argument is simple. Suppose you point to Smith and say “that guy is tall.” Let t be this utterance. Let us now state Evans’ premises.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-089",
    "text": "Premise 3: Understanding t consists in knowing which proposition it expresses. Knowing this involves grasping that proposition. So there is some proposition P such that you understand t only if you grasp P. Premise 4: P is the proposition that one has in mind when looking at Smith and thinking of him that he is tall, i.e. P is the proposition that is the content of demonstrative-thoughts that one has when the relevant demonstratum is Smith.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-090",
    "text": "Two things follow from these premises. First, Smith is a constituent of P; in other words, P is object-involving with respect to Smith. Second, the demonstrative-thought behind t is Russellian with respect to Smith. Of course, what we said of that thought is true of every demonstrative thought. (In the foregoing argument, t may be replaced with any token t* of a demonstrative-utterance, so long as the demonstrative in t* is not empty.) Let us evaluate this argument. First of all, it is valid. Given premises 1-4, Evans’ conclusion follows. Further, the first two premises are obviously correct. The problem lies in the other two premises. Premise 4 is false. Premise 3 is ambiguous, and the argument fails on the relevant disambiguation. We’ve seen why premise 4 is false. Let P* be the proposition that lies behind your utterance of t. So P* is a proposition that you grasp, and your grasp of P* is what motivates you to utter t. We’ve seen that P* is not a singular proposition of the form x is tall, and that P* doesn’t have Smith as a constituent. P* is some existential proposition that Smith satisfies, but of which he is not a constituent. There is undoubtedly some sense in which premise 3 is true. But that premise is ambiguous. The reason is that, given any utterance, there are two different things it could mean to say that so and so “knows which” proposition is meant by that utterance. This ambiguity corresponds to the distinction between knowledge by acquaintance and knowledge by description. Understanding a sentence-token always involves having some kind of knowledge of the proposition which it encodes. But more often than not, that knowledge is knowledge by description, not knowledge by acquaintance. Let Green be an arbitrary person. We’ve seen, time and time again, that if O is a constituent of the external world, Green can’t just think O. He can think about O only by way of his knowledge that some existence claim E is uniquely satisfied. (Of course, O must be the thing that satisfies E.) In Green’s case, let something x has psi be the relevant existence claim. So Green grasps O by knowing that something uniquely satisfies the claim something x has psi. In other words, Green grasps O by knowing the truth of the claim: something x uniquely has psi. So far as Green can grasp...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-091",
    "text": "Thus, in so far as Green grasps the singular proposition O has phi, he grasps it by grasping some non-singular existence claim – some existence-claim that doesn’t presuppose O’s existence. At the same time, there is a clear sense in which (#) singles out or describes the relevant proposition. So there is a sense in which somebody who knows the truth of (#) grasps O has phi. Given any true existence claim, the truth of that claim supervenes on the truth of some singular proposition. We might describe the latter as the “truth-maker” of the former. (This is consistent with our earlier use of this terminology.) O has phi is the unique truth-maker of (#). So somebody who recognizes the truth of (#) is thereby grasping, and also recognizing the truth of, (#). The sense in which such a person recognizes the truth of (#) is identical with the sense in which one recognizes the truth of some proposition about Socrates if one believes the proposition: somebody or other was a greatest philosopher to die of hemlock poisoning, and any such person believed in the existence of abstract objects. So there is a clear sense in which one can believe a proposition to be true without grasping exactly that proposition. Grasping a proposition involves singling it out. If one knows a proposition by description, one has singled it out. Thus, one needn’t be acquainted with a proposition to single it out. Let t# be an utterance of “that thing is green”, where t# is accompanied by an ostension of O. The proposition encoded in t# is O is green. It is a datum that people can understand t# . Finally, it is a datum that this consists, at least in part, in associating that utterance with the right proposition. (So Green understands t# only because he can associate it with the right proposition.) Evans is right about all of this. But Evans is wrong to think that understanding t# consists in being acquainted with O is green and then associating it with t#. It is possible to be acquainted with that proposition. It can only be known by description. Here we need to head off a possible confusion. We saw earlier (in Chapter 3) that there is a descriptive proposition P such that one can be acquainted with P such that P is true iff O is green is true....",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-092",
    "text": "A related position of Evans’ is similarly fallacious. Let W* be a world where Descartes never existed, but that is otherwise just like our world. So your condition in W* at time t is identical with your condition in our world at t, at least in so far as this possible given that Descartes never existed in W*. Now consider any one of the various beliefs that you have in this world about Descartes – e.g. your belief that he was French. Evans’ holds that, in W*, you simply cannot have that thought. So far as, in this world, your thoughts concern Descartes, you simply fail to have thoughts in W*. So far as a mental event of yours in this world concerns Descartes, the corresponding mental event in W* fails to constitute a thought. Of course, from a psychologist’s standpoint there would be no difference between those events (unless you implausibly hold that, in order to psychoanalyze someone, you need to know facts about early modern French history). Whatever intelligence, and xxx whatever neuroses or psychoses, were implicated in the one the one case would be equally implicated in the other. But, according to Evans, one of those mental events would be a thought, whereas the other would not. Evans would not disagree with our contention that, from a psychologist’s viewpoint, your situation in W* would not (in virtue of Descartes’ non-existence there) be different from your situation here.[92] His position seems to be the category thought is not a psychological category. (This brings us an interesting general fact about content-externalist: it makes facts about representational content be causally, and therefore psychologically, irrelevant.[93] We will explore this in the next section.) Why does Evans hold that, for each Descartes-thought that you have in this world, you are shooting a blank – failing to think anything – in W*, even though your psychological condition here is identical with your condition there? Evans’ argument for this is similar to the argument that he gives in connection with demonstrative-thoughts (here is a summary):",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-093",
    "text": "The truth is that there is a way to circumvent that counterintuitive xxx and (so I have argued) incoherent conclusion. As we saw in Chapter 3, one thinks about Descartes through the right kind of uniquely individuating description. And, as we also saw, this is perfectly consistent with direct-reference-theory, contrary to what has been widely been assumed.[94] Psychology versus epistemology",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-094",
    "text": "Our discussion of Evans brings to light an incoherence that lies at the center of content-externalism. Let B be the brain-state or pattern of neural stimulation that realizes your belief that 13 is a prime number. In virtue of being such a belief, B has certain causal powers. For example, it has the power to generate a belief on your part that there is a prime number greater than ten. It is thus a matter of empirical fact that, in virtue of its having a certain content and thus in virtue of its being a thought of a certain kind, B has certain psychological properties that it would not otherwise have. Given this, it is not an option to deny that, in virtue of being a thought, B is a certain kind of component of one’s psyche. It would be deeply implausible to say that my belief that 13 is prime is object-dependent with respect to some constituent of the external world. Surely a brain in a vat that was just like mine would be capable of having arithmetical thoughts. Surely an envatted brain that was an atom-for-atom duplicate of Gauss’s brain would have at least some mathematical intelligence, and would therefore be able to grasp mathematical truths. There thus doesn’t seem to be any possibility of there being a pseudo-thought that was psychologically just like my actual thought that 13 is prime; and this, for the reasons given a moment ago, means that content is causally potent, at least in some cases. But, as Stich (1978) says, it seems deeply arbitrary to suppose that content sometimes has causal powers and sometimes doesn’t. That would be like saying that water is sometimes H2O and sometimes isn’t. Content-externalism is guilty of exactly this form of arbitrariness, given that content-externalism sometimes robs content of causal potency, and given that content at least sometimes has causal powers. A content-externalist could give the following response to this:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-095",
    "text": "You say that content is always potent if it is ever potent. But this is far from self-evident. Here is what I would propose, in light of the facts that you cited a moment ago. It is sometimes, but not always, the case that in virtue of having representational content, something x has causal powers that it wouldn’t otherwise have. In virtue of being a belief that 13 is prime, something x falls into a certain psychological category. But it is not the case that, in virtue of being a belief that Alpha Centauri is lovely, something x falls into a psychological category. The motivation for this view would be as follows. Let t be some Alpha Centauri-thought of yours. (So t is object-involving with respect to Alpha Centauri.) No thought with t’s exact content can occur in a world Alpha Centauri doesn’t exist. But in such a world, you could still have a thought t* that was causally just like t. The differences in content – the differences in respect of what kind of thoughts they were – between t and t* would thus be without causal or, therefore, psychological consequence. (After all, psychology is an empirical discipline, and psychological categories – like all categories employed in natural science – are causal.xxx) There would be no psychological differences between t and t*, even though they have different contents. xxx So, to close the argument, in some cases, a thing’s being a thought of a certain kind is psychologically pregnant, and in other cases it is not. In virtue of being a thought that 13 is prime, B falls into a certain psychological category that it wouldn’t otherwise fall into. But it is not the case that, in virtue of being a thought that Alpha Centauri is lovely, t falls into a certain psychological category that it wouldn’t otherwise fall into. Thus, xxx the property of being a thought sometimes is, and sometimes is not, a psychological property.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-096",
    "text": "This view has an ad hoc quality. And there is no need to take it, since the data can be accommodated without it. We’ve already seen the reasons for this; but a brief review of those reasons may be appropriate. If one grasps Alpha Centauri, one does so by grasping some existence-claim that is available to be grasped in any world w, regardless of whether Alpha Centauri exists in w or not. Given any external object x, if one grasps x, one does so by way of some existential proposition that can be grasped in any world, regardless of whether x exists there or not. So we must consider the grasping of propositions of this kind – these purely qualitative, existential propositions -- when we wish to come to a conclusion as to what psychological properties a mental state has in virtue of having a certain content. When we look at propositions of this kind, we discover the following important fact. In virtue of being a grasping of such a proposition, a mental state (or brain-state) does fall into this, as opposed that, psychological category. In other words, when we look at these propositions, we see that the property of being a thought of a certain kind is a psychological property – a property such that psychological explanation and classification is to be made in terms of it. Let us put this more perspicuously. Let P and P* be any two proposition of the kind in question. (So P and P* are examples of the purely qualitative, existential propositions through which we grasp external objects.) xxx Suppose that P and P* are distinct propositions. In that case, we find that the psychological properties – the mental-causal properties -- that one has in virtue of grasping P are psychologically different from the psychological properties that one has in virtue of grasping P*. Now suppose that P and P* are identical. In that case, we find that the psychological properties that one has in virtue of grasping P are psychologically identical with the psychological properties that one has in virtue of grasping P*. This is precisely what the externalist denies. Indeed, he denies it on two levels. First, as we saw earlier, the content-externalist is forced to say that, even if P and P* are different propositions, the psychological properties one has in virtue of grasping the one proposition may be indistinguishable...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-097",
    "text": "Yes, but an exact analogue the argument that we just ran with respect to x is lovely will apply to any singular proposition that is object-involving with respect to any external object. Consider the proposition: there is a lovely object in that part of the sky…Given a small amount of literary creativity, it is easy to hypothesize a scenario that demands that we say of that proposition exactly what we said of x is lovely. And in that second scenario, in order to explain the psychological differences between Smith and Brown, we will have to cite the fact that, on the relevant occasions, the sky was given to Brown in one way (i.e. via one descriptive content), whereas it was given to Brown in a very different way (i.e. via a different descriptive content). So, once again, when it comes time to explain the psychological differences between Smith and Brown, it is entirely irrelevant what singular propositions they come to believe concerning the external world. Those differences will have to be explained in terms of the fact that, on the relevant occasions, the one person did, whereas the other did not, come to believe in the truth of certain propositions that are not object-involving with respect to anything external. The differences will have to be explained in terms of the fact that they grasped different existential-descriptive propositions. If they grasped any propositions other than the purely descriptive one just stated, that fact is causally and explanatorily without consequence. Those other proposition-graspings, supposing that they exist, have no causal powers and no explanatory force. But this, of course, is tantamount to saying that those other proposition-graspings simply don’t exist. Let us distill these points. The content-externalist has two choices. On the one hand, he can choose to be in the position of having to explain why two similar situations can lead to two disproportionately dissimilar situations. On the other hand, he can choose to say that, in some cases, one’s coming to believe something has absolutely no consequences at all in terms of that person’s psychology or, for that matter, in terms of any other portion of the spatio-temporal world. Of course, both options are incoherent, or nearly so. The notion of a de re sense",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-098",
    "text": "Given these points, we are in a position to evaluate some of Evans’ most important semantic and epistemological claims. Because these must be understood in terms of Frege’s (1892) semantic system, let us briefly review the relevant aspects of that system, along with our findings concerning it. “The inventor of bifocals is identical with the first post-master general” expresses something non-trivial, whereas “The inventor of bifocals is identical with the inventor of bifocals” does not. Frege plausibly said that this is because definite descriptions have both sense and reference. Frege held that the sense-reference distinction also applied to proper names. The sentence “Hesperus is Phosphorous” expresses something non-trivial, whereas the sentence “Hesperus is Hesperus” does not. Frege concluded that proper names, like (in his view) definite descriptions, have both sense and reference. Kripke showed that Frege’s position is wrong as far as proper names are concerned. (We’ve also seen some reason to believe that it is wrong where definite descriptions are concerned.) Evans believes that Kripke’s arguments are cogent; so he believes that Frege’s analysis of “Socrates” and “Hesperus” is false. But Evans (1985: Chapter 7) believes that we could invent proper names with respect to which Frege’s analysis was correct. Evans holds that we could invent names – actual names, not quantifiers disguised as names -- that had, for at least part of the semantic content, Fregean senses. In connection with this, Evans’ argues there exist what McDowell would later refer to as “de re senses.” On the basis of these semantic contentions, Evans’ puts forth a far-reaching and, if true, extremely important epistemological thesis, namely: there are de re modes of presentation. This thesis is a fusion of three different bodies of thought: first, Frege’s semantics and epistemology; second, Kripke’s work on proper names; and, third, content-externalism. Here is what I now like to show. First, contrary to what Evans says, there cannot, even in principle, be proper names that have senses. The Fregean concept of sense is an incoherent amalgamation of semantics and epistemology. Evans’ belief that there are de re senses involves a similarly incoherent fusion of semantics and epistemology. But Evans’ view, unlike Frege’s, not only incoherently conflates semantics with epistemology: it conflates semantics with an epistemology that is itself incoherent. (Frege’s epistemology was not unlike that advocated in this work. Frege held that it is not objects per se that are the constituents of...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-099",
    "text": "(E1) If there is a unique thing x such that x invented the zipper, then “Julius” refers to x; and if nothing uniquely invented the zipper then “Julius” doesn’t refer at all. So, by our stipulation, “Julius” is a referring term. At the same time, it obviously has a sense, this being the concept zipper-inventor (or perhaps unique zipper-inventor). On this basis, Evans arrives at two conclusions. First, even though Frege was wrong with respect to actual proper names, the sense-reference distinction applies to invented proper names, such as “Julius.”[96] Second, there are de re senses. The idea behind the second claim is as follows. If somebody x uniquely invented the zipper, then “Julius was tall” is true exactly if x invented the zipper. In other words, given that x uniquely invented the zipper, the proposition encoded in that sentence is true in a world w exactly if x was tall in w. At the same time, as we saw in the last paragraph, “Julius” has a Fregean sense (unique zipper-inventor), and this Fregean sense is part of the proposition encoded in that sentence. So, Evans concludes, if x uniquely invented the zipper, “Julius was tall” encodes a proposition that is object-involving with respect to x. At the same time, the reason why that proposition has x as a constituent is that it contains a concept that singles x out. For any predicate phi, an exactly similar line of thought shows that, if x uniquely invented the zipper, then ┌Julius has phi┐ encodes a proposition that has x as a constituent and that has x as a constituent because it comprises some concept that singles x out. There is another fact about Evans’ proposal that must be pointed out. According to Evans, the proposition encoded in “Julius was tall” will vary from world to world. If Mary uniquely invented the zipper in w, then in w that sentence encodes a proposition that is true iff Mary invented the zipper. For this reason, says Evans, the kind of sense that “Julius” has isn’t quite the same as the senses of which Frege spoke. For Frege, the proposition meant by “the inventor of bifocals snored” doesn’t depend on who invented bifocals. This is because, according to Frege’s view, that person is not himself a constituent of the proposition meant by that sentence: only the sense of “the inventor of bifocals” makes it...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-100",
    "text": "The view that there are de re senses is the semantic counterpart of an epistemological thesis. We’ve already discussed this thesis; but a brief summary of our findings may be appropriate. In the morning, you look at what is in fact Venus. In the evening, you look at what is in fact Venus. You don’t realize that the thing you saw in the morning is the same as the thing you saw in the evening. This is obviously because your morning-perceptions make you aware of Venus through one mode of presentation (one that, if verbalized, would be at least approximately: “last celestial body to disappear from the morning sky”), whereas your evening perceptions make you aware of Venus through a different mode of presentation (one that, if verbalized, would be at least approximately: “first celestial body to appear in the evening sky”). It is because these modes of presentation differ that you can coherently question whether you were seeing the same thing on both occasions. At the same time, content-externalism tells us that, in both cases, Venus itself is a constituent of the contents of your perceptions. So evidently the modes of presentation implicated in your perceptions not only presented Venus to you, but managed to assimilate Venus into themselves. Those modes of presentation – those descriptive contents – were therefore de re with respect to Venus. Evaluating Evans’ argument",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-101",
    "text": "The notion of a de re sense is incoherent, as is the notion of a de re mode of presentation. Suppose that, in actuality, x uniquely invented the zipper. Let P be the proposition that, according to Evans, is encoded in “Julius was tall.” (Here we needn’t distinguish between types and tokens.) According to Evans, P is true in a world w exactly if, in w, x is tall. So P is identical, or at least equivalent, with x is tall. Obviously the concept unique zipper-inventor is no part of x is tall or, with a few irrelevant exceptions, of anything logically equivalent with x is tall. Before proceeding, let me explain what these “irrelevant exceptions” are. Obviously x is tall is logically equivalent with either x was tall or a unique zipper-inventor was a square-circle. But that proposition isn’t what is meant by “Julius was tall”; and, for obvious reasons, the same is true of any other proposition that is both logically equivalent with x is tall and also has the concept unique zipper-inventor has a component. So, despite Evans’ own stipulation, the proposition meant by “Julius was tall” does not have the concept unique zipper-inventor as a component. That sense is nowhere to be found in that proposition. What are we to say about the idea that P has as a component some de re mode of presentation -- about the idea that one of P’s components is a mode of presentation that actually has x as a constituent? That idea is shown to be untenable by an argument similar to the one just given. Supposing that such a sense exists, there is no denying that at least part of the content of that sense is the concept unique zipper-inventor. But we’ve just seen that, with a few irrelevant exceptions, no proposition that has the same truth-conditions as P has that concept as a component. Thus, the concept unique zipper-inventor isn’t a component of any proposition that has the same truth-conditions as the proposition that by Evans’ own stipulation is the meaning of “Julius was tall.” The concept unique zipper-inventor is no part what, by Evans’ own stipulation, is meant by “Julius was tall” and neither, therefore, is any concept that has the concept unique zipper-inventor (or zipper or inventor) as a component. So Evans has failed to identify any proposition that has a de re sense as...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-102",
    "text": "In the morning, you look at what is in fact Venus. You say sincerely say “that thing is lovely.” Let P1 be the proposition to which motivated this utterance. That evening, you again look at what is in fact Venus. You don’t know that, on both occasions, you were looking at the same thing. You say sincerely say “that thing is not lovely.” Let P2 be the proposition to which motivated this utterance. It is a datum that, given only what we’ve said, you are not necessarily irrational. The reason is that the object in question was given to you in different ways – ways that are so different that you don’t know that you some one object as both “lovely” and “not lovely.” But according to the content-externalist says that, for some, were thinking x is lovely in the morning and x is not lovely in the evening. Astonishingly, what content-externalists have done in response is to revise our conception of rationality: they respond by saying that one can assent to a proposition and its negation without being irrational. I can believe P and not-P without being irrational.[98] Given what we’ve seen, there is no need to embrace this highly revisionist view. The content of your morning perception is an existence-claim that is satisfied by Venus, and the same is true of the content of your evening perception. But Venus is not itself a constituent of your perception. There is no x such that (given only what we know about you from the story just told) you believe the singular proposition x is lovely and also the singular proposition x is not lovely. The semantic-externalist is quite right to say that you have affirmed both of those propositions. But we’ve already seen why this doesn’t entail that you believe both of those propositions. What you believe are the existence-claims that describe those singular propositions, not those singular propositions themselves. Those existence-claims are perfectly consistent. So we don’t need to jettison the age-old view that it is irrational to believe P and not-P.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-103",
    "text": "This objection does have merit. But what it shows is not that my position is wrong. It only shows only that, in the initial presentation of my views, I chose to illustrate fundamental principles through examples that were vivid but slightly inaccurate, rather than through examples that were technically accurate but that, at that phase of the presentation of my theory, would have been very hard to understand. In any case, the right response to the objector lies in a point made by John Searle (1983: 225-230). It is a point that we ourselves made earlier when discussing the relation between having a concept of an object and integrating it into one’s cognitive map of the world. Consider the visual sensation involved your morning-perception of Venus. Let V be that sensation. Even a content-externalist will grant that V is partly descriptive. Even if V turns out to be a hallucination, it still tells you something – it tells you that there is a celestial body having a certain (approximate) location, and so on. A content-externalist would say that, if V is a hallucination, then there are gaps or blanks in its representational content where there would otherwise be objects. But he cannot plausibly deny that V tells you something, if only something false (or coincidentally true). Surely the hallucinator is told something false by his hallucinations. In light of this, consider the existence claim:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-104",
    "text": "If V is caused by a blow to the head, or by consumption of a psychedelic drug, then it won’t be a perception of anything. The cause of V must be something which fits the description coded in V. It must be a brightly lit sky comprising a lovely luminescent planet. But even this, though necessary, is not sufficient. In other words, for V to be a perception, it is not enough that V be caused by something x that fits the description coded in it. V must be caused in a particular way x. Suppose that a brightly lit sky causes Bob to punch you, which in turn causes you to have V. In that case, V wouldn’t be a perception, even though it was caused (albeit indirectly) by something which fits its content. So there is some specific mode of causation C such that, for V to be a perception, it is necessary and sufficient that V be caused in manner C by something x that fits the description coded in it. (It is a question greatly debated among epistemologists what C is. I will not attempt to answer this question. But it may reasonably be taken for granted that there is some such privileged causal modality.) Given this, let us replace (**) with:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-105",
    "text": "The model just proposed satisfies all the relevant desiderata. That, as I would now like to show, is why it is worth tolerating any counterintuitiveness that might characterize it. We have completely descriptivized the content of perception. We have expelled external objects from the contents of our perceptions. On our model, such objects are described by those contents, but they are not actual constituents of those contents. Any analysis of perceptual (and cognitive) content must satisfy this requirement. This is because, so far as external objects are veritable constituents of our perceptual content, two perceptions or thoughts can have radically different contents without ipso facto having any differences in respect of their causal or their psychological properties. Our analysis is consistent with the fact that what we are seeing and, more generally, thinking about is determined by our causal liaisons. So our analysis accommodates the datum that motivates content-externalism. The problem with content-externalism is that confuses content with truth-maker. Supposing that x is a constituent of the external world (as opposed to a universal or a constituent of my own consciousness), for me to be thinking about x is not for x to be a constituent of the piece of information that I am grasping. Thinking about x typically involves having a descriptive fix on x. In many cases – indeed, in the cases that are cognitively central - that descriptive fix involves a causal component. (Our descriptivism is consistent with that fact, as we saw in Chapter 6.) But that causal connection is internal to a descriptive lock-on. Notice that (***) has a constituent of some person’s consciousness for a constituent. One of the constituents of (***) is a visual sensation, namely V. Notice (***) doesn’t describe V, but actually has it as a part. So (***) is object-involving with respect to some mental entity, but not with respect to anything external.[100]",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-106",
    "text": "Suppose you grasp some proposition P about some sensation, e.g. some itch, that you are having. So P might be: I am having this itch because I am allergic to the shirt I am wearing. Let P* be a proposition that is just like P, except that, where P comprises that itch, P* comprises some other sensation, e.g. a tickle. A grasp of P has very different causal and psychological properties from a grasp of P*. So the substitution just described has psychological consequences – as opposed to consequences that can only be registered by a controversial theory of mental representation. Believing P leads you to believe that allergies cause itches, whereas believing P* leads you to believe that allergies cause tickles. It is obviously not the case that, ceteris paribus, a grasp of P is causally indistinguishable from a grasp of P*. No recherché arguments about causality are needed to establish this. Intersubstituting parts of propositions has very real psychological consequences when the parts in question are contents of consciousness, e.g. visual sensations like V. Now let us a tell a different story. In our world, you are looking at Mary, and believing that she looks happy. Let T be the proposition that you believe true. Possible world w* is just like ours except that, in w*, you are looking at somebody who isn’t Mary, but looks exactly like her (i.e. looks exactly as Mary does in our world). In w*, you are thinking that this person looks happy. Let T* be the proposition that you believe true. In virtue of that difference, does your mental state in w* have causal properties not had by your mental state here? The answer is “no”, as we discussed earlier. But, according to McDowell, T and T* are different propositions, the reason being that, in the place where T has Mary as a constituent, T* has some other person as a constituent. By itself, intersubstituting parts of propositions has no psychological consequences when the parts in question are external objects. So, contrary to what McDowell says, it is not arbitrary to say that we can be acquainted (in Russell’s technical sense) with the contents of our own consciousness, while also maintaining that we are not acquainted (in that sense) with external objects. There are quite obvious reasons to believe that acquaintance with our mental states is not psychologically innocuous and also that...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-107",
    "text": "We’ve seen that understanding “Socrates”, or any other referring term, involves associating it with some description that its referent uniquely satisfies. But we’ve also seen that the descriptions that a person associates with such an expression are highly specific to the circumstances under which he first encounters it. A consequence is that any two people will almost certainly associate different descriptions with “Socrates.” But surely “Socrates” is useless as a device of communication unless people mean the same thing by it, and surely people cannot mean the same thing by it if any two people associate different descriptions with it. So our analysis seems to conflict with the fact that referring terms can be understood only in so far as the descriptions associated with them are shared. This is a point that Frege (1892) stressed: the “senses” of referring expressions must be public. If the sense that I associate with “Socrates” is great hemlock-drinking philosopher, and the sense that you associate with him is ironic main character in most of the Platonic dialogues, then what you mean by “Socrates was wise” will be different from what I mean by those same words. What you mean will be equivalent with: somebody x was uniquely an ironic main character in most of the platonic dialogues; and x was wise. And what I mean will be equivalent with: somebody x was uniquely a great hemlock-drinking philosopher; and x was wise. According to Frege, to the extent that people associate different senses with a given expression, that expression fails as a way of allowing people to express their thoughts to one another. At the same time, it is a datum that we can use expressions like “Socrates” to make ourselves understood to one another. My analysis seems to be inconsistent with that fact. I believe that Socrates was a person of principle. The occurrence of “Socrates” in the last sentence expressed that belief. But if my analysis is right, how can that be? For what I mean by “Socrates was a person of principle” is one existence-claim, and what you mean by it, and thus take it to mean when hearing it from others, is some entirely different existence-claim. I would now like to show why my analysis is consistent with the facts concerning the usefulness concerning “Socrates” and other expressions as devices of communication. Our analysis is consistent with the important points made...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-108",
    "text": "Obviously (TP) doesn’t say anything that is of general interest. It doesn’t say anything that historians or philosophers would find illuminating. As we’ve seen, the thoughts through which you compute the meanings of utterances are of the same basic kind as the thoughts which prompt you to produce such utterances. Since there is no way for you to understand T except by way of your knowledge of some egocentric, contextual proposition like TP, knowledge of such a proposition must be what prompts you to utter T. But this doesn’t entail that what you mean when you utter “Socrates was wise” is TP, or anything like it. For reasons that we’ve given, when you say “Socrates was wise”, you know that what is literally meant by yours words is confined to the underlined part. You thus know that, so far as your objective is to speak truly, your objective is met exactly if that operator-right proposition is correct. For you to mean that proposition by your utterance of “Socrates was wise” is simply for you to make that utterance with that objective. It is true that you don’t directly grasp that proposition: you grasp it only in the indirect sense described earlier. But you can still mean that exact proposition by your words; you can mean exactly x was wise, for the appropriate x. You don’t have to mean some existence-claim, even though, ultimately, you are incapable of grasping anything other than such a claim. To put these issues into context, let us briefly discuss what is probably the most famous analysis of the nature of linguistic meaning. That account is due to H.P. Grice (1957). According to Grice, expression-meaning must be understood in terms of speaker’s meaning. “Snow is white” means snow is white in virtue of the fact that people mean snow is white by “snow is white.” In general, our utterances mean what we mean by them. Grice’s picture is not correct. Searle (1969: 43-47) put his finger on the basis problem with it. You cannot checkmate somebody in a context where the rules constitutive of the game of chess are inoperative; and you cannot even intend to checkmate somebody unless you believe that those rules are operative. Similarly, you cannot affirm that snow is white with the words “snow is white” in a context where the rules constitutive of the English language are inoperative; and you cannot...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-109",
    "text": "where P1…Pn may be, and probably are, entirely different from P*1…P*n . But (1) and (2) have the same truth-maker. The thing which satisfies (1) is identical with the thing which satisfies (2). So even though what Fred takes away from Smith’s utterance of “Socrates was wise” may be very different from the thought that prompted Smith’s utterance, there is still a significant sense in which a truth has been transmitted. Thanks to that utterance, Fred now has a thought that has the same truth-maker as Smith’s thought. Another illustration may be in order. I see Brown for the first time at time t. But what I see is not just Brown; what is given to me in my perception corresponds to the existence-claim: over there, next to that tree, there is some man x such and x is unshaven and looks disheveled, and x just introduced himself to me by saying “I am Brown: please forgive my appearance – you see, I didn’t sleep well last night…” Let us continue this story. You see Brown for the first time at time t*, and the content of your perception is given to you through the existence-claim: behind that podium, there is a clean-shaven, debonair fellow x such that x is giving a competent, but ultimately not very informative, lecture on the history of psychology, and such that I’ve been told that x’s name is “Brown”. Suppose that you and I are together, and somebody tells us both: “Brown is a member of the libertarian party.” What you will take away from that utterance is:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-110",
    "text": "(4) a few days ago, next to the maple tree outside my house, there was some man x such that x was unshaven and looked disheveled; moreover, x is a member of the libertarian party. But even though (3) and (4) are very different, they both have the same truth-maker. This point generalizes without limit. (We are continuing to confine our attention to cases where the people in question speak English and are cognitively competent.) If, ten days later, I say to you: “Brown just bought a new car”, the thought that motivated my utterance of that sentence will have the same truth-maker as the thought which that utterance leaves you with. So even though the thoughts that I have in connection with sentence-tokens of the form ┌Brown has phi┐ will always differ in significant ways from the thought that you have in connection with sentence-tokens, those two sets of thoughts will be coordinated in a very strict fashion. They will categorically have the same truth-makers. And this – nothing else -- is what is important to our being able to communicate with another through language. Suppose that, in order to communicate with each other, you and I had to associate exactly the same propositions with utterances of “Brown looks tired”, “there is no way that Brown can afford the BMW he just bought”, and so on. In that case, communication would be impossible. Given the descriptive nature of sense-perception, and given the public nature of languages like English and Russian, there is no way that we could possibly have qualitatively identical thoughts in connection with “Brown looks tired” or, by reasons exactly similar to those just given, in connection with any other utterance. Communication is possible only because communication does not presuppose such a complete cognitive convergence between speaker and auditor. For communication to occur, only a limited convergence is needed: the speaker’s thoughts must have the same truth-maker as the auditor’s.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-111",
    "text": "Some would take these remarks to show that communication is impossible.[107] Some would say that, if indeed the proposition I associate with an utterance of “Brown looks tired” isn’t identical with the proposition that you associate with it, then we simply aren’t understanding each other: there is only an illusion of communication, fostered by a kind of parallelism between our thoughts. Here is the view I would endorse. The line of thought given in the last paragraph is a purely terminological point, masquerading as one that is substantive. It is a datum that people make themselves understood through language. I say to you: “your mother is coming tomorrow.” Something has been communicated; and that is why you immediately start tidying your house, washing the bedding in the guest bedroom, and so forth. Verbal communication is an obvious and pervasive phenomenon. The naïve model of this phenomenon is this: communicating involves the speaker and the auditor associating exactly the same propositions with the noises that are produced during their exchange; and so far as they fail to do so, they are not really communicating – even though they may feel as though they are. As we’ve seen, this position is a non-starter, given the public nature of linguistic symbols and given the formidable cognitive pre-requisites to internalizing and manipulating those symbols. This isn’t to say that there is never a convergence of the sort just described. But it would be false to say that communication categorically presupposed such an absolute convergence. A more realistic model is the one proposed a moment ago. Communicating involves both speaker and auditor associating propositions that have the same truth-makers with the noises that are produced in during their exchange. Of course, if P and P* are the same proposition, then they have the same truth-maker. So our model is compatible with the possibility that, in at least some cases, communicating involves speaker and auditor associating the very same proposition with a certain sound or ink-mark. But our model, unlike the naïve one, is consistent with the fact that those two propositions are often distinct. What is necessary, according to our model, is that both propositions have the same truth-maker and are thus coordinated with each other. In general, linguistic communication involves a coordination, not an identity, of thought. Speaker and auditor must have parallel, not necessarily coincident, thoughts. Because linguistic communication involves identity of truth-maker,...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-112",
    "text": "According to the naive view, genuine communication occurs only to the extent speaker and auditor associate exactly the same propositions with the expressions used in their exchange.[110] I would now like to develop our criticisms of the naïve view You and I both speak English. Let S1…Sn be the set of English sentences that you and I both understand. As we’ve discussed, for practically any value of i, the proposition that I associate with a token of Si will be very different from the proposition that you associate with it. At the same time, the truth-maker of the one thought will be identical with the truth-maker of the other. So there is some x such that the singular proposition x was wise is the truth-maker of the proposition I associate with “Socrates was wise” and also of the one that you associate with it. This means that, even though you and I access the meaning of “Socrates was wise” through different bodies of information, we are nonetheless in complete agreement as to what state of affairs must hold for that sentence to be true. Of course, “Socrates was wise” was arbitrarily chosen, and what we just said of it is true of each sentence in S1…Sn. So what is true of “Socrates was wise” will be true also of sentences reporting evidence relevant to the truth of that sentence. Suppose recent historical research proves beyond a shadow of a doubt out that Socrates died when Plato was only ten years old. Given our model, there is some x and some y such that the propositions that both of us associate with “Socrates died when Plato was only ten years old” are true exactly if the singular proposition x died when y was only ten years old is true. Thus, given our model of semantic competence, it follows that ceteris paribus you and I are in complete lock-step in regards to the evidential and, more generally inferential significance of any sentence of English. A corollary is that validity of the arguments literally meant by one’s words will perfectly mirror the validity of the argument that is grasped by the thoughts behind those words. What we just said about validity is true of truth, cogency, and every other logically significant property. Our model thus accommodates the fact that sentences of English are capable of unambiguously transmitting information about the world, even though,...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-113",
    "text": "It seems clear that, within certain limits, we know with absolute certainty what it is that we are thinking. Right now, think about how much you enjoy reading Descartes’ works. (For the sake of argument, either suppose that you do enjoy reading his works or replace the proposition I like reading Descartes’ works with one that does befit your psychology, e.g. I do not particularly enjoy reading Descartes’ works or I want to go to Paris.) You know with unimpeachable (“Cartesian”) certainty what it is that you are thinking right now. Further, you know, with that same certainty, that you are in fact having a thought right now. In any case, our pre-theoretic intuitions give some credence to these assertions. We mustn’t confuse questions 666 concerning the range of things which we can know with Cartesian certainty with the question of 666 whether we can know things with such certainty. Freud, Chomsky, and others have argued that we are unaware of much of the mental activity that occurs within our own minds.[111] But these discoveries don’t show that we don’t have any Cartesian certainties. They only show that we don’t have such certainties with respect to everything within our own minds. Right now think about the fact that you enjoy (or don’t enjoy) reading Descartes. Nothing that Freud or Chomsky say is inconsistent with the obvious truth that you know with Cartesian certainty that you are now thinking about that proposition. Freud may be right to say that many of your reasons for thinking 666 it are not known to you, and involve symptomatic conversions that are rooted in anxieties the grounds for which may never be revealed to your consciousness. Chomsky may be right to say that your being able to grasp that truth involves intricate performances on the part of some sub-personal cognitive apparatus that couldn’t possibly disclose itself to consciousness. Be all of this as it may, your knowledge that you are now thinking about the proposition I enjoy reading Descartes is characterized by a special and inviolable certainty – one that cannot attach even to the best substantiated beliefs about the external world.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-114",
    "text": "Given the information available to you, it is epistemically possible that Descartes didn’t exist. It could turn out that the relevant various historical records were forgeries, that the work attributed to him was actually written by someone else, and so on. The essence of content-externalism is that Descartes himself – as opposed to some description that happens to single him out – is a constituent of certain thoughts of yours (e.g. I enjoy reading Descartes). If that doctrine is right, then there are various thoughts that you in fact have that you wouldn’t be having if turned out that Descartes had never existed. So supposing that you are now consciously entertaining the proposition I enjoy reading Descartes, an apparent consequence of content-externalism is that your knowledge that you are now having that thought is only as good as your knowledge that Descartes himself existed. This in turn means that you don’t know with any special certainty that you are having that thought. If content-externalism is right, then your knowledge of the contents of your own consciousness becomes as uncertain as your knowledge of early modern French history. (See Bilgrami 1992: 364-365, McKinsey 1991: 355-356.[112]) These remarks generalize without limit. Right now have the thought Alpha Centauri is more massive than my car. For reasons analogous to those just given, if content-externalism is right, then your knowledge that you are now having that thought is no more certain than your knowledge of some spatially and temporally remote region of the cosmos. Of course, this seems quite wrong. If you are consciously having a thought about Descartes, you do (or at least can) know with a special certainty that you are having that thought. Even if we grant that one can be deluded as to the identities of the thoughts one is consciously having, there is no denying that there is a kind of certainty that can attach to our knowledge of what we consciously thinking that cannot possibly attach to our knowledge of what is going in the external world (McKinsey 1991: 355-356,Bilgrami 1992: 364-365). Content-externalism has a closely related and equally counter-intuitive consequence, namely: you don’t know the identities of the thoughts that you consciously entertain with any more certainty than you know about the constitution of the external world. As before, entertain the thought I enjoy reading Descartes. Let M be the mental process that mediates that thought. If...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-115",
    "text": "(TB) Suppose that you are thinking: I enjoy reading Descartes. Let T be that thought. Now suppose that you are now thinking that you enjoy reading Descartes. Let T* be that thought. T* actually comprises T. So in thinking I am now thinking that I enjoy reading Descartes, you are necessarily thinking I enjoy reading Descartes. The very occurrence of T* thus guarantees its own truth. It is a self-fulfilling thought. To be maximally clear, let us restate this argument. T* is a thought to the effect that T is occurring. T is a veritable component of T*. Therefore T* cannot possibly occur without being correct. Therefore, T* is grounds for its own truth. You cannot have T* without knowing T* So if you believe that you are thinking I enjoy reading Descartes, that belief is grounds for its own truth. You cannot have that belief without having logically adequate grounds for believing and, further, without in fact believing it on those very grounds. Obviously this gives a certainty to one’s belief that one is thinking I enjoy reading Descartes that doesn’t attach to one’s believing some proposition about the external world. But, in addition, it gives a certainty to that belief that doesn’t even attach to one’s belief in the principles of logic or mathematics. This last point is crucial. If you believe that 7+5=12, your belief cannot possibly be wrong. But your thinking 1+1=2 is not what makes that thought true. 7+5=12 is true in virtue of facts about the numbers and arithmetical operations. If you had to prove to somebody that 7+5=12, it wouldn’t be enough to say: “I just thought it; therefore its true.” You’d have to go through the sort of rigmarole that Whitehead and Russell went through. By contrast, if you think I enjoy reading Descartes, the grounds for that truth of that belief are simply that you had that belief. For this reason, your thoughts about what you are (consciously) thinking have the sort of certainty that Kant described as “apodictic.” Nor 666 is it logically impossible that such thoughts should be wrong. Those occurrences provide the grounds for their own truth; and, in virtue of having those very thoughts, you are believing in their truth on those very grounds. So your having those thoughts guarantees that you recognize the reasons for which they are logically, and judge them to be true for...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-116",
    "text": "That is undeniable. There is no denying that, if it occurs, T* is necessarily correct. So if you manage to think T*, your belief is ipso facto correct. And, just as Burge says, the reason for this is that thinking T is a pre-condition for thinking T*. But the very thing that is in question is whether content-externalism allows that pre-condition to be met in the relevant contexts. It is easily shown that there are situations where content-externalism doesn’t allow you to have any thought at all but where, at the same time, it is clear on independent grounds that one is having a thought and, further, that one knows with Cartesian that one is having that thought. Supposing that you have succeeded in having T, Burge’s argument does indeed show that you cannot be wrong to think that you have T. But if externalism is right, there are situations that are epistemically just like this one – situations where the neurons in your head are firing in exactly the manner in which they are firing here, where you feel exactly as you do here, have the same feelings of certainty, and so on -- but where you simply fail to have T. A fortiori you fail to have T* in such situations. At the same time, each of those situations is epistemically indistinguishable from your situation here; and it is therefore a datum that, in any one of those situations, you have the very same Cartesian certainties that you have here. So the worlds 666 where Burge’s assumptions are granted are not the worlds where one has the Cartesian certainties whose existence he is tethering to the truth of those assumptions. Let us develop this argument. Suppose that content-externalism is correct and, once again, think (or try to think) to yourself: I enjoy reading Descartes. So far as your mental state consists in your having that thought, your counterpart in a Descartes-free world w 666 is failing to have a thought. Now think: I am thinking that I enjoy reading Descartes. So far as your mental state consists in your having that thought, your counterpart in w is failing to have a thought. Supposing, as we are, that content-externalism is correct, your counterpart is wrong. He attributes a thought to himself that he doesn’t actually have. In the place where you are actually having a thought, your counterpart is...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-117",
    "text": "But, in light of how Burge and other content-externalists construe what it is to think about Descartes, (*) only takes into account the set of worlds where Descartes exists. It doesn’t take into account the entire 666 set of worlds where Descartes doesn’t exist but where your epistemic situation is exactly as it is here. So it doesn’t take into account all of the worlds in terms of which claims about self-knowledge must be evaluated. It only takes into account where Descartes has already been loaded, externalist-style, into your thoughts. Thus, depending on how one chooses to look at it, Burge’s argument either begs the question, by restricting its attention to worlds where Descartes has been made a constituent of our thoughts, or it erroneously identifies the class of worlds that are epistemically identical with ours with some subset of the class of worlds where Descartes exists. Either way, the argument is fallacious. Another content-externalist stratagem",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-118",
    "text": "(SK) involves a failure to give due attention to distinctions of scope. Some background may help bring this out. Let w be a world where there is XYZ instead of water, but that is otherwise just like our world. Let w1 be a world there is X1Y1Z1 instead of water, but that is otherwise just like our world; let w2 be a world there is X2Y2Z2 instead of water, but that is otherwise just like our world; and so on. So your epistemic situation in our world is identical with your epistemic situation in each of w1, w2, and so on. Let us proceed. 666 Let T 666 be the thought: I enjoy drinking XYZ; let T1 666 be the thought: I enjoy drinking X1Y1Z1; 666 let T2 666 be the thought: I enjoy drinking X2Y2Z2;and so on. 666 Finally, suppose that, in our world, you are thinking I am currently thinking that I enjoy drinking water. 666 Like everyone else, the externalist admits that we don’t know with Cartesian certainty that we are in a water-world, as opposed to an XYZ-world (or an X1Y1Z1-world…). At the same time, the essence of the content-externalist’s position is this: if I am in w, I am thinking 666 T; if I am in w1, I am thinking T1; if I am in w2, I am thinking T2; and so on. Given this, suppose for the sake of argument that (SK) is cogent. 666 In that case, if I am in w2, then there is some thought – namely T2 – such that 666 I am having T2 and such that I am attributing T2 to myself. But notice that, in the last sentence, the “there is” is given wide-scope with respect to the other operators – with respect to the expressions “attributing” and “having.” So if (SK) is cogent, then in w2, there is a thought that I am having and that I am correctly attributing to myself – but I don’t know which thought it is. I don’t know whether it is T1 or T2 or T3… Some fiction may clarify the structure of this argument. Because of some accident of genetic engineering, there are various people who look (and also dress and talk and act) exactly the same. These people are John1, John2...and John10. One day somebody who is in fact John4 is standing in front of me. Under these...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-119",
    "text": "Given what it is that we can know about ourselves, xxx and with what degree of certainty we can know it, content-externalism must be wrong. In any case, we have seen some good reasons to accept this and no good reasons to reject it. But Donald Davidson rejects it, and he provides a bold argument on behalf of his position.[115] Let us now consider that argument. From the viewpoint of a physicist, it is irrelevant whether you measure weight in pounds or kilograms. What matters is that you use some consistent system of measurement. My weight in pounds is 195. So far as there is a significant connection between the number 195 and my weight, that reflects the contingent and logically insignificant fact that a certain system of measurement has been adopted. Given any object O XXX, and given any number N, there is some viable system of measurement S such that, relative to S, O has mass N. It is only relative to some arbitrarily chosen system of measurement that there is any significant connection between any object’s mass and any number. Suppose that Smith believes that water quenches thirst. In Davidson’s view, Smith’s relation to the proposition water quenches thirst is comparable to the relationship between my body-mass and the number 195. Relative to one viable system of measurement, there is a special connection between my weight and the number 195; and relative to others, there isn’t. Relative to one viable system of description, there is a special connection between Smith’s mental state and the proposition water quenches thirst; and relative to others, there isn’t. Just as it is useful, but not necessary, to measure weight in pounds, so it is useful, but not necessary, to describe mental events in terms of propositions. 666 [ADD MISSING PREMISE] Consequently, given only what is going on “in Smith’s head”, there is no reason to say that Smith believes that water quenches thirst. Thus, even if Smith has a complete knowledge of what is going on in his head, he doesn’t necessarily know that he believes that water quenches thirst. In light of a correct understanding of statements like “Smith believes that water quenches thirst”, it is clear that we don’t have any special knowledge concerning our own mental states. Content-externalism is consistent with this, and should therefore be commended, not rejected. Evaluating Davidson’s argument",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-120",
    "text": "Smith’s relation to the proposition water quenches thirst is not comparable to the relationship between my weight and the number 195. In the one case, we are dealing with an arbitrary convention (or, more accurately, with a non-arbitrary consequence of an arbitrary convention). In the other, we are dealing with a fact that has nothing to do with convention. Not many authors deny this. But even though Davidson’s view is not widely accepted, it is worthwhile to state explicitly why his view is wrong and what is wrong with his argument for it. People are usefully described as having attitudes towards propositions. Why isn’t the same true of rocks and trees? The obvious answer is: “rocks and trees don’t have attitudes towards propositions; people do have such attitudes.” But this is exactly the position that Davidson is attempting to refute. And there is much to be said for that position. If you subtract the representational from the mental, not much is left. Indeed, according to one school of thought, known as “intentionalism” 666, nothing mental is non-representational. Even phenomenal content is representational: given a difference in phenomenology, there is a difference in representational content. I myself think that this is an overstatement. For reasons I have given elsewhere[116], I think that there are mental entities that are either non-representational or only derivatively representational. But what is indisputable is that representationality is a pervasive feature of the mental. It is also indisputable that non-derivative representationality is a sufficient, if not a necessary, condition for mentality xxx. Supposing that Davidson is right, there must be some way of identifying and describing mental phenomena that does not involve the concepts of belief, desire, and so on. But this doesn’t seem to be the case. Given that the concepts mental and non-derivatively representational are virtually interchangeable, it makes questionable sense to say that there could be a viable description of psychological reality that didn’t use concepts such as representation and proposition. Where human subjects are concerned, there doesn’t seem to be a neutral subject-matter that we may or may not choose to describe in terms of concepts like desire, fear, and so on.[117] Davidson’s argument assumes otherwise and is therefore fallacious. One might make the following objection to this last point:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-121",
    "text": "In fact, Davidson himself makes this very point in his essay “Mental Events.”[118] There Davidson says that “events are mental only as described.”[119] The idea is that, just as a person may be described as a lawyer or father or soccer coach, so an event may be described as a pattern of electrical stimulation or as a surge of fear. Supposing that this is right, it seems to follow that psychological statements organize data that could just as well be organized in completely non-psychological terms. And it is exactly this view that underlies that Davidson’s views on self-knowledge. But this line of thought is misguided, as a story may help show. I am suddenly overwhelmed by a number of complex feelings. I attempt to articulate them. (I say “I now realize that I should have become an actor, and that my decision to work on Wall Street -- though socially respectable and seemingly indicative of a mature acceptance of life’s exigencies -- was ultimately an attempt to avoid confronting the question that has been haunting me since the age of five, to wit…”) Let S be the statement that results. Let us suppose that S is accurate. Later that day, I am watching a film of the brain-event that realized the just described mental event. (That brain-event was recorded by a micro-camera inside my cranium.) I describe what I see, using the appropriate neuro-physiological terms. Let S* be the statement that results. Let us suppose that S* is accurate. The event in virtue of which S is true is identical with the event in virtue of which S* is true. But the data of which S is a correct synthesis is entirely different from the data of which S* is a correct synthesis. S* conceptualizes various visual perceptions of various discolorations on a certain video-monitor. That body of data doesn’t even overlap with the body of data conceptualized by S. There is no neutral data of which both psychological and non-psychological syntheses are possible. A pang of remorse may be identical with some series of neural events. But the data correctly synthesized by a verbal expression of remorse is entirely different from the data correctly synthesized by any statement of the form ┌neural events of type PHI are now occurring.┐ Even though I have unexceptionable grounds for saying “I now feel terrible remorse over stealing my sister’s cookie”, I may...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-122",
    "text": "It is ill-advised for proponents of content-externalists to attempt to reconcile that doctrine with our intuitions about self-knowledge. This is because content-externalism nearly enough is a denial that such intuitions are correct. I look at Venus in the morning and sincerely say “that is lovely.” I look at Venus in the evening and sincerely say the same thing. But I don’t know that I was looking at the same thing on both occasions. The content-externalist says that there is some one proposition such that I was sincerely affirming that proposition on both occasions. More explicitly, there is some x such that, on each occasion, I believed and affirmed the proposition: x is lovely. It is a datum – one that content-externalists don’t deny – that, under the circumstances described, I need not know this last fact. So the essence of content-externalism nearly enough is that one doesn’t know what one is thinking. It would therefore seem ill-advised for content-externalists to try to show that their doctrine validates our intuitions about self-knowledge. We can corroborate this by modifying the story just told. Consider a scenario that is just like the one just described, except in this one respect: In the evening, I sincerely say “that is not lovely.” According to this content-externalist, there is some x such that in the morning I believe the proposition x is lovely, and such that in the evening I believe the proposition x is not lovely. It is a datum that, given only what we’ve just said, I am not necessarily guilty of irrationality – I am surely not to be compared with someone who sincerely says “I believe that Smith is French and that Smith is not French.” Most content-externalists admit this.[123] At the same time, it is clear that I would be guilty of irrationality if knew that, for some x, I was sincerely affirming x is lovely and also x is not lovely. So if content-externalism says that I xxx know with Cartesian certainty what it is that I am believing, then that doctrine is forced to part with the datum that I can coherently affirm both “that [pointing to Venus in the morning] is lovely” and also “that [pointing to Venus in the evening] is lovely.” So it is in that doctrine’s interest to ensure that our pre-theoretic claims about self-knowledge are wrong. Also, although I myself believe that content-externalism is...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-123",
    "text": "If content-externalism is right, then two people who are in epistemically identical situations can have thoughts (or perceptions) with different contents. I am having a thought that has Smith as a constituent. But it is epistemically possible that I am having a thought that instead has Twin-Smith as a constituent. In this chapter, I wish to argue that this is incoherent. To say that it is epistemically possible that I am thinking about Twin-Smith is to say that, given only the data at my immediate disposal, it cannot be ruled out that I am thinking about Twin-Smith. To say xxx that this isn’t ruled out by the data at my immediate disposal is to say that it isn’t ruled out by my mental content. So two people are in epistemically identical situations just in case their mental states have the same contents. I would now like to develop the argument just outlined. The essence of content-externalism is this:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-124",
    "text": "X and Y are in identical epistemic situations iff, for any proposition P, the grounds that X has for believing P are identical with the grounds that Y has for believing P. (Actually, it would probably be even more accurate to say this: X and Y are in identical epistemic situations iff, for any truth or falsehood P, the grounds that X has for believing P are identical with the grounds that Y has for believing P. This definition, unlike the previous one, doesn’t involve the controversial (and, I will argue, false) view that all truths and falsehoods are identical with propositions – this is a topic we will discuss at length in chapters 22 and 23. But, in this context, solely for the purposes of brevity, we will use the term “proposition” as a shorthand for “truth or falsehood” or “piece of information.”) X has the same grounds as Y for believing some proposition P iff what X already believes has the same bearing on P as what Y already believes. For you to have good grounds for believing that somebody stole your car is for the propositions in which you already believe to have a certain relation (some kind of confirmation-relation) to the proposition somebody stole your car. So X and Y are in identical epistemic situations exactly if, for any proposition P, the propositions in which X already believes stand in precisely the same relationship to P as the propositions in which Y already believes. Thus (1) is equivalent with:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-125",
    "text": "In order for the propositions in which X believes to bear on any proposition P in precisely the same way as the propositions in which Y already believes, it is necessary that X and Y believe precisely the same propositions. Before closing the argument, there is a fact relating to the concept of analyticity that we must point out. Even if the propositions that X believes are analytically equivalent with the ones that X believes, there may still be some proposition P such that the exact way in which the former bear on the latter will differ from the way in which the latter bear on the latter. Suppose my one belief is that 1+1=2 and that your one belief is that each thing is self-identical. Of course, for any proposition P, the one proposition in which I believe entails P iff the same is true of the one proposition in which you believe. But the exact way in which the one proposition bears on for some n, n+1=2 will obviously be very different from the exact way in which the other bears on that proposition. A derivation of for some n, n+1=2 from the one proposition will be extremely straightforward; in the other case, such a derivation will be extremely circuitous. In any case, those derivations will differ. Given obvious extensions of this reasoning, it is clear that if, for any P, X’s beliefs are to have exactly the same bearing on Y’s on P, X and Y must have precisely the same beliefs. So X and Y are in the same epistemic situation exactly if they have exactly the same beliefs. Given what was said in the last paragraph, it follows that (3), and therefore (1), are equivalent with:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-126",
    "text": "In fact, the position just stated is similar to one that McDowell (1998: Chapters 10-13) holds. But each of (A)-(C) is a datum. Under the circumstances described in (C), X has no better reason than Y for believing that he is in an H2O world than Y, and Y has no better reason than X for believing that he is in an ABC-world. You are in an H2O world. Imagine a counterfactual scenario w such that, in w, you are in an ABC-world, but are otherwise exactly as you are now. So in w, you believe that you are in H2O world. Of course, that belief is wrong. But is it less rational than your actual belief that you are in such a world? Of course not. Your sensory surfaces are disturbed in exactly the same way as his. So the one set of disturbances cannot possibly differ from the other in respect of the extent to which it warrants a given belief. So for all the one knows, his condition is in fact identical with the others. In other words, the one person’s condition is epistemically just like the other’s. Let us turn to (B). We must note that the content-externalist does (implausibly) deny (B). As we’ve seen, he says that, for some x, one can rationally believe x is lovely and x is not lovely. So it might seem that, in assuming (B), we have simply begged the question against the content-externalist. But we have provided independent support for (B). But have we begged questions in assuming (A)? The essence of content-externalism is that, even if X and Y are otherwise the same, differences in their environments amount to differences in what they believe and, therefore, to differences in their epistemic situations. So, it seems, our use of (A) begs the question. I would like to rebut this. According to the content-externalist, whenever X has a belief that is object-dependent with respect to H2O, Y has a belief that is object-dependent with respect to ABC. But the content-externalist will not say that X and Y differ in all of their beliefs. If X thinks 1+1=2, so does Y. They differ only with respect to a certain sub-class of their beliefs. Their beliefs diverge only when those beliefs are object-involving with respect to those features of their environments that are not common to both worlds. Since not every belief...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-127",
    "text": "S and S* are incompatible. There is no possible world where they are both true. But apart from this belief in S, Smith’s epistemic situation is, by hypothesis, identical with Smith*’s. So the beliefs that Smith has apart from his belief in S are identical in content with those which Smith* has apart from his belief S*. It is clear that Smith believes S in virtue of his having those other beliefs, the same being true mutatis mutandis of Smith*. So if, as Burge supposes, Smith believes S, that is in virtue of the fact that has various other beliefs, e.g. the belief that there is some painful malady x such that x is referred to as “arthritis” and I have been told that I have x. There is no possible world where Smith just believes S. A belief in S necessarily presupposes some more fundamental belief, such as the one just described. That is why, in preparation of his thought-experiment, Burge himself takes pains to ascribe certain beliefs to both Smith and Smith*: they both have certain beliefs about language, about their own phenomenal states, about what physicians have said about how to ameliorate those states, and so on. As Burge surely knows, it would make little sense to say that Smith’s belief in S occurred in a vacuum of other beliefs. This is surely because those other beliefs are constitutively related to Smith’s beliefs about his medical situation. But that is very close to saying that he has the latter beliefs in virtue of having the former. So it seems that, if Burge is right, two people have incompatible beliefs in virtue of having the very same beliefs. To block this, Burge would have to say that it is not solely in virtue of having these various other beliefs that Smith believes in S, or that Smith* believes in S*. So even though Smith and Smith* share existential-descriptive beliefs like there is some malady x called “arthritis” that leads to excruciating joint-pain…their having these other beliefs is not the sole reason why they believe in S and S*, respectively. There is, Burge would maintain, an irreducible, causal component; and it is that purely causal, entirely non-descriptive component that makes all the difference. The problem is that this causal connection operates by way of knowledge that Smith and Smith* have of the already discussed existence-claims. For example, suppose that...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-128",
    "text": "One might think that the debate between externalism and internalism is just a matter of nomenclature. We can choose to let the word “perception” refer either to a certain kind of purely psychological phenomenon or only to successful occurrences of that phenomenon. Similarly, we can choose to use the word “thought” to refer either to a purely psychological phenomenon or only to successful instances of that phenomenon. The externalist chooses the one option; the internalist chooses the other. This is not a tenable position. A veridical perception decomposes into a purely psychological part and a non-psychological part. As we’ve seen, the non-psychological part is what is described by the purely psychological part. That is why the purely psychological part would have been a failure if the non-psychological part hadn’t existed. Similarly, if thoughts decomposed into a psychological part and a non-psychological part, then the psychological part of a thought would be something which would be a failure if the non-psychological part didn’t exist, the reason being that non-psychological part would be what was described by the purely psychological part. So in order for thoughts to decompose into a psychological part and a non-psychological part, the purely psychological part must itself be a thought; it must itself be true or false. But this means that the thought would be purely psychological, and that what we were just describing as the non-psychological part of the thought wouldn’t be a part of the thought at all, and would instead be what made the thought true.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-129",
    "text": "Content-externalism is incompatible with the presumption that, in virtue of having such and such representational properties, a brain-state has causal properties that it would not otherwise have. In any case, this is what we have argued. McDowell (Evans 1982: 203-204) tried to show otherwise. But Fodor (1987b) showed quite conclusively that McDowell’s argument is a non-starter; and Fodor’s counter-argument provided positive support for the thesis that McDowell was attempting to refute. But there is an argument for that thesis that is far more powerful than any thus far considered. That argument is due to Frank Jackson and Phillip. Working jointly, those authors have produced an original and compelling analysis of the concept of causal explanation. And they have argued that, given this analysis, there is no difficulty reconciling content-externalism with our presumptions concerning the causal potency of the mental. I should begin by stating my position. I believe that what Jackson and Pettit say about causal explanation in general is important and correct and cogently argued. But, I will argue, the same cannot be said of their attempt to use these correct and deep insights to rescue content-externalism. In their attempt to save content-externalism, Jackson and Pettit have misapplied their own correct views. Jackson and Pettit have also attempted to use their insights into causation to defend functionalism against what appears to be a devastating objection to it. We will find that, once again, Jackson and Pettit have misapplied their own insights into causation; and we will also find that the aforementioned criticism of functionalism is in fact cogent.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-130",
    "text": "We have already seen why, supposedly, content-externalism is incompatible with the causal potency of the mental. So let us discuss why the same appears to be true of functionalism. It will help if we begin by focusing on the fact that it is states of affairs, not objects, that have causal properties. The rock didn’t break the window. What did do was the rock’s having various properties, e.g. its having a certain mass and moving a with a certain velocity. Similarly, it is not brain-state β that does any causal work – it is brain-state β’s having such and such thermal (or morphological or electrical or representational or syntactical…) properties that does so. Let B be the brain-state (or structure or series of events…) that realizes Smith’s belief that 1+2=3. According to functionalism, B realizes that belief entirely in virtue of what its causes and effects are. So B qualifies as such a belief because circumstances at least approximately like the following hold. Given that Smith already believes that 3 is an odd number, B’s existence leads Smith to believe 1 and 2 add up to some odd number. Given that Smith already believes that Jones has one car, and two motorcycles, and no other motorized vehicles, B’s existence lead Smith to believe that Jones has exactly three motorized vehicles. Given that Smith already believes that three is the successor of two, and that adding one to a number is the same as generating its successor, Smith (an English-speaker) says “three” when asked “what is 1+2?” Of course, given only what we have said about Smith, he needn’t have a belief that 1+2=3. Smith’s possession of the dispositions just described could be explained without imputing such a belief to him. A closely related point is that Smith’s belief that 1+2=3 is not exhausted by his having just those three dispositions. But the idea behind functionalism is that Smith’s belief is exhausted by those three dispositions plus a large number of other dispositions of a similar kind. According to functionalism, B’s being a belief that 1+2=3 is identical with its having a certain functional role. So B’s being such a belief consists in (inter alia) its leading Smith, under the right circumstances, to forming the belief that 1 and 2 add up to an odd number; it consists in its leading Smith to forming the belief that Jones has three motorized...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-131",
    "text": "Let us suppose that, in world W, (*) describes an actual causal relationship, i.e. let us suppose that (*) is as true a causal statement as a lay-person (someone who has not mastered the subtleties of micro-physics) will ever produce. W is governed by the same physical laws that govern our world. (W may even be our world.) Granting all of this, it was not, strictly speaking, the flame that caused the pan to heat up. It was not even the flame’s having a certain temperature. The only events that really did any work in the way of heating up the pan were various mass-energy displacements at, or vanishingly close to, the relevant surface of the pan. Let M1…Mn be the mass-energy displacements at the point of contact between the flame and underside of the pan. Now consider a scenario W* that is just like W, with just one difference: in W*, the flame in its entirety is absent except for M1…Mn. In W*, the pan will have he very same temperature that it has in W. It seems, then, that the flame didn’t do anything, except in so far as it comprised M1…Mn. This seems equivalent to saying that it was M1…Mn, and the flame, that heated the pan. If this is right, then (*) is false. Leaving aside the causal statements made by a few microphysicists, what we just said about (*) is true mutatis mutandis of every causal statement has ever been uttered. Consider the statement:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-132",
    "text": "Suppose that (**) holds in world W, where W is governed by the same laws as ours. As Jackson and Pettit point out, it was not the squareness of the peg that prevented it from entering the whole; it was specific resistances generated by specific interactions of specific parts of specific surfaces. In order for those resistances to be generated, it isn’t necessary that the peg be square. The corners of the peg are not, in this context, doing anything: if we sawed them off, the peg still wouldn’t go into the hole (assuming, of course, that we sawed off only modest amounts); we’d be left with a heptagon that would fail to go into the hole for the very same reasons as the square. The forces that prevent the peg from entering the whole are invariant xxx with respect to infinitely many different possible alterations of the pegs shape and size, so long as those alterations fall within certain limits. Thus, it seems false to say that the peg’s squareness is what prevented it from entering the whole. Rather, what we must say is that specific forces (or mass-energy displacements or…) F1…Fn, occurring at contact points C1…Cm, are what prevented the peg from entering the whole. But surely it wouldn’t be right say, without qualification, that (*) and (**) were false. It is a datum that (*) and (**) are (or can be) true. Leaving aside the utterances of a few microphysicists, not a single causal statement produced by anyone contains any mention of anything comparable to M1…Mn. If it is a datum that true and informative causal statements are almost always given by statements like (*) and (**); and, notwithstanding the points made a moment ago, it is therefore not an option to say, without some kind of heavy qualification, that they are false. One last example. The pressure of the gas inside the container xxx is increased (because that gas is heated). The container subsequently bursts. What caused the vessel to burst was not, strictly speaking, the gas’s having (or suddenly acquiring) a certain pressure. Ultimately it was specific impacts of specific particles on specific parts of the surface of the container that led to the bursting of the vessel. Given a counter-factual scenario where those specific impacts occurred, but where the container was otherwise empty of gas, the container still would have burst. Given this, it...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-133",
    "text": "my statement is not in the same category as “the container burst because elves used their telepathic powers to make the container explode.” How is the putative truth of (***) to be reconciled with the fact it was certain specific collisions K1…Kn, and not the gas’s pressure per se, xxx [comma inserted] that ruptured the vessel? How are the truth of (*) and (**) to be reconciled with the fact that, strictly speaking, it was E1…En and F1…Fn, and not the flame or squareness of the peg per se, that heated the pan and prevented the peg from entering the hole? Jackson and Pettit deal with this problem by distinguishing between what they call “causal efficacy” and what they call “causal relevance.” It must be kept in mind that these are neologisms that are to be understood strictly in terms of the definitions that Jackson and Pettit provide. Their pre-existing meanings are to be set aside (except in so as those coincide with the meanings given to them by Jackson and Pettit). In connection with this, Jackson and Pettit distinguish between what they call “program causes” and what I will henceforth refer to as “effective causes.” (The term “effective cause” is my term. A state of affairs E is an “effective cause of” of E* iff E is causally efficacious with respect to E*. Any similarities between my use of the term “effective cause” and Aristotle’s are unintended and are to be disregarded.) Let us now define these terms – or, in any case, let us illustrate their meanings. Consider statement (*). Events E1…En are causally efficacious with respect to the heating of the pan. They are causes of the heating of the pan in the strictest possible sense. As we discussed, the flame itself is, from some viewpoint, quite inert as regards the heating of the pan, except in so far as it comprises E1…En. But, as we also pointed out, there is plainly a sense in which (*) is true; there is plainly a sense of the word “cause” in which the flame (or, more precisely, it’s having such and such properties) is a cause of the heating of the pan. The flame (or, rather, its having such and such properties) is, as Jackson and Pettit put it, “causally relevant” to the heating of pan. If one event is causally relevant, in the relevant technical sense of that...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-134",
    "text": "These remarks help to make it clear at an intuitive level what is meant by the terms “program cause” and “causally relevant.” Let us now try to convert that intuitive understanding into an explicit definition. Although the flame per se is not causally efficacious with respect to the heating of the pan, the existence of the flame guarantees the occurrence of events that are thus efficacious. Let W^ any counterfactual scenario where E1…En do not occur, but that is otherwise just W (the world where (*) is true). Of course, in W^, the flame exists, and the relation that it bears to the pan in that world is comparable to the relation that it bears to the pan in W. Thanks to the existence of the flame, the pan will be heated in W^: it is guaranteed that, in W^, some micro-events will have the effects on the pan that, in W, are generated by E1…En. Under the circumstances, the flame’s presence thus programs for the heating of the pan: it constitutes a structure that, under the circumstances, renders inevitable the heating of the pan. Equivalently, the flame’s presence is causally relevant to the heating of the pan. (Remember that, in this context, the term “causally relevant” is being used in a neologistic sense.) Analogous remarks apply to each of the scenarios discussed. Although the squareness of the peg per se is not efficacious with respect to the peg’s resisting being put in the hole, the squareness of the peg guarantees the presence of forces that are thus efficacious. Given any world where F1…Fn (the forces that, in actuality, prevent the peg from entering the hole) are absent, but is otherwise just like our world, the fact that the peg is square guarantees that some forces will prevent the peg from entering the hole. The squareness of the peg constitutes a structure that, under the circumstances, prevents the peg from entering the hole, even though this outcome is not generated by the squareness of the peg per se. Under the circumstances, it is inevitable that the container will burst, given that the gas inside is exerting such and such a degree of pressure on its walls. The gas’s having that pressure guarantees that, even if K1…Kn specifically are absent, some collisions or other will cause the container to rupture. Under the circumstances, the gas’s having that temperature programs for (or,...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-135",
    "text": "Let us now discuss how, given the distinction between causal relevance and causal efficacy, Jackson and Pettit attempt to show that content-externalism is in fact compatible with the presumed potency of the mental. Let W be our world, and let W* be a world that is just like ours except that it contains XYZ as opposed to H2O. In W, I see a glass of water (H2O) and, being thirsty, I decide to drink its contents. In W*, I see a glass of XYZ and, being thirsty, I decide to drink its contents. The content-externalist says that the contents of my perception and subsequent intention in W are different from the contents of my perception and subsequent intention in W*. In W, I see, and wish to drink, a glass of H2O. In W*, I see, and wish to drink, XYZ. Here is what the internalist says in response. What does all the work is what is spatiotemporally local. What is remote does no work, except in so far as it leads to the right local states of affairs. So what is in the glass is irrelevant to what I think or do, except in so far as it leads to the right local events. Equivalently, given the right local events, it is irrelevant, so far as the generation of my ideation and conduct are concerned, what remote states of affairs obtain (or used to obtain). Thus, in so far as mental state’s content is a function of what is remote, its content is inert; a mental state’s content is not inert only in so far as that content is a function of what is local. Mental content does nothing, and thus has no effects, in so far as the content-externalist’s conception of it is correct. Given that mental content does have effects, the content-externalist’s position must be wrong. Jackson and Pettit counter-respond by saying that this argument fails to distinguish between causal relevance and causal efficacy. My thinking about H2O is not causally efficacious with respect to forming an intention to drink the contents of the glass. But given that I am thinking about H2O, it is guaranteed, under the circumstances, that I will form that intention. True – my thinking about H2O does not supervene on what is local (intra-cranial). True – what is causally efficacious is confined to what is local. But it doesn’t follow that my...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-136",
    "text": "First of all, the distinction between causal relevance and causally efficacy – between program causes and effective causes – is an entirely correct one; and it is, in my view, of the highest importance.[125] Explanation almost always consists in identifying program-causes, not effective-causes; and this is not simply because of we are not always in a position to identify effective-causes. Jackson and Pettit convincingly argue that one is typically given much more predictive, explanatory, and counterfactual information if one finds out what the program-causes of an event are than if one learns what its effective-causes are (Jackson and Pettit 2004d). Their arguments on this matter strike me as cogent, and I have nothing to add to them. But we must regard as fallacious their attempt to show that, given the idea of a program-cause, content-externalism is consistent with the presumed causal potency of the mental. There are several reasons for this. Suppose we want to know whether Max’s thinking about R has any causal powers at all – whether it is xxx either causally efficacious or causally relevant to anything Max thinks or does. Fodor has made it clear that the relevant question is not “given that Max is thinking about R, is there some kind of guarantee that he will do such and such?” Rather, the relevant question is: “given that Max is thinking about R, is there some kind of guarantee that he will do such and such that would be absent if he were thinking about R*?” More simply: “Does Max’s thinking about R have any causal properties that his thinking about R* would not?” The externalist says: “xxx yes – because he is thinking about R, not R*, he has a desire to take a photograph of R, but of R*; he has a surge of joy in response to R’s aesthetic properties, and not in response to R*’s.” But that answer, we have seen, is irrelevant. Remember what we said in Chapter 1. I quote:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-137",
    "text": "Magnet A is attracted to magnet B. Magnet B happens to be green. But (ceteris paribus) if B were red or purple or orange, A would still be attracted to it. It is true that, because B is green, A is behaving in a way that it would not behave if B were some other color. (A is drawn towards a green magnet, instead of a red one.) But it doesn’t follow that B’s color has anything to do with A’s behavior. A’s behavior wouldn’t (ceteris paribus) be relevantly different in a world where B were some other color. This shows that B’s being green has no effect on what A does, notwithstanding that, because B is green, A is doing something (namely moving towards a green magnet) that it wouldn’t be doing if B were red. For exactly similar reasons, given only that Max has a desire to take a picture of R, as opposed to R*, it doesn’t follow that his thinking about R has any effect on his thought or conduct that this thinking about R* would not. The distinction between causal efficacy and causal relevance is irrelevant here. Ten minutes ago, the pan was cold. Now it is hot. I want an explanation. (To facilitate exposition, let’s suppose that I haven’t yet assimilated the fact that fire heats.) I consider the various events that preceded the heating of the pan. I put on a green shirt (I was previously wearing a blue one). I played the piano. I turned on the light in the kitchen. I turned on the burner on which the pan was resting. I brushed my teeth. To figure out which of these events was responsible for the heating of the pan, I take a tour all those worlds that are just like this one, except that they don’t comprise one of the events just mentioned. (The epistemological equivalent of this tour could be accomplished through experimentation – through employment of Mill’s methods, or some such. We can see talk of this metaphysically impossible tour as a way of condensing a long and tedious description of highly possible experiments that could be conducted within a single world.) So in W1 I don’t put on a blue shirt; but otherwise W1 is just like our world. In W2 I don’t brush my teeth; but otherwise W2 is just like our world. And so on....",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-138",
    "text": "The answer to that question is obviously “no.” By hypothesis, the proximal causes in W^ of my thought and behavior would be identical with their proximal causes in our world. True – in W^, those proximal causes would lead to my grabbing glass X as opposed to glass Y. But given how we’ve described W^, it follows tautologously that it is X that I will reach for, and not Y. When we wish to assess causal potency – whether in the form of causal efficacy or causal relevance – we obviously don’t want to study the logical consequences of our definitions. Supposing that the content-externalist’s position is correct, it is indeed guaranteed that the glass’s being a constituent of my mental content has various effects on what I think and do. But the guarantee in question is of a logical, indeed a tautologous, nature; it is not a causal guarantee. Another example may be appropriate. I am gazing at the heavens with my high-powered telescope. I see star X. Because X is so beautiful, I am filled with joy. Given this, let us suppose for argument’s sake that content-externalism is correct. In that case, X is a constituent of the representational content of my perceptual and cognitive states (in particular, of the aesthetic attitude just described). But, we may suppose, X ceased to exist millions of years ago. (I can see it because it took millions of years for the relevant light-rays to travel from X to my retinas.) The externalist seems to have a problem – actually two problems. First, he is forced to say that X is a constituent of the content of my visual perception. Given that X doesn’t exist, it follows that, for the content-externalist, my perception does not have a complete content: it as a gap where there is supposed to be a star. But my perception does have a complete content, and content-externalism is therefore wrong. It isn’t clear how the externalist is to respond to this, given that my visual perception has a content – a complete content, not one that has a gap in it where X is supposed to be.[126] But let us suppose that content-externalism can deal with this problem. Supposing that content-externalism is right, my thinking about X – i.e. X’s being a constituent of the contents of my mental states – supervenes on processes that went out of...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-139",
    "text": "The flame is contemporaneous with the events are causally effective with respect to the heating of the pan; indeed, the latter are constituents of the former; and therein lies the nature of the causal relation between the flame and the heating of the pan. But X ceased to exist millions of years ago. The same is true, of course, of the specific state of affairs involving X that is responsible for my perception (namely, X’s deflecting such and such light-rays in the direction of Earth, or some such). So nothing that is an effective cause of anything that I think or do could possibly be a constituent of any state of affairs involving X. Given this, it should be apparent that Jackson and Pettit are over-extending the term “program-cause” – that they are using it to denote two quite difference concepts. Supposing that content-externalism is correct, X’s being a constituent of my mental content does indeed guarantee that there will be certain modifications of my neural (or mental) condition. But the nature of this guarantee is logical, not causal, and it is a tautologous consequence of the content-externalist’s position. That position is the view that X’s being a constituent of my mental content is identical with X’s being a cause (of some kind) of some current, and therefore causally potent, condition of mine. So given the content-externalist’s position:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-140",
    "text": "By contrast, the connection between the presence of the flame and the heating of the pan – or between the temperature (pressure) of the gas and the rupturing of the vessel or between the squareness of the peg and its resistance to entering the hole – is entirely synthetic and a posteriori. This connection is given by a synthetic a posteriori proposition, and is therefore not a tautologous consequence of our definitions. What led Jackson-Pettit astray",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-141",
    "text": "What obviously is causally responsible for Smith’s current condition is the fact that, millions of years ago, X deflected some light-ray in Earth’s direction, and that light-ray eventually collided with Smith’s retinas. So, quite obviously, some state of affairs involving X affects what Smith is now thinking and doing. But it doesn’t follow that X’s being a constituent of Smith’s mental content is one of those states of affairs. Further, it would make little to say X’s being such a state of affairs was one of the states of affairs involving X that had any kind of effect of Smith’s current condition. In fact, it makes little sense to speak of a “state of affairs” here at all.[127] There is no time during which both X and Smith exist. So it is hard to see how there could be any state of affairs, in any causally significant sense of the term, consisting of X’s being a constituent of Smith’s mental content. A fortiori it makes little sense to say that X’s being a constituent of the contents of those states has any effects on Smith. And even though it follows from the content-externalist’s position that some state of affairs involving X must have an effect of Smith’s current condition, given that X is a constituent of Smith’s mental contents, it does not follow, as we saw a moment ago, that X’s being such a constituent has any such effects. Consider the flame. There are infinitely many times t such that, at t, we can truly say: the flame exists. That is why, for many times t, the flame is operational: it heats; it burns; it sooths; it torments. The same is true of the squareness of the peg, the temperature of the gas, and anything else that is a relatum of a true causal statement. There is no time t such that, at t, we can say: star X’s being a constituent of Smith’s mental is doing such and such. After all, there is no time at which X’s being such a constituent exists, given that X and Smith are separated by an interval of millions of years. Of course, if the externalist is right, the noun phrase “X’s being a constituent of Smith’s mental content” is not an empty one. But not every non-empty noun-phrase denotes a state of affairs, if by “state of affairs” we mean something of...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-142",
    "text": "is true. x’s coughing explains the conductor’s becoming annoyed in approximately (but only approximately: see below) the same way that the flame’s presence explains the pan’s becoming heated. x’s coughing is not causally effective with respect to the conductor’s becoming annoyed. What is thus effective are various neural events N1…Nn that are confined to the interior of the conductor’s cranium. x’s coughing (or, in actuality, some causal successor of x’s coughing) programs for the occurrence of N1…Nn. In fact, what is going on is much more nuanced than Jackson and Pettit allow. First of all, it isn’t every aspect of x’s coughing that is responsible, on any delineation of the term “responsible”, for the conductor’s becoming annoyed. Rather, what happens is this. Among the mass-energy displacements constitutive of x’s coughing are various micro-events. Those micro-events lead to other micro-events. And so on, until we have some set of micro-events that lead to various micro-events that are constitutive of some physiological condition on the part of the conductor. That condition is related to the conductor’s becoming annoyed in the way that the presence of the flame is related to the heating of the pan. Among the constituents of that condition are various micro-events that effectively-cause the micro-events constitutive of the conductor’s becoming annoyed. Jackson and Pettit say that (SC) is related to the conductor’s becoming annoyed in the same way that (*) is related to the pan’s becoming hot. In other words, they say that somebody’s coughing (not this or that person’s coughing, but just somebody’s doing so) is related to the conductor’s becoming annoyed in the way that the presence of the flame is related to the heating of the pan. But that is false for many reasons. First of all, unlike the presence of the flame, somebody’s coughing (as opposed to Brown’s coughing or Smith’s coughing) isn’t a state of affairs. As Russell (1903) said, you never just meet a person. You meet Bob or Mary or Jane. Similarly, you never just hear someone coughing; you hear some specific person doing so (even though you may have no idea who that person is). It is true that (SC) does provide a perfectly good explanation as to why the conductor became annoyed. But the reasons for this are quite delicate and cannot be straightforwardly modeled on the relationship between (for example) the presence of the flame and the heating of...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-143",
    "text": "Brown’s answer is obviously correct, and it provides a perfectly good causal explanation of the fact that Smith’s question concerns. But the cause of a xxx particle’s being displaced must be vanishingly close to that particle. The expression “the fact that A and A* are struck with the same degree of force” doesn’t refer to anything that is vanishingly close to either A or A*. In fact, it doesn’t refer to anything that has any spatio-temporal location. Given this, how can Brown’s answer be correct? Here is what Jackson and Pettit say. Given the truth of (SAF), along with some accepted principles of physics, the truth of (AM) is guaranteed. Of course, Jackson and Pettit are right: (AM)’s truth is guaranteed. But the nature of that guarantee isn’t comparable to the guarantee that the flame’s presence provides for the heating of the pan. As Jackson and Pettit themselves point out, the fact that A and A* are struck with the same force isn’t a state of affairs. (The result of putting quotation marks around the italicized expression doesn’t pick out anything that has spatio-temporal boundaries, even of the most nebulous sort.) Brown is providing a good causal explanation. But that explanation is more akin to that provided by (SC) than to that provided by (*). Brown’s explanation combines logical and effective-causal components. Let us start with (SAF). As a matter of logic, this entails that for some specific value of F, some singular proposition of the form:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-144",
    "text": "And given (BAF), (SAF) logically follows. But what is important here is that there is no state of affairs consisting in the fact that A and A* are struck with the same force, and xxx there is no state of affairs consisting in the fact that A and A* are displaced by the same amount. By contrast, the flame’s being beneath the pan at t and the pan’s having temperature T at t* are both states of affairs: they are spatio-temporally located entities; the expressions that denote them are not nominalizations of abstract relationships or generalizations over singular propositions. Thus, the relationship between (SAF) and (AM) is not comparable to that holding between the flame’s presence and the pan’s temperature.[129] The problems with the Jackson-Pettit attempt to save functionalism can be distilled into the following argument. At time t, I have an intense desire to drink ice-water. Let B be the brain-state that realizes that desire. At that same time, I see a glass of ice-water in front of me. Because I am thirsty, I grab it and drink its contents. It is intuitively clear that, at t, it is my desire for ice-water that causes me to drink the contents of the glass. So my desire for ice-water is active at t. Thus B’s being a desire for ice-water is active at that time. If content-externalism is right, then B’s being such a desire supervenes on its functional role. (Let R be that role.) But B’s having such a role is not causally potent at t. The expression “B’s having functional role R” denotes an abstract property of a sequence of events. In this respect, it is less like the expression “the squareness of the peg” than it is like the expression “the fact that people gravitate towards extreme political positions in crisis-conditions.” Functionalism cannot accommodate the fact that, at t, my desire for ice-water is doing any work. Of course, given that B has R, it is guaranteed that, at t, I will grab the glass and drink its content. Jackson and Pettit correctly point this out and, on this basis, hold that functionalism is compatible with the causal potency of the mental. But this response overlooks one crucial fact. The just-mentioned guarantee is logical, not causal. Given that B has R, it follows tautologously that I will drink from the glass. But causal relations are not expressed...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-145",
    "text": "The concepts of a program-cause and of program explanation are of the highest importance. But for program-explanations, explanation would be impossible, outside of microphysics. (Also, for reasons that I haven’t given, but that Jackson and Pettit do give (2004d), explanations in terms of program-causes are in some ways more informative than explanations in terms of effective causes. Even though biological facts are realized by physical micro-facts, biology can capture principled regularities that micro-physics cannot.) A paradigm of a program-cause is the case of the pan’s heating in consequence of the flame’s being put underneath it. The concept illustrated by this paradigm is an important one. This concept is instantiated by sequences of states of affairs such that the first states of affairs is literally composed of the events that effectively cause the second state of affairs. But we render the term “program cause” ambiguous, or lacking in any coherent meaning, if we start using that term to denote relations that don’t hold between states of affairs. Noun-phrases – even non-empty ones -- don’t always denote states of affairs. The expression:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-146",
    "text": "Because functionalism is practically an orthodoxy among students of the mind, it is worth our while to state some additional arguments against it, so as to reinforce our conclusion that it is false. We will see that the objections to functionalism raised by these additional arguments are naturally understood as corollaries of the fact that functionalism is incompatible with the causal potency of the mental. Suppose that, because he has brain-state B, Smith says “three” when asked “what is 1+2?” Even though B is what mediates between perceptual input (his hearing the question “what is 1+2?”) and behavioral output (his saying “three”), it doesn’t follow that any arithmetical belief of his was involved. It could be that, because of B’s electrical properties, the sounds he heard triggered an involuntary laryngeal spasm which led to his producing the sound “three.” An analogous point holds with regard to any other example of a case where B mediates between cause and effect in a way that is characteristic of a belief that 1+2=3. One day Smith learns that Jones has one car and two motorcycles, and no other motorized vehicles. For some reason, he finds this knowledge very exciting. This causes his heart to race. Given B’s electrical properties (not its representational properties), this causes Smith to form the belief Jones has three motorized vehicles. Given the input (Smith’s learning that Jones has two motorcycles and a car), B leads to the right output (Smith’s believing that Jones has three motorized vehicle). In other words, given the input, B leads to the same output as a belief that 1+2=3. But we clearly don’t have a case where Smith’s believing that 1+2=3 led to his having the right belief. We have a situation where dumb luck simulated the operation of such a belief. In general, if B mediates between input and output in the wrong way, then B isn’t a belief that 1+2=3, regardless of whether B consistently assigns the right output to any given input. The functionalist has a response to this:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-147",
    "text": "That is entirely correct. But we mustn’t confuse issues relating to what B is with issues relating to how we ascertain what B is. Supposing that B always produces the right output, that is excellent evidence that B is a belief that 1+2=3. But we’ve just seen that, given any instance where B generates the right output, B’s generating that output can, in principle, be explained without supposing that B realizes a belief that 1+2=3. Given any number of instances where B generates the right output, that fact can in principle be explained without having to suppose that B realizes a belief that 1+2=3. This means that the statement B mediates between input and output in a way characteristic of a belief that 1+2=3 does not analytically entail, and is not analytically entailed by, B is a belief that 1+2=3. Of course, as we’ve noted, if B mediates between input and output in a way that is characteristic of such a belief, then refusing to characterize B as such a belief may be nothing more than childish skepticism. But given that such skepticism is not 666 incoherent and that it is not analytically false, it follows that B’s mediating between input and output in the right way is merely evidence of B’s being a belief that 1+2=3, and is thus not constitutive of its being such a belief. There is another, similar argument against functionalism.[130] Suppose that B assigns the right output to a thousand different inputs. (For example, given that Smith has just heard “Brown has 1+2 bicycles”, B leads Smith to say “therefore Brown has 3 bicycles.”) Given the evidence, it is likely that B is a belief that 1+2=3. But that same evidence is consistent with the hypothesis that B is a belief in some “bent” proposition, e.g. 1+2=3 – except when the objects being added are insects: in that case, 1+2=4. So as long Smith hears or reads anything having to do with insects, B will assign the same output to any given input as a belief that 1+2=3. But if Smith hears “there are two cockroaches in Brown’s room, and one ant, and no other insects”, Smith says “therefore there are four insects in Brown’s room.”[131] In general, no matter how often B generates the right output, it is a possibility that B mediates a belief in some proposition other than 1+2=3. Given that this...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-148",
    "text": "We must begin by discussing a doctrine that we will refer to as “conceptual atomism.” Some background is needed before we can say what that doctrine is. According to the view that we have put defended, for any spatiotemporal entity x, my having a concept of x involves my knowing some description that x satisfies. An immediate consequence of this view is that in order to have a concept of any spatiotemporal object, one must already have concepts. Where such objects are concerned, there is no possibility of conception in a vacuum of other concepts. Of course, not everybody will agree that our particular view of conception is the right one. But what is generally, though not universally, accepted is that possession of one concept presupposes possession of others.[133] As we discussed earlier, it seems preposterous to assume that an otherwise conceptless creature could have a concept of Socrates or of the Washington Monument. It seems even more preposterous to assume that an otherwise conceptless creature could have thoughts about theoretical entities, such as electrons or neutrinos. There doesn’t seem to be any spatiotemporal entity x such that one could have a concept of x without having a concept of anything other than x. The idea that one’s x-concept could exist in isolation thus seems to be a non-starter (Berkeley 1934, Sellars 1963, Bonjour 1985, Peacocke 1992, Kuczynski 2003, 2004). Concepts are not atoms; they are not self-contained units. Where there is one concept, there are many. Conceptual atomism is false, and conceptual non-atomism – conceptual molecularism or holism – must therefore be correct. In any case, this seems like a reasonable position; and our analysis is consistent with it, since it makes it a precondition for my having any concept of Socrates that I have a number of other concepts. Here we must make a distinction. In this work, we have discussed what it is to have a concept of a spatiotemporal entity. We have not discussed what it is to have a concept of a non-spatiotemporal entity – of a property or a proposition. So we have left it open whether conceptual atomism holds with respect to our concepts of abstracta. We will discuss this problem at length in Chapters 22-23. We will find that non-atomism is no more true with respect to our concept of abstracta than it is of our concepts of spatiotemporal entities. (Actually, in...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-149",
    "text": "Fodor has made it clear that, if one accepts content-externalism, one must advocate an atomistic conception of what it is to be aware of spatiotemporal objects. Fodor accepts content-externalism, and he thus accepts conceptual atomism. Even though many agree with Fodor that content-externalism is correct, few agree with Fodor’s conceptual atomism. But so far as one is a content-externalist, one is guilty of incoherence in rejecting Fodor’s atomism. As we will see, Fodor is an atomist across the board: conceptual atomism holds with regard to our grasp of both spatiotemporal and abstract entities. In Fodor’s view, an otherwise conceptless creature could grasp the concept of justice or number or money (1990, 1998). A creature that didn’t have concepts like society or property could, according to Fodor, have the concept of money. Of course, this is, on the face of it, an implausible view. But to echo what we said a moment ago, content-externalism demands that just this view be accepted. So supposing that content-externalism is correct, Fodor is guilty only of seeing what others fail to see. Fodor realizes that conceptual atomism is a counterintuitive doctrine. For this reason, he provides a number of brilliant arguments on behalf of it (Fodor 1998). He also successfully shows that a number of independently plausible positions actually demand an acceptance of atomism. (He does not, however, show that those independently plausible positions are correct. We will see reason to thin k that they are not.)",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-150",
    "text": "In this section, I would like to discuss why content-externalism demands an atomistic conception of conception. In this context, we will suppose for the sake of argument that content-externalism is correct. According to that doctrine, the contents of a mental state is a function at least in part of the origins of that mental states. Brainstates b and b* may have different contents even if, leaving aside their causal origins, they are qualitatively identical. For example, b may be a concept of Smith, while b* is a concept of Jones, even though (leaving aside their distal causes) b and b* are qualitatively identical, and are embedded in the same way in qualitatively identical nervous systems. It may help to recall the story that we told in Chapter 1. The information encoded in Max’s perceptions and subsequent thoughts is different from that encoded in Twin-Max’s corresponding perceptions and thoughts; and those differences lie entirely in the fact that the one person’s mental states have different origins from the others. They lie entirely in the fact that, after time t, Max’s perceptions and subsequent thoughts do, whereas Twin-Max’s do not, originate with some state of affairs that have rock R as a constituent. It isn’t as though, for Max and Twin Max to diverge in this way after time t, they must already differ in respect of what concepts they have. The just described differences between Max and Twin-Max don’t presuppose any conceptual differences. In general, if content externalism is right, two creatures can differ with respect to a single concept. X and Y can be absolutely identical except that, where X has a concept of Smith, Y has a concept of Jones. So it is a straightforward consequence of content-externalism that some concepts are atoms. A corollary is that atomism is false only to the extent that the content of a mental state is not a function of its causal origins. On pain of incoherence, one is an atomist to the extent that one is a content-externalist. Content-externalism is a form of atomism. Conceivably, one could be an externalist with regard to certain concepts (e.g. one’s concept of Smith) but a non-externalist with regard to other concepts (e.g. one’s concept of the number five). Indeed, I am sure that this is the position that most self-described content-externalists would take. If Smith and Jones are atom-for-atom duplicates of each other, then surely...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-151",
    "text": "So some description couched in terms of D1…Dn fixes the referent, but doesn’t give the meaning, of the term “quark.” Given this fact, it is obvious why there is no tension between, on the one hand, the obvious truth that theoretical entities are understood in terms of non-theoretical data and, on the other hand, the well-established thesis that statements about theoretical entities are not synonymous, or otherwise reducible to, statements about macroscopic data.[136] Because that data has a reference-fixing role, there are counterfactual scenarios where those same theoretical entities generate very different experimental data. So the counterfactual properties of statements about that experimental data don’t track the counterfactual properties of statements about those theoretical entities; and this thwarts attempts to reduce the one set of statements to the other. Fodor’s reasons for accepting conceptual atomism",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-152",
    "text": "Fodor sees very clearly that conceptual atomism is a direct consequence of content-externalism. So given how implausible atomism is, why doesn’t Fodor reject content-externalism? Before content-externalism even existed[137], Fodor (1968, 1975) advocated the so-called Computational Theory of Mind (CTM). As Fodor has always realized, CTM demands an acceptance of conceptual atomism. So Fodor correctly sees CTM as providing independent corroboration for the atomism demanded by content-externalism. Fodor also advocates the Symbolic Theory of Thought (SCT). As Fodor realizes, CTM demands SCT. But Fodor also sees clearly that, apart from its connection with CTM, there is much support for SCT. So Fodor correctly sees SCT as providing independent corroboration for the atomism demanded by content-externalism. It is no surprise that no one has argued more powerfully than Fodor for either CTM or SCT. As previously noted, Fodor’s arguments for CTM are intertwined with his arguments for SCT. Let us now consider those arguments",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-153",
    "text": "Before we consider the reasons for accepting CTM, we must ask: what does the word “compute” mean? What is it to perform a computation? Right now I could perform a computation; I could compute a sum (i.e. I cold add two numbers). But given that interpretation of the word “compute”, (*) is patently false, at least as a general statement about cognitive activity. A precondition for my adding two numbers is that I already have many thoughts, and that I have a wealth of concepts. I must know various symbolic conventions (e.g. that “1” denotes the number one); I must grasp various mathematical principles; I must have cognitive wherewithal to have perceptions of enduring physical objects (e.g. the paper and pencil that I will use to compute the sum in question) and also to synthesize those perceptions into a body of mnemic information on which I can draw as circumstances require (I won’t be able to add if I can’t keep track of the various figures I write down, or of what my reason for doing so was). So if the word “compute” is taken in its customary sense – in the sense that it bears in statements like “Smith is performing a computation” – then the existence of computations is actually an extremely derivative form of mental activity and, consequently, CTM is viciously circular. Fodor is aware of this problem, as are most advocates of CTM. In an attempt to avoid this vicious circularity, advocates of CTM define the terms “compute” and “computation” as follows:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-154",
    "text": "As we will see in a moment, there are excellent reasons to advocate CTM. But before we consider those reasons, we must make a couple of points explicit. CTM is obviously committed to the idea that we think in symbols – that the basic units of thought are expressions and that, consequently, we think in a language. A consequence is that CTM is committed to conceptual atomism. If, as CTM requires, we think in a language, then its expressions are our concepts. Any language must have ultimate units of significance (also known as “morphemes”). Given any language, some of its expressions are complex, and others (“Socrates”) are simple. It isn’t possible for every expression of a language to be complex. So supposing that we think in a language, some of the expressions of that language are simple and foundational, and all the rest are built out of those simples. This means that some of our concepts are simple and foundational – they are atoms – and the rest are built out of those atoms. CTM is thus committed to conceptual atomism. There is a possible objection to this:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-155",
    "text": "There are several points to make here. The first of these points is made by Fodor himself (Fodor 1998: 13[140], Fodor and Lepore 202: 101[141]). If one accepts CTM, one cannot advocate any form of CRS. CTM is trying to account for cognitive behavior in terms of operations on symbols. According to CRS, something can be a symbol only if it is already a part of a pattern of inference-making. So CRS makes the having of vast networks of thoughts be a pre-requisite the use of any symbols. Thus, to avoid vicious circularity, any identification of thought with the manipulation of symbols must not accept a CRS-account of meaning; and any such identification must accept the conventional view that some of the symbols of any given language are foundational and atomic, and are thus not to be defined in terms of other symbols belonging to that language. So whatever merits it has a general statement about language, the objector’s point is irrelevant in this context. But not only is the objector’s point irrelevant: it is also demonstrably false. “Socrates” doesn’t have the same semantics as “Aristotle.” But nothing is entailed by “Socrates snored” that isn’t also entailed by “Aristotle snored”; and “Socrates snored” doesn’t entail anything not also entailed by “Aristotle snored.” Of course, what we just said about “snored” is true of any other predicate. So an inferential account of the semantics is incapable of discriminating between “Aristotle” and “Socrates” and, in general, between any two proper names.[142] One could side-step this last point by saying that, given what we’ve learned about Aristotle and Socrates, “Aristotle snored” does have different entailment-relations from “Socrates snored”. Given our historical knowledge, the one does, while the other does not, entail “the author of the Metaphysics snored”; and the one does, while the other does not, entail “somebody who died of hemlock-poisoning snored.” But, as Fodor and Lepore (2002: 101) say, if we take that point of view, then every sentence of the form ┌Aristotle has phi┐ that we know to be true becomes an analytic truth. The sentence “Aristotle died before his 90th birthday” becomes analytic. Since it obviously isn’t analytic, the point of view just described is false. Thus, CRS is both false and irrelevant; and we may therefore conclude that SCT is committed to conceptual atomism. An advocate of SCT could counter-respond by saying that the Mentalese symbol for Aristotle...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-156",
    "text": "Let us now turn to the question: Why advocate CTM? (The argument about to given is found in Fodor 1981: 13-17, 226-227, 1987: 18-20, 1994: 294-298.) Thoughts are identical with, or at least realized by, brain-activity. (In any case, this is a plausible and widely held view.) Brains are physical objects, and are therefore governed by the laws of physics. The laws of physics are not laws of rationality. Whether the billiard ball goes in this as opposed to that direction has nothing to do with canons of good reasoning. The same is true of our brains and of the various structures they comprise. All of these things are entirely physics-driven, and there would thus seem to be no room for canons of good reasoning to play any part. At the same time, our cognitive activity is rational, at least to a high-degree. Our thoughts follow one another in ways that are generally consistent with the canons of logical reasoning. But how is this possible, given that those thought-sequences are purely physics-driven and that the laws of physics have nothing to do with the canons of good reasoning? How is it possible for rationality to track physics, given that everything spatiotemporal falls within the scope of physical law and that physical laws are not laws of rationality? We will refer to this as the “tracking-problem.” CTM solves this problem. Symbols (or symbol-tokens, strictly speaking) are purely physical objects. But we can create environments in which they follow one another in ways that are consistent with the strictures of logic. Given a set of symbol-tokens, we can create environments such that, given the laws of physics and the physical properties of those symbol-tokens, the latter are physically compelled to form patterns that constitute rational ideation (Fodor 1981: 226, 1981b, 1987: 18-20, 1990: 22). Consider the symbols “Jerry is not bald”, “either Smith is tall or Jerry is bald”, and “Smith is tall.” We can create a physical environment such that, if the first two symbols are tokened (at more or less the same time) in that environment, then the first symbol is tokened in that same environment immediately thereafter. Here is another example. Consider the symbols “12”, “+”, “14”, “=”, “26”. We can create a physical environment such that, if the first four symbols are tokened (in that order) at a given time in that environment, then the fifth is tokened...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-157",
    "text": "There is an obvious apparent problem with CTM – but if one accepts content-externalism, that apparent problem turns out to be a virtue. Contrary to what CTM says, our thinking obviously is (or at least seems to be) semantics-driven. I believe that Smith is either in Iceland or in Jamaica. I then learn that he is not in Jamaica. On this basis, I conclude that he is in Iceland. Presumably it is because the first two thoughts have certain contents that they lead to my having the third thought. So supposing, as CTM does, that my having these thoughts consists in my various expressions being tokened in my brain, I obviously arrive at this conclusion on the basis of the meanings of those expressions, and not (merely) on the basis of their non-semantic properties. Thus, if indeed we think in symbols, our thinking is semantics-driven, and CTM is therefore false. Here there are two points to make. First, as we’ve already seen, if content-externalism is right, then content is causally inert. What is causally potent is always what is local; and, according to content-externalism, a brain-states having a certain content does not supervene on what is local: on the contrary, it supervenes specifically what is non-local – what is distal and purely relational and therefore causally hollow. So, as Fodor (1981, 1987b) clearly says, content-externalism is incompatible with the view that semantics is causally operative. Further, for a theory to be adequate, it must it must be consistent with the relevant data, and not with our a priori beliefs (except, of course, in so far as our a priori beliefs are consistent with the data). In this context, the data is that certain kinds of thoughts are likely to follow certain other kinds of thoughts. Just as there are regularities in the non-mental world, so there are regularities in the mental world; and the latter regularities are the data that a correct model of cognition must accommodate. It is not a datum that semantic content is what is responsible for those regularities. Here our comparison with physical theory may once again be useful. As Hume pointed out, it is not a datum that there are “forces” or “powers” in the physical world. Similarly, it is not a datum that, in the cognitive sphere, there are “semantic forces.” This isn’t to say that such thing don’t exist, but only that the...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-158",
    "text": "I would now like to argue that CTM is erroneous and that the arguments for it involve irreparable non-sequiturs. Let us start by putting forth one of the standard criticisms of CTM – a criticism that is probably coeval with CTM itself. Given any symbol-token S, and given any meaning (or referent) M, there is some possible language L such that S means M in L. In English, the symbol-token “Socrates” refers to Socrates. But there are possible languages in which refers to Plato and possible languages in which it doesn’t refer to anything. For exactly similar reasons, there is a possible language in which the symbol-token “4” refers to Socrates, a possible language in which it refers to the number seven, a possible language in which it refers to Pluto, and so on. Thus, if a computer transitions from “2+3=” to “5”, that is a valid transition only if it is assumed those shapes instantiate English symbols. That transition is valid only from the viewpoint of somebody who speaks English, and its validity therefore presupposes the existence of thought: it presupposes the formidable cognitive wherewithal needed for somebody to have mastered the relevant symbolic conventions. So computational processes presuppose cognitive ability, and therefore cannot be constitutive of it. (See Dennett 1978: Chapter 6, Lycan 1984: 237, Kuczynski 2002, Searle 1984, 1992.[143]) This line of thought is easily generalized. Given any sequences of physical events, there is some language L such that, in L, that sequence of events tokens a valid argument or a correctly executed mathematical operation. Indeed, given any sequence S of shapes, and given anything that can be encoded in language – be it a poem, a political speech, or a proposal for world peace – there is some language L such that S encodes that poem (or political speech or…) in L. Given that not every single sequence of events is an actual instance of a beautiful poem (or political speech or…) being articulated, it follows that no sequence of events has any meaning at all merely in virtue of its shape. If an event E has a certain meaning M, that is not merely in virtue of E’s morphology. Nothing means anything merely in virtue of its morphology. What is the advocate of CTM to say in this response to this point? One possible response is this:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-159",
    "text": "But then we have to ask: in virtue of what does 2 refer to two? Here is Fodor’s (1990, 1998) answer: 2 refer to two in virtue of the fact that the 2 has a certain causal connection to instances of the number two (i.e. to pairs of apples, pairs of shoes, and so on). Even if Fodor is right about this, it doesn’t help CTM. As we’ve seen, the fact that 2 has certain origins is causally and explanatorily inert. The fact that the beginnings of that symbol-token are to be traced to some state of affairs involving some particular pair of shoes is irrelevant so far as 2’s behavior is concerned. (Jackson and Pettit (2004) disagree. But we saw in Chapter 12 that the grounds for their disagreement are spurious.) So if indeed it is in virtue of its causal origins that 2 refers to two, then from the viewpoint of the description and explanation of brain-processes, 2 might as well be in the same category as some symbol that refers to Pluto or to the number five or to nothing at all. So given a content-externalist conception of mental content, 2 is indistinguishable from any other shape, at least as far as the analysis of psychological and neural activity is concerned. In that case, the very problem that we discussed recrudesces. The sequence 2+3=5 is, from every relevant viewpoint, indistinguishable from a symbol that means 2+3=978 and from one that means snow is green and from one that means nothing at all. Given an acceptance of content-externalism, the objector’s position implodes, and our original criticism of CTM prevails. Thus, if the objector’s point is to prevail, semantics must be causally operative. It must be in virtue of its referring to a certain number that 2 has the causal role it does. But if semantics is operative, then CTM implodes, since the essence of that doctrine is that thinking consists in sequences of symbol-tokenings that are not semantics-driven. This connects with another point. As we’ve discussed, there is no intrinsic connection between “2” and two. (This point was famously made by Saussure 1966.) Whatever semantic connection holds between them is derivative of human thought and social practices; and this point mutatis mutandis holds of every symbol of every natural language. As we’ve seen, the connection between 2 and the number two cannot be conventional. The semantic connection between...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-160",
    "text": "As we’ve seen, the connection between a Mentalese symbol and its meaning cannot be conventional or otherwise mediated by thought. For CTM to work, 2 must naturally mean two. In that case, 2 is just a direct awareness of that number. On the one hand, we have a brain-state (consisting of some token of a Mentalese symbol); on the other hand, we have a number; and the former is a direct awareness of the latter. But it seems to be of the essence of symbolhood that a symbol is a kind of intermediary (Kuczynski 2002, Horst 1996). There is no symbolic awareness of Smith where there is a direct awareness of him. A symbolic awareness of Smith consists in my encountering some symbol like “Smith”, and duly interpreting it in the light of the relevant symbolic conventions. A direct awareness of Smith would consist in my seeing him. The two kinds of awareness are antithetical to each other. (Of course, I could read and understand a sentence like “Smith is wise” while also looking at Smith. But in so far as I am doing the one, I am not doing the other.) So unless we trivialize the notion of a symbol by saying that any awareness of anything is ipso facto symbolic, it isn’t clear how Mentalese symbols (so-called) have any significant similarity with actual symbols. This, of course, calls into question the viability of CTM, since that doctrine just is the thesis that thinking consists in symbolic-manipulations of a certain kind (Kuczynski 2002). Of course, an advocate of CTM could defend against this by saying that the word “symbol”, as used by CTM, is meant only in a metaphorical or otherwise extended sense. (This, in fact, seems to be the position taken by Fodor 1975: 65-67, Lycan 1984: 237, and other computationalists.) But in that case, CTM is reduced to the explanatorily innocuous platitude that thinking consist in operations involving things that are like symbols, in as much as both they and symbols represent things, but aren’t really symbols.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-161",
    "text": "But underlying CTM is a confusion even more insidious than any of those just discussed. CTM identifies thinking with form-driven, or formal, manipulations of symbols. The question is: what reason is there to believe that a purely formal operation on symbols could qualify as a cognitive achievement? On the face of it, a formal operation is the antithesis of one that is thought-driven. It is precisely when people don’t understand the formulas in front of them that they are forced to rely on mechanical procedures. Where a neophyte needs to fall back on a formal procedure to solve a problem (e.g. to derive an integral), a mathematician can generate the right answer on the basis of genuine insight into the concepts involved. The mathematician’s answer would seem to be more thought-driven than the neophyte’s and, in general, it would seem that a symbolic operation is formal precisely to the extent that it is not thought-driven. Nonetheless, there is some basis for CTM’s identification of formal manipulations of symbols with genuine cognitive achievements; and the grounds for that identification can be distilled into the following argument.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-162",
    "text": "By way of anticipation, we will find that (SYN) is unsatisfactory in many ways. (In particular, we will find that a knowledge of semantics is to some degree constitutive of a knowledge of syntax and that (SYN) is therefore wrong, since it demands that knowledge of syntax be entirely independent of knowledge of semantics.) But it is a good point of departure, since it is approximately correct. Also, because it is the answer given by advocates of CTM, we should grant it, if only for the sake of argument. If we show that CTM fails given (SYN), then we will have shown that CTM fails relative to its own assumptions, and is therefore uncontroversially false. Supposing that (SYN) is correct, it is clear why CTM cannot be accepted. Syntactic form is completely different from geometrical form. (We will use the expressions “morphology” and “morphological” to denote form in the geometrical sense.) First of all, morphology is a property of expression-tokens, not expression-types, since expression-types are abstract objects and thus don’t have morphology. Two morphologically identical expression-tokens can have completely different syntactic forms; and two syntactically identical expression-tokens can have two completely different morphologies. Consider the symbol-token “snow is white.” There is a possible language L in which that token, or at least one morphologically identical with it, means: if Beethoven had been born in 1400, he would have invented the fugue. Considered as an expression of L, that token has one syntactic structure. Considered as an expression of English, it has an entirely different syntactic structure. (Incidentally, this shows that what syntactic structure an expression has is a function of what it means – of its semantics: a point we will find to be of inestimable importance.) In general, a sentence-token’s morphology imposes no constraints on its syntax. Given any sentence-type, there is no limit to how different in respect of morphology two tokens of it can be. Consider the sentence-type: “snow is white.” That sentence could be tokened by sounds, hand-signal, light-rays, noises. And even within a single one of these media, there is little limit to how different in respect of morphology two tokens of that sentence can be. We could imagine a token of that sentence being uttered by someone with a very deep voice over a period of a year; and we could imagine a token of that same sentence being uttered by someone with a...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-163",
    "text": "(4)’s syntactic structure is a function of the meanings of the expressions of which it is composed. Suppose that one of the occurrences of “Smith” were replaced with an occurrence of an expression belonging to a different semantic category. In that case, the result would be meaninglessness. (Consider the sentence that would result if “Smith” were replaced with “cucumber.”) This shows that it is because “Smith” falls into a certain semantic category that (4) is characterized by a certain syntactic structure. Obviously (4)’s syntactic structure is determined, in part, by the fact that its main connective (“if…then…”) has a certain meaning; and that sentence would have an entirely different syntax, at least in the relevant sense of the word, if the main connective were replaced with a different one (e.g. “and” or “or”), let alone with an expression not belonging to the same semantic category as that connective. If you replace the occurrence of “Smith” in (4) with “Jones”, a sentence with the same syntactic structure results. But nonsense results if you replace that occurrence with an expression (e.g. “cucumber”, “elephant”, “not”) belonging to a completely different semantic category. A sentence’s syntax thus seems to lie in its more abstract semantic properties. A syntactic description of a sentence is a low-resolution description of its semantics. (Later we will replace this vague statement with a more precise one.) It follows that a manipulation of symbols is syntax-driven only if it is semantics-driven. As we’ve seen, CTM cannot countenance the idea that the symbolic manipulations constituting our cognitive processes are semantics-driven. Therefore those manipulations are not form-driven in the syntactic sense of “form.” We’ve already seen why those manipulations cannot be form-driven in the morphological sense. Aside from syntactic and morphological form, it isn’t clear what kind of form could possibly be relevant to CTM. It thus appears that no disambiguation of the word “form” validates the idea that our thinking consists in form-driven operations on symbols. So far as that idea has credibility, it is, I believe, because logical (or syntactical) form is being conflated with morphological form. This equivocation creates the illusion that purely morphology-driven operations can miraculously have the property of realizing logic-driven, and therefore cognitively pregnant, symbolic operations. Indexicality and the irreducibility of logical to syntactical form For the sake of argument, let us set aside everything just said. Let us suppose, solely for the sake of argument,...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-164",
    "text": "(*) There is no morphological characterization of syntax. (*) There is no syntactic characterization of logic. (*) There is no morphological characterization of logic. (*) A morphology-driven manipulation of symbols is not necessarily one that tracks either syntactic or logical form.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-165",
    "text": "We’ve seen that CTM involves a misunderstanding of the concept of “formal” truth and that it fails to realize that the relevant kind of form is semantic in nature. Let us now further examine the concept of formal truth. This will shed further light on the nature of the misunderstandings that underlie CTM. First of all, we must distinguish between analytic truth and formal truth. “Either it is raining or it is not raining” is formally true (as well as analytically true). By contrast, “anything wise is sentient” is not formally true, even though it is analytic. But what exactly is the difference between formal (logical) and analytic truth? Let us start by giving the conventional answers to this question. Sometimes a sentence is said to be “logically true” if it is true “under all reinterpretations of its non-logical constants”, where a “logical constant” is any of the following expressions: “if…then…”, “and”, “or”, “not”, “=”, “some”, “all.” Sometimes modal connectives, e.g. “possibly”, are put on this list (Quine 1970: 50). (Superficially, this definition seems to be circular, since the term “logically true” is defined in terms of the expression “logical constant” and thus in terms of the expression “logical.” But the circularity vanishes if the expression “logical constant” is taken as an abbreviated way of referring to the list containing all and only “not”, “all”, “=”, and so on.) Consider the following four sentences:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-166",
    "text": "(2) and (4) are both true, and (4) is what results when the non-logical expressions (“Fred”, “wise”, “cucumber”) are uniformly replaced with other non-logical expressions. (1) is true, and (3) is false. But (3) is what results when a non-logical expression in the former is replaced with a different expression. For this reason, (1) is not a logical truth, even though it would traditionally be regarded as an analytic or necessary truth (Quine 1970: 47-50). There are two reasons why this analysis of logical truth is unsatisfactory. Suppose that we defined the term “whole number” as “any number that is not a fraction or a real number or a quaternion or an imaginary number…” Our definition would be extensionally correct, but it would fail to put its finger on the property that all and only whole numbers have in common (apart, of course, from the negative and disjunctive property of not being either a negative number or a fraction or a real number…). Quine’s analysis of logical truth is guilty of a similar defect, since it defines a logical truth as one that is true under all substitutions of its component-expressions other than “and” and “or” and “=” and… Even if that analysis is extensionally correct, it doesn’t say what it is for a sentence to be logically true. This brings us to the second problem with Quine’s analysis: it isn’t extensionally correct. As Kaplan (1977, 1989) observed, sentence-tokens like “I am here now” are naturally described as logically true. But the analysis of logical truth under examination cannot accommodate that fact. By the same token, that analysis cannot accommodate the fact that “I am not here now” is logically false. Can we say that a sentence is logically true iff it encodes an analytic proposition? No. Given such a position, we couldn’t mark the obvious difference between",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-167",
    "text": "Given that (KB) means any case of knowledge is a case of belief, it logically follows that (KB) is true. But the semantic rules of English do not themselves assign truth to that sentence. Those rules merely assign a certain meaning to it. At that point, non-semantic (albeit purely conceptual and a priori) facts assign the truth-value true to it. English semantics rules do not themselves assign the truth-value true to (KB) (or any token thereof). But a token T of “I am here now” is in a different category from (KB). The rules of the language to which T belongs themselves assign truth to T. To see this, let us consider those rules, leaving out irrelevant technicalities. One of those rules is “if somebody x utters a token of ┌I have phi┐, that token is true, i.e. it is assigned the truth-value true, exactly if x has phi. Another is: “if in place x, there occurs token of ┌this place has phi┐ [or, equivalently, ┌here it is phi┐], that token is assigned the truth-value true exactly if x has phi. Yet another is of those semantic rules is: “if at time x, there occurs token of ┌this time has phi┐ [or, equivalently, ┌now it is phi┐], that token is assigned the truth-value true exactly if x has phi.” Given these, and a few other, strictly semantic facts, it follows that it is a theorem of English semantics that any token of “I am here now” is assigned truth. That is why any such utterance is logically true, even though what such an utterance semantically encodes is contingent and a posteriori. Another example may be appropriate. Any token T * of:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-168",
    "text": "is syntactically (or formally) true. To see why this is so, let us consider the semantic rules that assign meaning to such a token. (As before, we will set aside irrelevant technicalities.) One of those rules is: “a token of ┌it is not the case that S┐ is true, i.e. is assigned the truth-value true, iff S is false.” Another is: “A token of ┌either S or Q┐ is assigned the truth-value true iff either S is assigned is the truth-value true or Q is assigned that truth-value. Given these facts, and a few others of a strictly semantic nature, it follows that it is a theorem of English-semantics that T* is assigned the truth-value true. So T and T* are logically true because of how they are assigned the meanings that they in fact have. This suggests that syntax is an aspect of meaning, the same therefore being true of syntactic (“formal”) truth. Given what we’ve seen, a sentence-token’s syntax would seem to lie in how it means what it means (as opposed to in what it means). In a moment, we will substantiate this thesis as to the nature of syntax. We should point out that, if that thesis is correct, then T and T* are logically true because of how they mean what they mean, and their being formally true can be understood in terms of their morphology or, indeed, in terms of any other than semantics. The relevance of these points to CTM",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-169",
    "text": "Formal truth is semantic truth. Indeed, there is no notion that is more semantic than that of formal truth, since E is a formally true expression just in case E’s truth is a theorem of the semantic rules that assign it meaning. It is therefore clear that unless a creature is responding to the semantic properties of the symbols that it houses, it is not responding to the forms of those symbols, at least not in any relevant sense of the word. Our analysis is also consistent with the close connection between the concepts of formal truth and computation. A statement is formally true or formally false exactly if its truth-value can be computed on the basis of the rules that assign it meaning. One might make the following objection to this analysis:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-170",
    "text": "Even if this objection is correct, it concedes that semantic truth is a necessary condition for formal truth, and that objection thus doesn’t help CTM at all.[149] We’ve seen that the word “form” is ambiguous, and that CTM involves a failure to register this ambiguity. Points similar to those just made in connection with the word “form”, and in connection with CTM’s use of it, are true of a number of other expressions that occur in arguments on behalf of CTM and, more generally, in discussions on the foundations of mind. Among these other expressions are “automatic procedure”, “mechanical procedure”, and “algorithm.” Sometimes we say that there is a “mechanical” procedure for deciding whether a given sentence is true or not. Consider the following four sentences:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-171",
    "text": "(1) Either Smith is tall or Smith is not tall. (2) Smith is tall and it is not the case that Smith is not tall. (3) There are continuous functions that cannot be differentiated at any point. (4) It is false to say that laws are simply commands and do not necessarily differ in any significant respect from a gunman’s threats.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-172",
    "text": "No one would say that there was any mechanical way of determining whether (3) was true. In fact, (3) is true. But that was established on the basis of creative insight, not on the basis of an application of a mechanical test. The same point holds of (4), supposing that (as H.L.A. Hart argues[150]) it is in fact true. But there is a strictly mechanical procedure determining whether (1) and (2) are true or not. We need only apply the method of truth-tables. In this context, what does the term “mechanical procedure” mean? The naïve answer is to say that a mechanical procedure is one that a machine could implement. But a machine couldn’t determine whether (1) and (2) were true or not. Obviously there is no reason why we couldn’t construct a machine that scanned (1) and (2), and then wrote “true” next to (1) and “false” next to (2), and did the same for any other sentence whose main connective was a truth-functional operator like “and” or “either…or…”. But, as we saw earlier, unless the machine’s behavior is semantics-driven, it isn’t figuring out whether those sentences were true or false. If we allow that the behavior of a “machine” can be semantics-driven, then a machine is no less capable than we are of figuring out whether (3) and (4) are true. In that case, if we say that a mechanical procedure is one that a “machine” can apply, we are falsely saying that there is a mechanical procedure for determining whether (3) and (4) are true and, by the same token, for writing effective literary criticism and composing great symphonies. So it is false to say that a mechanical procedure is one that a machine can implement. Given the points made a moment ago concerning syntax, I would propose a different answer to the question: what is a mechanical procedure? It is a semantic theorem that (1) and (2) are true. It is not such a theorem that (3) and (4) are true (even though they are both conceptually true). As we noted, it is generally held that there is a “mechanical procedure” for ascertaining the truth-values of (1) and (2), but not of (3) and (4). This suggests that there is a “mechanical procedure” for determining the truth-value of a sentence (or sentence-token) S, belonging to language L, exactly if it is a theorem of the semantic...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-173",
    "text": "Some would deny this, saying that (BKC) and (CKB) encode distinct but equivalent propositions. But it seems more reasonable to suppose that those inscriptions differ not in respect of the proposition that they encode, but in respect of the grammatical mechanisms that link them to some one proposition. The proposition meant by “triangles have three sides” is logically equivalent with that meant by “1+1=2.” But the relationship between these two propositions obviously isn’t comparable to relationship between the proposition meant by (CKB) and that meant by (BKC). In the one case, it can plausibly be said that we are dealing only with “purely verbal” differences. In the other case, this cannot be said. A reasonable synthesis of these facts seems to lie in the supposition that (CKB) and (BKC) differ not in respect of what they mean, but in respect of how they mean what they mean. It is uncontroversial that, from a linguist’s standpoint, (CKB) and (BKC) are syntactically different.[151] Given that those tokens encode the same proposition, this suggests that those tokens are syntactically different because of how they mean what they mean. In general, syntax is meaning-how, whereas semantics is meaning-what. (BKC) is syntactically identical with:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-174",
    "text": "Why is this? (JKS) and (BKC) have structurally identical “derivation-trees.” Though they have different meanings, they are “hooked up” to those meanings in similar ways. Since the syntax of an expression lies in the relationship that it bears to its meaning, it is absurd to say that syntax-driven operations are semantically innocent. Independently of CTM and of our criticisms of it, it is pretty clear that, even though they have different propositions for their meanings, it is in virtue of some kind of meaning-involving similarity that (BKC) and",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-175",
    "text": "For the sake of argument, let us suppose that you don’t speak Finnish. If a Finn tells you that (*) has (**) for its meaning, there is a sense in which you know the meaning of (*), but there is also a sense in which you don’t. A Finn does, whereas you do not, have any understanding of the semantic decomposition, to use Jerrold Katz’s (1972) expression, of XYZ. You don’t know which part of XYZ means aardvarks, or which part means musicality, and so on. But even if you have a dictionary, and thus know which words in (*) are the translations of “melodically”, “aardvarks”, and so on, you still won’t know why those words are ordered or inflected in the way that they are, so far as you are even able to distinguish inflections from word-roots. So there is at least one reasonable delineation of the term “meaning” relative to which a Finn does, whereas you do not, know the meaning of XYZ, notwithstanding that you know which proposition XYZ encodes. What a Finn knows that you do not is the derivation-tree of XYZ. This follows directly from our description of the situation. It is entirely consistent with existing usage of the term “syntax” to say that a Finn does, whereas you do not, know XYZ’s syntax. It immediately follows that the concept of syntax is not a meaning-innocent notion and that CTM is false so far as it assumes otherwise. A corollary is that, so far as the term “mechanical procedure” has syntactic content, a sensitivity to meaning is a pre-requisite to executing such a procedure. For reasons already considered, this is problematic for CTM. Let us consider some possible responses to our analysis:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-176",
    "text": "In natural language, grammatical and logical form diverge, as you’ve discussed. “Socrates is wise” and “no one is wise” have the same grammatical form, even though they have very different logical forms. But we can construct languages in which the logical differences between “Socrates is bald” and “no one is bald” are not obscured by grammatical similarities and in which, in general, grammatical and logical form coincide. The word “syntax” can refer either to the syntax of one of these idealized languages or it can refer to the syntax of natural languages. Linguists typically use that word in the second sense, and logicians typically use it in the first. So far as you have shown anything, it is only that, in the linguist’s sense of the word “syntax”, sensitivity to meaning is a precondition for engaging in syntax-driven operations. You have not shown that anything comparable holds in connection with the other disambiguation of that word. Since it is the latter disambiguation that matters in this context, you have not shown anything of significance.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-177",
    "text": "For the sake of argument, let us grant the objector’s supposition that syntactic and logical form coincide where Mentalese expressions are concerned. That reinforces more than it undermines our analysis of syntax and our related criticism of CTM. Let P and P* be the propositions meant by “nothing is wise” and “Socrates is wise”, respectively. The grammatical mechanisms that hook up the former with P are similar to those that hook up the latter with P*. More precisely, the derivation-tree for the one sentence is structurally the same as the derivation-tree for the other. That is what creates the illusion of a semantic parallelism, i.e. of a parallelism in respect of the propositions that those sentences express. Now let us suppose that English* is just like English except that, in English*, logical differences are always marked by syntactic differences. So in English* one doesn’t say “nothing is wise”; rather, one produces a sentence whose grammatical form matches its logical form, e.g. “the property of being wise is uninstantiated.” In English*, syntax and logical form coalesce because dissimilarities between what sentences mean are not covered up by similarities in respect of how they have these meanings, and xxx dissimilarities between what sentences mean are not covered up by similarities in respect of how xxx they have those meanings. For exactly similar reasons, if Mentalese is logically perspicuous, that is because (dis)similarities between what two expressions mean correspond to (dis)similarities in respect of how they have those meanings. So contrary to what the objector says, syntax is no less a meaning-involving affair than where English is concerned than where Mentalese is concerned.[152] One of the objectives of the present work has been to show that facts about pre-semantics are often mistaken for semantics itself. The how of meaning is displaced onto its what. Given a failure to distinguish meaning-what from meaning-how, it is no wonder that what should in fact be described as “syntax” ends up being described as “semantics.” It is because of this muddle that there is nowhere for “syntax” to go other than the domain of pure morphology. It is therefore not unreasonable to conjecture that a failure to distinguish semantics from pre-semantics is responsible for CTM’s presupposition that syntax is identical, or at least capable of being meaningfully aligned, with pure morphology. In its turn, the idea that morphology by itself has some kind of significant connection with...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-178",
    "text": "even though both (i) and (iii) are both “syntactically true” and are therefore both provable. Two syntactically true sentences are syntactically identical if they are identical in respect of their proof-theoretic properties. Of course, not all sentences are syntactically true (or syntactically false). But because we know what it is for two syntactically true sentences to be syntactically identical, it is easy to produce a general criterion of syntactic identity – one that applies to any pair of sentences, regardless of whether its members are syntactically true or not. Any sentence, whether syntactically true or not, can be embedded in a complex sentence that is syntactically true. The sentence “if Smith is tall, then something is tall” is syntactically true, even though “Smith is tall” is not. In light of this, let S and S* be any two sentences, whether syntactically true or not; and let C(S) be any syntactically-true sentence of the form…S…If C(S) is syntactically identical with C(S*), then S and S* are syntactically identical; and if not, not. When the mathematical logician talks about “syntax”, he is talking about an aspect of semantics. If he says that a sentence is syntactically true, he is saying that it is a theorem of the rules that assign it meaning that it is true; and if he says that two sentences S and S* are syntactically identical, he is saying that the proof of the theorem that C(S) is true is relevantly similar to the proof the corresponding theorem for C(S*), where C(S) and C(S*) are defined as before. Like the linguist, the mathematical logician uses the term “syntax” to refer to meaning-how. The logician and the linguist operate with different contextualizations of the notion of meaning-how. But that doesn’t matter in this context. What matters is that, when the mathematical logician uses it, the term “syntax” refers to an aspect of meaning and that, consequently, a syntax-driven operation is meaning-driven. We may conclude that neither the linguist’s nor the mathematical logician’s disambiguation of the term “syntax” favors CTM.[154]",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-179",
    "text": "There is another delineation of the “mechanical procedure.” Let us see if it does a better job of validating CTM than the delineation just considered. Let LM be the system of semantic rules that assigns the number one to “1”, the number two to “two”, the operation of addition to “+”, and so on. As almost everyone past the age of six knows, there are special techniques involving those rules that enable one to add (or multiply or divide…) large numbers. If one wants to add 1,297,967 and 7,645, one writes down the corresponding numerals, making sure to line up with the “5” with the “7”, the “4” with the “6”, and so on. Once that is done, adding those two numbers is reduced to adding a series of single digit numbers. So what would otherwise be a task requiring Herculean mathematical prowess becomes a task that is entirely “mechanical”, meaning that no intelligence (over and above such as is possessed by anyone of normal cognitive ability past infancy) is required to execute it. Obviously this delineation of the term “mechanical” doesn’t validate CTM. In order to implement the procedure just described, one must have a formidable repertoire of perceptual and cognitive capabilities. One must be able to see, hear, and write down symbols; one must have mastered a system of symbolic conventions. Only a creature that already has considerable cognitive powers can engage in operations that are “mechanical” in the sense just described. It would therefore be absurd to suppose that the foundations of cognitive life consisted in the implementation of such operations.[155] There is a third delineation of the term “mechanical procedure.” Given the existence of certain symbolic conventions (e.g. the convention that “1” denotes the number one), there is a function that assigns truth-values to arithmetical statements on the basis of their shapes. There is a function that assigns truth to “1+1=2” on the basis of its shape and that assigns falsity to “1+1=3” on the basis of its shape. And there is no difficulty constructing a machine M such that, given the left-side (so to speak) of an arithmetical equation, M produces a shape that is assigned truth by the function in question. (So given “12+12=”, M writes down, or otherwise generates, a “24”, thus producing a shape – “12+12=24” – that is assigned truth by the function in question.) The activity of a machine like...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-180",
    "text": "Earlier we discussed why linguistic communication demands that speaker and auditor have isomorphic, not coincident, thoughts. Before that, we discussed why what a sentence communicates consists less in what is literally meant by it than it does in what the auditor learns in the process of figuring out what is literally meant by it. In this section, we’ve seen why “formal” truth is syntactical truth and that, consequently, a sentence-token is “formally true” in virtue of how it means what it means. A short story will help show how these points relate to one another, and also why they have so often been overlooked. Aaronson is a scientist who has generated a great deal of experimental data. He sends a report of that data to me. His report contains no analysis – just raw data. My job is to distil that data into a theoretically significant statement. In the process of doing so, I must add two 87-digit numbers. Even though I don’t have a calculator, I am able to compute the relevant sum, thanks to the algorithms that I learned as a third-grader. It is beyond my powers to figure out to what exact number an 87-digit number-expressions refers. So identities of the two numbers that I am adding are unknown to me, as is the identity of their sum. I include my computations in my lab-report, which I then send to Brown. Brown is no more able than I am to excogitate the reference of an 87-digit number-expression. But, for reasons similar to those just discussed, he can still use my written record of my computation to analyze what I have sent him. (Brown’s job is to mediate between scientists and non-scientifically inclined policy-makers. So his job is to analyze my analysis into a form that is meaningful in the context of a political discussion.) Brown’s analysis is condensed into a statement that contains only short, easily understood number expressions, if it contains any such expressions at all. He then relays that analysis to policy-maker Green. Here information was transmitted from Aaronson to Green. Many of the symbols that were instrumental to that accomplishment were not understood. But those symbol-tokens were not therefore frozen or otherwise useless. Even though nobody fully understood the 87-digit number-expressions just described, those expressions facilitated the flow of information from person to person. We thus see corroboration for our earlier point that part...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-181",
    "text": "It is natural to suppose that a language is a set of rules that assign meanings to objects on the basis of their morphologies. This is exactly what CTM assumes; for it is built into the CTM-view that there are strictly morphological characterizations of syntactic structures and also of semantic notions such as proof, entailment, and confirmation.[157] We will see in the next chapter that such a view is quite false. Given any language, actual or possible, an object’s having this or that shape is neither necessary nor sufficient for its being assigned any meaning by that language. But right now, if only for the sake of argument, let us suppose that this assumption of CTM’s is correct. What follows from this supposition is not that thought consists in shape-manipulation per se. As we saw a moment ago, sensitivity to semantic (and extra-semantic) facts is a pre-requisite for cognitive achievement, even in domains where all issues can be decided through decision-procedures. Even such where domains are concerned, what counts as a genuine cognitive achievement is one’s recognition of a rather complex proposition, one having the form: given that such and such conventions are operative; given that, because those conventions are operative, there is a morphological characterization of truth; and, finally, given that this particular shape has the relevant morphology; it follows that this particular shape expresses a truth. There is nothing mechanical about one’s coming to see the truth of such a proposition, and one’s doing so has no intrinsic connection with one’s manipulating shapes. Of course, the manipulating of shapes is often a psychological aid to one’s arriving at the correct judgment; and one often writes down the judgments that one generates. But in both cases, the connection is entirely causal, as opposed to constitutive, and is therefore entirely contingent. Suppose that Smith proves some theorem. Here we must distinguish three things: first, the proof itself; second, Smith’s knowledge of that proof; and third, his communicating that proof to someone else. The first is an abstract object. In fact, it is a network of logical, and therefore abstract, relations holding among objects (numbers, propositions) that are themselves abstract. The second is a psychological condition. The third is a complex state of affairs having both psychological and non-psychological components. To communicate his knowledge, Smith must produce various noises or ink-marks; and producing such ink-marks and noises may also help Smith...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-182",
    "text": "The essence of content-externalism is that what an object is thinking, and therefore whether it is thinking, is a function of its causal liaisons to the environment. You are right to say that an object qualitatively just like one of our calculators wouldn’t really be calculating or otherwise cogitating if it were created by a freak accident on some planet where our symbolic conventions weren’t operative. But content-externalism shows that an object qualitatively just like you wouldn’t be thinking about water on a planet where XYZ, as opposed to H2O, came out of water-faucets and filled our oceans, and so on. But we saw in Part I why this point of view cannot be accepted. Analytic functionalism and the Ramsey-Lewis sentence",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-183",
    "text": "(AF) Given only that machine M outputs a “12” in response to an input of “7+5=”, it doesn’t follow that M has done a sum; and you are right to say that one is guilty of the crudest form of behaviorism in so far as one thinks otherwise. But this is neither here nor there as far as CTM is concerned. David Lewis (1972) used the concept of a Ramsey-sentence to show how a creature’s mental states – while not identical with dispositions towards certain behaviors, given certain inputs – can nonetheless be understood entirely in terms of that creature’s inputs and outputs. Let C be a creature and let S be a giant, conjunctive sentence giving a complete description of C’s psychology. Obviously, S will not contain only psychological terms; it will contain at least some terms linking psychological states to publicly verifiable inputs and behavioral outputs. must be made for will make at least some mention of inputs and behavioral outputs. So S will contain sentences like “ceteris paribus, given a perception of cold-water, C will grab said class and drink its content.” (Given any psychological theory – whether Freudian, Chomskyan, or Skinnerian – it will surely make at least some allowance for the behaviors characteristic of mental states, even though those theories may differ among one another as to the relationship between mental and behavioral facts. Also, if S doesn’t contain sentences concerning overt behavior, then it is hard to see how it could constitute a testable, or therefore empirically significant, theory. So there is nothing question-begging in Lewis’ supposition that S will refer to publicly ascertainable inputs and outputs on C’s part.) We now “Ramsify out” all the expressions in S that refer to mental states. Given any mental term mi occurring in S, we replace it with a variable xi, and then prefix the resulting open-sentence with a quantifier that binds all of the occurrences of xi. (The identity of this quantifier may depend on the value of i. So it might sometimes be ┌for some xi┐, and it might other times be ┌given any xi. ┐) Let S* be the sentence that results from this process. Given any conception of scientific rigor, S* will be no less an adequate description of C’s psyche than S. Really, the differences between them will confined to phraseology. (Where S says “given a perception of ice-water, thirst is...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-184",
    "text": "The position just described is a form of functionalism, and we’ve already (Chapter 13) seen one reason why that doctrine cannot be accepted. There are other problems with (AF) and with functionalism generally. One of these problems is identified by Fodor himself (Fodor 1998: 45, Fodor and Lepore 2002). If content is causal role, then the same content cannot possibly have different causal roles. But supposing that b is your belief that snow is white, there are obviously counterfactual scenarios where b has a causal role different from the one it has here. (If you had written your dissertation on crystallography, instead of on Bentham’s political theory, your belief that snow is white would have led you to make many inferences that have not in fact made.) (AF) makes b’s association with its representational content much more brittle than it actually is. For similar reasons, (AF) makes it virtually impossible for two different people to believe that snow is white, since the causal role of one person’s belief in that proposition will inevitably differ from that of another person’s corresponding belief. Of course, what we just said about beliefs that snow is white is true of all beliefs and, indeed, of all propositional attitudes. The counter-response would be to say that if two causal roles are sufficiently similar, then they both realize the same content. So causal role fixes content, but content doesn’t determine a unique causal role. There is an obvious problem with this counter-response. The causal role of one person’s belief that snow is white can be extraordinarily different from the causal role of another person’s belief that snow is white. Smith is a physicist who has spent his life studying the reflective properties of crystals and who believes (correctly, let us suppose) that a solution to the major problems of contemporary physics are to be found through careful consideration of snow’s chromatic properties. Brown is a ski-instructor who wishes that snow were green, because the glare caused by snow’s whiteness gives him headaches and makes it hard for him to see. Let bs the brain-state realizing Brown’s belief that snow is white, and let bb be Smith’s corresponding brain-state. Obviously the causal roles of these two states differ dramatically. So far as they have anything in common, it seems to be that each realizes a belief that snow is white: so far as bb‘s functional role is...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-185",
    "text": "If a coffee-machine accidentally produced the sounds “snow is white”, nothing would have been said; no symbols would have been tokened. Of course, one might think that the coffee-machine was actually producing symbols. But one would believe this only in so far as one believed that the coffee-machine’s production of those sounds was actually animated by certain intentions (or that the coffee-machine had been created by somebody with certain intentions and that, consequently, somebody was speaking through the machine, much as one can speak through a letter or an email). The moment one accepts that the coffee-machine is inanimate, and that its production of those sounds is simply an accident, and not the result of its creator’s intentions, one immediately accepts that nothing has been said and that nothing linguistic has occurred.[162] This suggests that the psychological underpinnings of a symbol-token are not just causally, but also constitutively, involved in that tokening. Even though it is imperceptible to others, one’s mental state is constitutive of the symbol-token one is producing. This shows that when the symbol-type “snow is white” really is instantiated, a constituent of that instance is some kind of mental state: when somebody says “snow is white”, the symbol-token that has been produced actually comprises at least some aspects of the mind of the person who produced that token. Of course, it would be false to say that every aspect of that person’s psyche is a constituent of that token. Suppose that, while experiencing a tickle in my left foot, I say “snow is white”, but that my reasons for saying this have nothing to do with that tickle. In that case, even though it is an aspect of my mental condition, that tickle is not constitutive of the symbol-token I have produced. But this obviously doesn’t mean that other mental states of mine are not thus constitutive; and we just saw that they are. Sometimes the psychological aspects of a symbol-tokening are spatio-temporally remote from its morphological aspects. Suppose that I am typing on a keyboard that forms letters out of giant rays of light in some remote galaxy. In that case, the morphological aspects of the token of “snow is white” that I produce is estranged by millions of years and miles from the psychological aspects that same token. Symbols not strictly psychological entities",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-186",
    "text": "At the same time, psychology cannot single-handedly turn an otherwise dead sound into a living symbol-token. Suppose that, while in the grips of a psychotic delusion, Smith utters complete gibberish, thinking that it means snow is white. 666 One might be able to figure out that Smith meant snow is white. But this would be a case of one person’s having psychoanalytic or criminological insight into another. It would not be a case of two people speaking a common language. Indeed, it would not be a case of anybody using any language. Given only that Smith thinks that his words mean snow is white, it doesn’t follow that they really do mean that, albeit in some private language. (My reasons for this do not have anything to do with Wittgenstein’s celebrated “Private Language Argument”, which we will discuss in Chapter 18. In any case, any similarity between my argument and Wittgenstein’s is unintended.) Suppose that Smith snaps out of his delusional state, but remembers the exact noises that he produced. He will say: “I thought I was saying that snow is white; but I now realize that I was uttering gibberish.” He won’t say: “I was saying that snow is white, but I was saying it in my private idiolect.” Here we must remember that Smith’s intention is to speak some language that others speak: Smith thought that he was speaking English or some other public language. So even if Smith does have some kind of private code whereby he communicates with himself; and even if, relative to that code, the sounds he produced mean snow is white; his intention was to use some public language, and not that private code. So it was an accident that the gibberish he produced was homonymous with the sentence that means “snow is white” in his code. Suppose that I try to produce the English words “snow is white” but that, solely because of some vocal chord malfunction and not because of some repressed urge to speak French, I end up producing the sounds “la neige est blanche.” In that case, I haven’t spoken French 666 any more than the previously discussed coffee-machine is speaking English. Of course, witnesses would probably assume that a French sentence had been uttered 666. But they would be wrong, as we just saw. It may be that I do speak French. But given that my French knowledge...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-187",
    "text": "In order for a symbol to be tokened, it is necessary that it arise in a certain way from a certain kind of social knowledge. (Later on, we will try to state more precisely the nature of this knowledge.) In this context, the word “necessary” denotes constitutive, not causal, necessity. So the just described psychological and social conditions are veritable constituents of the symbol-token. This doesn’t conflict with our presumption that symbol-tokens, unlike social practices, are discrete entities. If our analysis is right, a symbol-token is a convergence of a number of different factors, and that convergence-point is discrete, even though the forces that are converging are not. A symbol-token has morphological, psychological, and sociological components. The morphological components indicate an awareness of the relevant semantic rules; and the relevant semantic rules constitutively involve the existence of social practices. (Initially, this might seem to be viciously circular, since the social-practices in question presumably involve the use of symbols. In Chapter 25, when we are proposing a Searle-based alternative to Grice’s theory of meaning, we will see why there is no vicious circularity.) To some degree, the function of the morphological aspects of the symbol is to indicate the operativeness of psychological and sociological factors. But there can be no more be a symbol in the absence either of the latter two factors than there could be in the absence of the first. So far as we tend to think otherwise, it is a reflection of our tendency to telescope meta-perceptual into perceptual information. Here it is crucial to keep in mind the distinction between saying and expressing. When I produce the sounds “snow is white”, that symbol-token doesn’t mean that such and such socio-psychological factors are now operative. Semantically, that symbol-token ascribes a certain color to snow, and that is all it does. But given that a symbol-token meaning snow is white has been produced, it can be inferred that certain psycho-social factors are operative. So that symbol expresses, but does not state, the existence of those factors. A symbol is what results when a bit of morphology is produced in consequence of the convergence of social and psychological factors. A symbol-token is thus best thought of as a convergences of psychological and sociological forces. Of course, we instinctively gravitate towards the position that symbol-tokens are discrete physical objects – bits of ink and noise. In fact, that position may...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-188",
    "text": "Though there are elements of truth in it, ($) is false on the whole; and it is worthwhile to say precisely why it is false, since there is such a strict parallelism between ($) and the conception of symbol-hood that I am attempting to refute. Let B be some particular dollar bill – e.g. the dollar bill that is in your pocket. Now imagine the following scenario. Tomorrow, the U.S. is taken over by a foreign power. A new system of government is imposed, and this involves changing the currency that is used. The bits of paper that Americans used to use to make purchases are now as useless as Monopoly money.[163] Under these circumstances, what has become of B? (We are supposing that B hasn’t been damaged or destroyed.) Obviously B isn’t money anymore. Given this, the problem with ($) is clear. B is a piece of paper. That piece of paper hasn’t been destroyed. But B isn’t money any more: as far as its being money is concerned, B might as well have been incinerated. Leibniz’s Law thus prevents us from saying that B itself is money. Given these points, what we must say is at least approximately as follows. B per se was never money. B was a certificate of some kind. It certified that its possessor has certain rights within a certain legal-political structure. Since that structure is now gone, what B certifies doesn’t exist: B is a bogus certificate, and thus not a certificate at all. By itself, B never had purchasing power. Something that has no purchasing power isn’t money. So B was never money. What did have purchasing power, and what was therefore money, was B’s being embedded in a certain legal-political structure. By itself, a piece of paper isn’t money. What is money is that piece of paper’s being embedded in certain social practices. Up to a point, the function of the piece of paper is to indicate the presence of those social factors. That is why there are so few limits as to the physical form that money can take. So long as the relevant social factors are indicated, the physical composition of the indicator is irrelevant. That is why there can be billionaires who are not in a possession of a quarter or dollar bill. So far as it has any physical incarnation, a person’s vast fortune may be realized...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-189",
    "text": "A short story can help us substantiate this line of thought. One day, while rummaging through your attic, you come across a bottle of colorless liquid. On the bottle there is a strange ink-mark. We will refer to that ink mark as “X.” But the ink-mark itself does not itself have an X-shape. We must keep in mind that “X” is our word for an ink-mark. If it should turn out that X betokens an expression of some language, “X” is not our word for that symbol-token, but only for the corresponding ink-mark. In this context, we need to be especially fastidious about this distinction if we are to avoid prejudging the issue being discussed. It turns out that X does betoken a symbol belonging to a language L, and the English-translation of that symbol-token is: “If consumed, the contents of this bottle cure arthritis.” But you don’t know now what X means and you don’t even think that it is a symbol. Your inclination is to believe that it is meant only to be a logo or some kind of decoration. Nonetheless, you find X’s design to be intriguing, and you put the bottle on your windowsill in an effort to enhance the appearance of your under-decorated room. Your friend Brown, who suffers from acute arthritis and has had no luck with conventional medicine, is a native speaker of L. One day, he sees the bottle. He immediately uncaps it, and drinks it down. He is immediately cured of his arthritis. The statement on the bottle was correct. It is a datum that Brown’s activity was symbol-driven, whereas yours was not. But what exactly does it mean to say this? Here we must remember a point made earlier, and to be discussed at length in a later section. It is not objects, but states of affairs, that have causal properties. It is not the rock that breaks the window, but is rather some state of affairs consisting of the rock’s having a certain mass and moving with a certain velocity at a time vanishingly close to the moment of impact. From the standpoint of causal explanation, the rock is inert; what does all the work is the rock’s having a certain mass, its moving with a certain velocity, its having a certain structure, and so on. For exactly similar reasons, the ink-mark is a non-entity from the viewpoint of...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-190",
    "text": "These points about symbolism have manifold relevance to the question of whether CTM is viable. Given only that the presence of what is in fact a symbol has caused you to act in a certain way, it doesn’t follow that your subsequent thought or behavior has any symbolic dimension. The presence of X on the bottle caused you to do things that you wouldn’t otherwise have done, and to think things you wouldn’t otherwise have thought. But those thoughts and deeds were not relevantly different from the thoughts and deeds that would have been precipitated by your seeing a beautiful flower or a graceful foal. If we insisted on describing your activity as symbol-driven, we thus would strip that term of any meaning. We will henceforth reserve the term “symbol-driven” for activity that is similar to Brown’s – activity constitutively connected with one’s acquiring information through a symbolic intermediary. (In this context, the word “information” is meant to denote any content, not just true content.) CTM doesn’t register the distinction between a behavior’s being symbol-caused xxx and its being symbol-driven xxx. There is no denying that the calculator’s behaviors are caused by the presence of what are in fact symbols. But it doesn’t follow that the calculator’s behavior is symbol-driven, i.e. it doesn’t follow that anything’s being a symbol is responsible for the calculator’s behavior. And, as we saw, in so far as the calculator’s behavior is strictly morphology-driven, its behavior is demonstrably not symbol-driven. In our story, Brown’s response to X was symbol-driven because it embodied an understanding of the socio-psychological conditions that gave rise to X. Brown’s relationship to X is not significantly paralleled by calculator relationship to the ciphers that appear on its screen. Brown’s relationship to X presupposes socio-psychological knowledge on his part. This provides indirect, but powerful, confirmation for a point that we defended earlier. For a symbolic-operation to be form-driven, in any relevant sense of the word “form”, is for it to be driven by a knowledge of at least some of the semantic properties of the symbols in question. More exactly, a formal symbolic-operation is an attempt to show that the truth of a certain symbol (or symbol-token) is a theorem of the semantic rules that assign meaning to that token. Obviously semantic facts are, at least in part, a consequence of psychological facts. If the cognitive activity associated with the sound “Mars”...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-191",
    "text": "It is clear that (iii) is a consequence of (i) and (ii). It is also clear why (i)-(iii) pose a problem for CTM additional to those already discussed. CTM needs there to be a morphological characterization of certain semantic notions; it needs to bring 666 semantic facts (e.g. the fact that one sentence entails another) into alignment with facts about morphology. Supposing that our semantic rules permitted little or no morphological divergences between two tokens of a given symbol-type, such an alignment might be possible within “certain famous limits.” But given what symbol-tokens are, the a priori possibility of such an alignment occurring is vanishingly close to zero. In any case, the conditions under which such alignments would occur would constitutive obfuscations, not expressions, of the basic facts about what symbols are. Any symbol-token has psychological and sociological components -- I am referring to the symbol-token itself, not to what it refers to or otherwise signifies. The function of its morphological component is in large part merely to indicate those other components. Therefore, we cannot reasonably demand of a language that its morphological aspect remain stable. That is like expect the pressure of the gas in a sealed vessel to remain constant, while we raise its temperature. We cannot expect dependent variables to behave like constants (or like independent variables). CTM need the morphological and semantic aspects of language to be in lockstep. For the reasons just given, the circumstances that permit such alignments are in the nature of singularities. There are situations where, within limits, a morphological characterization of certain semantic notions are possible. These are cases where what is in fact the dependent variable (morphology) appears as though it is one of independent variables (psychology and sociology); and, in its turn, this misleading appearance creates the misleading appearance that the socio-psychological components of symbol-tokens are parasitic on their morphologies. Such situations thus doubly obscure the nature of symbolism, as they invert the structure characteristic of symbol-tokens, and then proceed to condense the ordinarily distinct entities constitutive of that structure. In taking morphology as primary, CTM erroneously takes such singularities as its paradigms, and erroneously regards non-singularities as deviations or irregularities. Some fiction may help elucidate and also substantiate these remarks. In the year, 2025, human beings lose the ability to speak and to write. They cannot generate new sounds or new ink-marks. If a person wishes to speak,...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-192",
    "text": "Of course, you and I know what is meant in this context by the occurrences of “like this.” We know that the inscription “11+11” does, whereas the inscription “11-11” does not, satisfy the relevant condition. But because Smith has a strictly morphological conception of what is meant by “like this”, he cannot comply with your instructions except within vanishingly narrow horizons. Smith cannot execute your orders unless in cases where the inscription before him is a perfect duplicate of the paradigm that you gave him. In any case, given only what you’ve told him, Smith has no reason to believe that “11×11” is relevantly different from “11+11”, or that the latter is relevantly similar to “11+11.” From a purely morphological standpoint, the second two symbols are much less alike than the first two. (Of course, what it is for two symbols to be “morphologically alike” depends on the context. Given his investigative concerns, physicist may regard “11×11” as being morphologically closet to “11+11” than to “11+11”, whereas given his concerns, physicist B may take the opposite view. Like all forms of resemblance, morphological similarity is to be understood in contextual terms. But for analogues of the reasons just given, that fact itself redounds to the discredit of CTM.) In fact, even if the inscription before Smith is an atom-for-atom duplicate of his paradigm – even if it is just like the inscription of “11+11” from a few lines back -- he still cannot carry out your instructions. Even under those circumstances, it would be no less rational of him to write a “78” next to that inscription of “11+11” than it would be to write a “22.” This is because, given only what you’ve told him, what you meant by “like this” might have had little or nothing to do with strictly physical properties of the inscriptions that you were indicating. Imagine the following. In plain view of both you and Smith, your beloved daughter etches a token of “11+11=” in the ground. And, again in plain view of both of you, your much reviled son then inscribes a “22” to the right of the equals-sign. It could be that, given your obviously irritated response to your son’s behavior, along with the familial saga in which it is embedded, Smith is not being irrational in taking your first utterance of “like this” to mean something that reminds me of my...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-193",
    "text": "Too much of a connection between semantics and morphology is as threatening to the existence of a usable language as the absence of such a connection. I have probably never heard two utterances of “he’s over there” that sound quite the same. The class of circumstances that permit a perfect instantiation of a given morphology is only a tiny subset of the class of circumstances where we wish to communicate, and language would therefore be useless if there were too close a connection between morphology and meaning. A corollary is that a certain plasticity is built into any aspect of a creature’s functioning that has a genuinely symbolic dimension. To the extent that a creature’s behavior is strictly morphology-based, it doesn’t bear any significant resemblance to anything that is uncontroversially an instance of symbolic activity. Genuinely symbolic activity does, whereas strictly morphology-driven activity does not, allow for an unlimited degree of deviation between a creature’s linguistic paradigms and its reproduction of those paradigms. Genuinely symbolic behavior has a plasticity not had by its mechanical analogues. At first it might appear that, if indeed this last point is true, that is merely a reflection of an evanescent, if not already extinct, fact about our technology. These days one can buy scanners that have “character recognition.” So if you a scan a typed document, what is uploaded is confined to semantically relevant material, and excludes the semantically irrelevant material (e.g. coffee-stains, crushed insects, smudges) that tends to gather on documents. A scanner with character recognition can recognize the word “snow” in physical objects having very different morphologies. So such a scanner seems to have the plasticity that, according to what was just said, they lack. Also, there are technologies that transcribe the spoken word. These technologies are currently imperfect. But the imperfections are rapidly being eradicated; and it is not unreasonable to expect that, in a few years, there will no longer be a need to type (at least as far as those can afford such machines are concerned). Again, it seems that a technological fact counterexamples my analysis. But this line of thought presupposes the very conception of symbol-hood that it is meant to support and that we have seen reason to reject. Let S be some transcribing-device that has maximally good character recognition: M has no trouble “recognizing” the words that Brown has uttered, even if Brown has a medical...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-194",
    "text": "A symbol-token has both morphological and socio-psychological components, and the morphological component has done its job provided that it directs the auditor (or reader) towards the right social-psychological component. So there is nothing linguistically degenerate about X’s utterance, even though it may fail to satisfy the aesthetic strictures of a diction-coach. Of course, X’s utterance is morphologically degenerate, as I myself said. But that is just an elliptical way of saying that in most contexts an utterance acoustically like X’s wouldn’t provide the information needed to direct the auditor towards the socio-psychological component of the relevant symbol-token. There is no sense in which the story just told concerns a singularity or degenerate case. In the exchange between X and Y, context is probably doing more than it ordinarily would, and morphology is probably doing less than it ordinarily would. But these quantitative differences don’t constitute structural or categorical differences. We are dealing with a garden-variety expression of the forces involved in the composition of any symbol-tokening and, therefore, in any linguistic exchange. The dialogue between X and Y could be described as a “degenerate” or “singular” case only if it were assumed that any utterance that isn’t in lock-step with the aesthetic strictures of a diction-coach is ipso facto degenerate. But in addition to being question-begging in this context, such an assumption would demand that we categorize virtually every utterance every produced as degenerate. Let us consider another objection:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-195",
    "text": "There is indeed a sense in which utterances of “Smith went to O’Reilly’s” should bear a greater resemblance to a diction-coach’s pronunciation of that sentence than Smith’s does. But it is not comparable to the sense in which somebody who wishes to affirm (b) should utter (d) as opposed to (a). If you utter the sentence “Smith went to O’Reilly’s” with the intention of affirming the proposition Smith went to O’Reilly’s, people are generally more likely to know that your speech-act is in keeping with the relevant linguistic rules if your utterance is more like a diction-coach’s than it is like Smith’s. It is easier to know what a diction-coach is saying than it is to know what is being said by somebody who is mumbling or has laryngitis. But this doesn’t mean that the expressions produced by a diction-coach are more correct, relative to the rules constitutive of the language in question, than what is said by somebody who has laryngitis. It doesn’t mean that the diction-coach’s speech is more in keeping with those rules than that of somebody with laryngitis. It only means that ceteris paribus it is easier in the one case than the other to identify the speech-acts that have in fact been performed. So the sense in which one should speak like a diction-coach is comparable to the sense which one should speak directly into a microphone. The “should” here is of a generally instrumental nature, and has no specifically linguistic significance. But supposing that I wish to affirm (b), the sense in which I should utter (d), as opposed to (a), is of a distinctively linguistic nature. In uttering (a), I am guilty of linguistic incompetence. But I am guilty only of garden-variety instrumental incompetence if I mumble (d) with the intention of affirming (b). There is another objection to our analysis that we should consider:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-196",
    "text": "This line of thought is a non-starter, the reason being that it is inherent in the nature of symbolism that morphologically different entities be capable of betokening the same symbol, and that morphologically identical entities be capable of betokening different symbols. Whether a given sound (or ink-mark or pattern of light….) betokens this as opposed to that symbol is a function, not of that sound’s morphology, but of the relation of its morphology to the socio-psychological context of tokening. That is why two morphologically identical sounds (or ink-marks or patterns of light...) can betoken different words, and that is why two morphologically very different sounds (or ink-marks…) can betoken the same word. Let T1 an occurrence of word “bank” (financial institution), and let T2 be a morphologically identical occurrence of the word “bank” (river’s edge). Why do T1 and T2 betoken different words? In the one case, the context of utterance involved a perception of Smith putting a fishing pole into the back of his pick-up truck. In the other case, the context of utterance involved a perception of Jones angrily snapping his briefcase shut after unsuccessfully attempting to borrow money from his brother. Even though the morphology is the same, the relationship between morphology and context of utterance has changed; and that is why two words have been tokened, instead of one. Obvious extensions of this reasoning show why two different tokens of a single expression-type may be very different in respect of morphology. This line of thought accommodates the fact that morphology has some constitutive involvement in the tokening of a symbol. For a given symbol to be tokened, it is necessary that there exist a physical object (e.g. a noise or ink-mark) whose morphology stands in a certain relation to the context. This means that there is no symbol (or symbol-token) where there isn’t a bit of morphology. It also means that, all other things being equal, two tokens of a given expression-type will be morphologically similar. But this same line of thought accommodates the fact two tokens of a given expression-type can be morphologically very different. Given a sufficiently large change in the context of utterance, a commensurately large change in morphology will be needed to ensure that the relation between morphology and context is preserved. (If you gain two hundred pounds, the clothes that you wear must also change if they are to fit, i.e....",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-197",
    "text": "An expression-type is not a shape, and an expression-token is not an instance of a shape. A expression-type is a relation between morphology and context, and an expression-token is an instance of such a relation. So to identify thinking with computing is to identify thinking with the manipulation of instances of relations between morphology and contexts. (More exactly, it is to identify thinking with the manipulation of instances of relations of instances of morphology to instances of certain kinds of context.) It is not to identify thinking with the manipulation of bits of morphology. Given these points, if we are to evaluate Fodor’s view, we must ask: where a Mentalese expression is concerned, what is the relevant context? Suppose that S is a token of the Mentalese word SOCRATES. Supposing that our analysis is correct, S is an instance of a relation between morphology and context. Given CTM, the morphology in question must be had by some brain-state (some neural structure or pattern of neural stimulation). Let B be that brain-state. But what is the relevant context? There are different possible answers to the question, and none of them validates CTM. Let us start with the answer that Fodor himself gives. According to Fodor, so far as B represents Socrates, it is because some state of affairs is causally responsible for B’s existence. (Of course, Fodor doesn’t think that just any mode of causation will do. He thinks that there is some specific causal relation R such that, in so far as B represents Socrates, it is because some state of affairs involving Socrates stands in causal relation R with respect to B.) So far as B represents Socrates, it is, according to Fodor, because B is at one end of a long sequence of events beginning with Socrates himself. Thus, if Fodor is right, the relevant context includes a state of affairs that existed over two-thousand years ago. Supposing that we are right to analyze symbol-tokens, as instances of relations between morphology and context, it follows that S is a symbol-token representing Socrates in virtue of the fact that it is an instance of a relation between an instance of morphology and context. The instance of morphology would be B and the context would be some protracted state of affairs involving Socrates himself. So any manipulation of the Mentalese symbol for Socrates would involve a manipulation of some vast...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-198",
    "text": "Consider the English word “dog.” Here is what we have said about it. If a noise betokens that word, it is not solely in virtue of its morphology. Rather, it is in virtue of its morphology plus facts about the context of utterance. More exactly, it is in virtue of the relationship between the morphology of that noise and the context in which it occurred. There are instances of expression-types when, and only when, there are instances of relations of the sort just described. This suggests that, where public languages are concerned, expression-types just are such relations and expression-tokens are instances of such relations. Supposing that this analysis is correct, anything that isn’t an instance of such a relation doesn’t have any significant similarity to the things are ordinarily referred to as “expressions.” We’ve discussed why CTM cannot coherently regard tokens of Mentalese expressions as instances of relations of this kind. CTM thus cannot coherently regard cognition as an operation on anything that can appropriately be referred to as an “expression” or “symbol.” We must make a distinction. It is one thing to say that there is no interpretation of terms like “symbol” and “linguistic expression” that validates CTM, and it is quite another to say that we don’t think in symbols or linguistic expressions. What we’ve seen so far is not that we don’t think in symbols. What we’ve seen is that there is no interpretation of expressions like “symbol” and “sentence-token” that validates CTM’s thesis that thinking consists in formal symbolic (or linguistic) operations. We have not yet seen that thinking doesn’t consist in the tokening of expressions of some kind. CTM and SCT are distinct doctrines. CTM presupposes the truth of SCT, but SCT doesn’t presuppose the truth of CTM. I will argue that SCT is indeed false. But it is not false because CTM is false; it is false for its own distinctive reasons.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-199",
    "text": "For reasons that we discussed in Part I, content-externalism seems to be incompatible with the causal potency of the mental. We discussed a number of attempts to refute this, but found them to be fallacious. But there is one important approach to this problem that we did not discuss – that of Jerry Fodor. Fodor’s analysis makes heavy use of the concept of syntax. We were not in a position to evaluate Fodor’s analysis in Part I, since we hadn’t yet analyzed that concept. Now that we have done so, we can assess the merits of Fodor’s view. As we’ve discussed, Fodor is a hard-line content-externalist. In his view, given only that, leaving aside facts about the causal origins of their conditions, Max and Twin-Max are qualitatively identical, it doesn’t follow that they have anything in common in terms of the representational contents of their mental states. At the same time, Fodor takes it for granted that psychologically they are indistinguishable, i.e. that what an omniscient psychoanalyst would have to say about the any given one of them (in his capacity as psychoanalyst) would be identical with what he had to say about either of the other two. Fodor’s position is thus consistent with the causal efficacy of the mental and with the presumption that psychology has at least some integrity as a discipline. Fodor reconciles these two views by saying that, whatever causal properties a thought has, it has them in virtue of its syntax, not its semantics (representational content). The syntactic structures of Max’s thoughts are identical with those of Twin-Max’s thoughts. What those thoughts represent is a function of spatiotemporally remote, and therefore causally inert, facts about the environments in which those individuals are embedded. But syntax is an entirely internal affair. More exactly, given two subjects that are atom-for-atom duplicates, their thoughts cannot differ in respect of syntax, it being irrelevant what environmental facts led to those thoughts. Is this position tenable? No. First of all, thoughts have syntactic structure only if they are sentences. Obviously this is not an innocuous view. But for argument’s sake, let us suppose that it is correct and that, indeed, mental states have syntactic structure and, therefore, that they are sentence-tokens. Given this, let P be the meaning of",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-200",
    "text": "be tokens of the Mentalese translations of (a) and (b). There is no denying that (A) and (B), being brain-states, have causal properties. They have mass, shape, temperature, and various other causally efficacious properties. The question is not whether brain-states have causal powers or whether Fodor’s view strips them of such powers. The question is whether, supposing that Fodor is right to strip semantics of causal power, he can coherently say that syntax has causal power. In other words, can syntax be causally efficacious if semantics is not? No. As we saw earlier, a sentence-token’s syntax lies in how it means what it means. How a sentence-tokens means what it no more supervenes on its morphological properties than what it means. Given only its morphology, a token of (a) doesn’t have to mean: Mary loves Tom. An advocate of CTM could respond by saying that, where Mentalese symbol-tokens are concerned, syntax does supervene on morphology. But given what we said in the last chapter, this would mean that Mentalese symbol-tokens (so-called) were fundamentally different from their English and Spanish counterparts – so different that we couldn’t refer to the former as “symbols” without rendering that term ambiguous. The Regress-argument revived",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-201",
    "text": "We saw in Chapter 13 that syntax is semantic decomposition. A sentence’s syntactic structure lies not in what it means, but in how it is assigned that meaning by the semantic rules of the language to which it belongs. Supposing that our thoughts have syntactic structure, the relevant semantic rules are either mentally represented or they are not. If they are mentally represented, those representations cannot themselves coincide with Mentalese sentences (or sentence-tokens), since (for well known reasons[167]) no language can “contain its own truth-predicate”, as Tarski put it. Those rules must therefore be represented either in some non-linguistic form or in Meta-Mentalese (a language distinct from Mentalese that expresses the rules that assign meaning to Mentalese expressions). If we say that those rules are represented in a non-linguistic form, then we are giving up on the thesis that we think in sentences. If we say that they are represented in sentences (or sentence-tokens) of Meta-Mentalese, then we embark in a vicious regress, since everything that we have said about Mentalese is true of Meta-Mentalese. So let us suppose that the semantic rules of Mentalese are not mentally (or neurally) represented.[168] In that case, the operativeness of those rules does not supervene on any fact about one’s brain or, indeed, on any other causally effective fact about one’s person. But then, for the reasons covered in Part I, the syntactic structures of Mentalese sentence-tokens are stripped of any causal powers. It straightforwardly follows that Fodor is wrong to hold that it is every in virtue of their syntactic properties that brain-states do any causal work. In light of these points, we can see why one of the classic arguments against SCT is in fact cogent. If we think in a language, then presumably we understand that language – we know how to interpret its sentences. But interpreting such a sentence either involves translating them into another language that is already understood or it involves generating a non-linguistic representation of its meaning. In the first case, there is a vicious regress. In the second case, there is an acknowledgement that thinking ultimately does not consist in the tokening of sentences. Either way, SCT fails. This argument is well-known to advocates of SCT, and here is how they deal with it:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-202",
    "text": "If (NSK) is right, Mentalese is so different from any paradigm-case of a language that we must (once again) question whether the it is appropriately described as a language. The answer to that question is “no”, as we will now see. Given any one English-speaker, the English-language could exist if that person didn’t exist or did exist but didn’t speak English. But suppose that nobody spoke English. In that case, it wouldn’t exist. One might respond by saying that languages are purely function-theoretic pairings of physical objects with meanings. In a moment, we will consider this position, finding it to be entirely false. But even if it is true, it remains an uncontroversial fact that, if nobody spoke English, English would, at the very least, be defunct. Knowing English consists in knowing the relevant semantic rules. English is dead if nobody knows those rules. It is obvious that whether a public language is alive or dead is constitutively dependent on whether people know the relevant semantic rules. This doesn’t mean that any one person has to knows all of those rules. But it does mean that the language in question is dead if nobody knows any of them. It is an essential fact about any public language that its very existence (or, in any case, its not being dead) is constitutively dependent on its rules being known to somebody. But for a language to be alive, it is not sufficient (though it is necessary) that somebody know its semantic rules. A knowledge of those rules must be causally responsible for the judgments that people make as to what noises and ink-marks mean, and as to what noises or ink-marks to produce in a given context. You privately learn how to read and write some long-dead language L, and a number of other people simultaneously do the same. But nobody knows that anyone else knows L; and nobody uses their knowledge of L to communicate anything to anyone else, or even to themselves. Under these circumstances, L is quite obviously a dead language (though it could be readily revived). So supposing that E1…En is a complete list of the expression-tokens that people produce, a language L is alive only if, for some i, a knowledge of L it is causally responsible for somebody’s producing Ei. (Obviously this is not a sufficient, but only a necessary, condition for L’s being alive.) If...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-203",
    "text": "(a) and (b) are syntactically identical, and the same is presumably true of (A) and (B). Supposing that Fodor is right to say that there are mental-causal differences only where there are syntactic differences, it follows that (ceteris paribus) one’s belief that Mary loves Tom has the same causal properties as one’s belief that Larry punched Bob. Since this consequence is false, so is Fodor’s analysis. Because he identifies syntax with morphology, and not with semantic decomposition, Fodor would not be moved by these arguments.[171] But syntax is not morphology, as we have seen, and the argument just given therefore stands. One might object that, for special reasons, the Mentalese translations of (a) and (b) don’t have the same syntactic structures. But what we just said about (A) and (B) will hold of any two Mentalese sentence-tokens that are semantically different but syntactically identical. In response, an advocate of SCT might say that, where Mentalese is concerned, it is impossible for two sentences to have the same syntax but different semantics. (This is not far from the position that Fodor himself sometimes appears to take.) But this suggestion is a non-starter. Syntax is recursive semantics. If Mentalese satisfied the condition just described, the same recursions could never be used twice. Since a language just is a set of recursions defined over a certain lexicon, that is tantamount to saying that there is no such thing as Mentalese. Chapter 15 Event-causation and the root-problem with CTM",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-204",
    "text": "There are two points to make here. The advocate of (FRM) might be right to say that my criticisms of CTM are null and void if one takes the computations posited by CTM to be nothing more than bits of morphology impacting other bits of morphology. But given the points we’ve made in connection with terms “symbol”, “algorithm”, “syntax”, “form”, and the like, it isn’t clear what intuitive motivation there would be for (FRM). The idea behind CTM is that, in at least some cases, a cognitive achievement is attained in consequence of strictly morphology-driven interactions among bits of matter. The question is: why believe that semantically antiseptic interactions among dead bits of morphology can generate cognitive achievements? As it is traditionally defined, CTM answers by saying: such interactions are relevantly similar to the cognitively pregnant symbolic-operations performed by logicians and mathematicians. But (FRM) rejects this answer; and (FRM) doesn’t have an answer to the question “why should we believe that semantically antiseptic interactions among dead bits of matter constitute cognitive achievements?” It could well be that, when somebody has a thought, that is in virtue of the fact that some neural state of affairs has certain morphological properties. In fact, there is almost certainly at least an element of truth in that view, given that our cognitive activity is almost certainly not entirely independent of the morphological properties of our brain-states. So (FRM) may be right. But (FRM) doesn’t have any meaningful similarity to (CTM), as it is traditionally understood. There is another difference between (CTM), as traditionally understood, and (FRM). Supposing for the sake of argument that there is a one-one correspondence between neural morphology and mental content, (CTM) aspires to explain that correspondence. (CTM) aspires to explain how thought arises out of unthinking matter. If we grant (CTM)’s supposition that strictly morphology-driven operations among bits of matter are the essence of cognitive achievements like proof- and theorem-generation, it does indeed become clear how it is that bits of dead matter can realize thought; and that is obviously at least part of the reason that (CTM) is so widely accepted. But (FRM) explicitly refuses to endorse that very supposition, and it thus strips (CTM) of much of its raison d’être. So even if it turns out that (FRM) is correct, that wouldn’t redound to the credit of (CTM), at least not on any natural understanding of that doctrine....",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-205",
    "text": "But there is a much more important point to make in response to (FRM). It can be shown that, in so far as interactions among brain-states (or physical objects any kind), constitute instances of thought, those interactions must be driven by the representational (semantic) properties of those states. This doesn’t mean that strictly morphology-driven interactions don’t generate thought. But it means that, in so far as such interactions do generate thought, it is because representational properties are identical with, or realized by, morphological properties and that, consequently, morphology-driven interactions are ipso facto semantics-driven. Let us start by recalling a point made earlier. It is not objects, but states of affairs, that have causal properties and that figure into adequate causal explanations. It is not the rock that breaks the window. What does so is the rock’s colliding with the window with a certain amount of force at a certain instant. Language often obscures this fundamental fact about causality. We say things like “Hitler was the cause of World War II.” But this is obviously elliptical for some statement to the effect that such and such actions on Hitler’s caused (or were partial causes of) World War II. We should also point out that it is states of affairs, not objects, that are caused. What is caused is not the statue, but rather the existence in a certain place and time of a piece of marble with certain properties. I should point out that, in this context, the term “state of affairs” is meant to cover both events as well as static conditions. Some artist is causally responsible for the fact that there is a certain statue in a certain place and time. Here what was caused was a (relatively) static condition. Of course, that condition was caused by way of events: the artist had to chip away at a hunk of marble and then arrange for it to be moved to a certain place. So static conditions are created by way of changes. What is relevant here is that both will be referred to as “states of affairs.” (Incidentally, our usage of that expression is not stipulative or neologistic, and is perfectly consistent with its existing meaning. As we will see later, what we refer to as “static” states of affairs – e.g. a statue’s remaining in a certain place -- are uniform changes, and what we refer to as...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-206",
    "text": "Suppose that I think Socrates at wise and then later think somebody was wise. Let b and b* be the brain-states mediating those thoughts. As we just saw, if b and b* are to constitute a single thought, or are to be part of the same thought-process, it is necessary that b’s being a thought that Socrates was wise be at least part of what generates b*. But it is not sufficient, as the following story shows. A hypnotist programs me to think something was wise whenever my heart rate goes above 90 beats per minute. One day it suddenly occurs to me that Socrates was wise. (I finally understand some obscure passage of the Republic, and I see that, contrary to what I used to think, Socrates really was wise.) The resulting euphoria causes my heart-rate to sky-rocket. Because of my hypnotic programming, this causes me to think something was wise. Here we have a case where my thinking Socrates was wise causes me to think something was wise. So if b and b* are the brain-states associated with those two thoughts, we have a case where b’s being a thought that Socrates was wise is responsible for b*’s being a thought that something was wise. But obviously we don’t have a case where I have thought Socrates was wise, therefore something was wise and, more generally, we don’t have a case where a single thought or thought-process comprises both of those thoughts. An exact analogue of what we just said about b and b* could be constructed in connection with ink-marks or noises or any other symbol-tokens. In general, for the juxtaposition of two representational entities (be they thoughts or symbol-tokens) to constitute a single, complex representation, it is necessary but not sufficient that the one’s being a representation of a certain kind be causally responsible for the generation of the other. Of course, it is an interesting question what other conditions must be fulfilled. But in this context we don’t need to know the answer to that question. CTM demands that semantics be totally inert, and it thus renders impossible the fulfillment of one of the conditions necessary for the combining of representations into other representations. This by itself is a major against CTM, given how frequently such combinations occur.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-207",
    "text": "To develop this line of thought, and to see more fully why CTM must be rejected in light of it, we must first distinguish between two different kinds of complexity. Consider an inscription of the word “Socrates.” That inscription is physically complex, since it consists of a multiplicity of marks. But it is not semantically complex.[173] Any brain-state that realizes a concept of Socrates will inevitably have a great deal of physical complexity. But it doesn’t follow that any such state has representational complexity. I myself believe that anything that realizes a concept of Socrates will have representational complexity. But I cannot take that for granted here, since this is exactly what I am trying to show. In any case, even if anything that realizes a concept does have representational complexity, we must distinguish between the kind of complexity that such a thing has in virtue of being such a concept and the kind of complexity that it has for some other reason. With this distinction in place, let us tell another story. At time t, Smith thinks Socrates. b is the brain state realizing this thought. At some later time t*, Smith thinks snored. b* is the brain-state realizing this thought. For exact analogues of the reasons just given, unless b’s being a representation of Socrates is responsible for b*’s subsequent occurrence, Smith has not thought Socrates snored, at least not in virtue of the fact that b and b* occurred. Semantics cannot be inert if any one is to think anything true or false. No true or false thought is representationally simple. So nobody can think anything true or false except in so far as it is one’s brain-states’ having representational properties that are governing one’s cognitive activity. It readily follows that CTM strips anyone of the ability to think anything true or false, given that, according to CTM, it is never in virtue of its semantic properties that a brain-state has causal powers. I myself believe that, contrary to what the argument just given seems to presuppose, one cannot just think Socrates or snored. Supposing that this right, it might seem that my argument crumbles. But it does not crumble, and this is because, as we discussed earlier, CTM needs it to be possible to think just Socrates or snored or blue. CTM demands that we have atomic concepts, and that our thoughts consist of concatenations of...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-208",
    "text": "Fodor’s argument There is no doubt that some expressions are definable. “Triangle” can be defined as “closed planar figure such that any two, but not all three, of its sides intersect.” “Two” can be defined as “the successor of one.” In general, expressions belonging to “bona fide axiomatic systems” can be defined. Further, “patently phrasal” expressions can be defined, at least in a relative sense: “smart brown cow” can be defined as “anything x such that x is smart, x is brown, and x is a cow.” But leaving aside these two classes of expressions, virtually no expression can be defined. No one has produced an adequate definition of “knowledge.” (It used to be thought that “knowledge” could be defined as “justified true belief.” But Gettier (1963) famously proved this false, and attempts to produce an adequate definition have failed. See Shope 1983.) What we just said about “knowledge” is true of practically any expression denoting a philosophically, or otherwise theoretically, important concept. In fact – what is probably more important – even expressions denoting pedestrian concepts turn out to be incapable of definition. Consider the verb (not the noun) “paint.” Contrary to what might initially be thought, this cannot be defined as “to cover in paint” or even “to intentionally cover in paint.” When you dip your paintbrush into a bucket of paint, you are not painting it, even though you are intentionally covering it in paint. There are other prima facie reasonable definitions of this verb; but they all fail. Given that the word “paint” is indefinable, it follows that the corresponding concept is simple. (In this context, the word “concept” denotes a property or, in any case, some kind of abstract entity. It does not denote a psychological entity; it does not denote one’s grasping of something.) After all, if that concept were complex – if it consisted of other concepts (e.g. cover, intentional, and so on) – then there would be some true statement saying how that concept were composed of those other concepts (just as there is a true statement saying how water molecules are composed of hydrogen and oxygen molecules). There isn’t; so it doesn’t. “Paint” (taken as a verb) is indefinable and the concept that it expresses is therefore simple. Given virtually any other expression, what we just about “paint” is true of that other expression, showing that all (or nearly all) concepts...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-209",
    "text": "In this context, the word “concept” obviously doesn’t denote a psychological entity. So if cogent, the argument just shows that concepts in the non-psychological sense of the word are simples. That argument does not, at least not directly, say anything about concepts in the psychological sense. To simplify further discussion, let us refer to concepts in the non-psychological sense as “conceptso”, and let us refer to concepts in the psychological sense as “concepts.” So a concept is one’s grasp of something, and a concepto is a platonic entity. Fodor is trying to show that concepts are atoms (simples). He is trying to make a case for conceptual atomism. So Fodor must be assuming that if conceptso are simples, the same is of our psychological representations of those concepts. In any case, if this assumption is not granted, then Fodor’s argument doesn’t show that concepts are atoms. So for the sake of argument, let us grant Fodor’s tacit assumption that conceptual atomism follows from conceptualo atomism. (Later we will examine this assumption.) Granting this assumption, there are two major problems with Fodor’s argument. Nobody denies that x’s being a belief is necessary for x’s being knowledge, and nobody denies that the necessity in question is analytic, and not empirical, in nature. Nobody denies that putting paint on something is necessary for painting it, and nobody denies that the necessity in question is analytic. Given any concepto C, nothing is easier than to identify conditions that are analytically necessary for something’s falling under it. But surely analytic necessities correspond to conceptualo structure. x is an instance of knowledge does not entail x is an instance of putting paint on something. But the latter is entailed by x is a case of painting. Surely this tells us that the architecture of the one concepto is different from the architecture of the other. In fact, this last point would seem to be a truism: given that to fall under the one concepto but not the other, x must be an instance of belief, those two conceptso are ipso facto structurally different. When we talk about the “structures” (or “compositions” or “architectures”) of conceptso, we obviously aren’t referring to their physical structures. We are referring to relations of logical dependency, not of spatiotemporal juxtaposition. With a minor qualification to be stated shortly, for conceptso C and C* to differ in respect of their structures just...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-210",
    "text": "So on one possible disambiguation, the term “the concepto identical with Hesperus” refers to this wide-scope descriptive information.[178] What else might the expression “the concepto of Hesperus” refer to? Hesperus’ existence is not a simple, ultimate metaphysical fact. Given any possible world W where Hesperus exists, its existence supervenes on various other facts. Certain displacements, having certain origins, resulted in a large solid body having a certain trajectory. Of course, Hesperus is not modally frozen: there are possible worlds where, because of some cataclysm, it breaks free of its orbit around the sun. More generally, there are worlds where it has properties very different from those that it actually has. But there are no worlds where Hesperus has totally different origins from those that it actually has. Given this last point, it would seem that any world W where Hesperus exists is one that has much in common with our world apart from including Hesperus: some space-time region R of W must comprise innumerable sub-atomic events that are qualitatively much like the events comprised by some corresponding region in our world. Further, because Hesperus is presumably individuated by its origins, it exists in a world only if that world comprises at least some objects that are numerically identical with objects in our worlds. (And, of course, the same thing mutatis mutandis holds of those parents objects.) So there is some list of properties P1…Pn such that, for a world W to comprise Hesperus, it is necessary, and perhaps sufficient, that each of these properties be instantiated in W. (For reasons already given, none of these properties will be identical with Hesperus or identical with Hesperus or a square circle or anything of the sort. For each i, Pi will be some property that is metaphysically and analytically more fundamental than identical with Hesperus or any other such property.) It seems to me that, on one possible (and reasonable) disambiguation, the term “the concepto of Hesperus” refers to this set of properties: the set of properties such that their joint instantiation is necessary (and sufficient) for Hesperus’ existence in any world W. Relative to this disambiguation, the concepto of Hesperus is replete with conceptualo structure. For exactly similar reasons, “the concepto of Socrates” would refer to a conceptuallyo complex entity. And this, of course, would scuttle the objector’s point that “the concepto of Hesperus” and “the concepto of Socrates” refer to...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-211",
    "text": "But as we’ve seen (Chapters 1-4), nothing at all can be inferred from this fact as to structure of the concepto of Aristotle or of the concepto of Socrates. An exact analogue of the argument just given shows that we have said about singular terms is also true of terms denoting natural kinds (“water”, “wood”). Does conceptual atomism follows from conceptualo atomism?",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-212",
    "text": "As we noted earlier, Fodor’s argument tacitly assumes that the truth of conceptualo atomism is sufficient for the truth of conceptual atomism. Is this assumption correct? No. While a case can be made that conceptualo atomism is necessary for conceptual atomism, no case can be made that the former is sufficient for the latter. For the sake of argument, let us suppose that (with the obvious exceptions that Fodor discusses) conceptualo atomism is correct, and let C and C* be two conceptso. Given only that these conceptso are simple, i.e. that no concepts (other than themselves) are constitutive of them, it doesn’t follow that my mental representations of them are conceptually simple. Let X and Y be two qualitatively identical, perfectly homogeneous spheres that are located in different places. I think of X as the sphere in Aunt Jenny’s basement and I think of Y as the sphere in Uncle Fred’s attic. So even though X and Y are qualitatively identical, and even though they are both lacking in internal structure, it doesn’t follow that my concepts of them are qualitatively identical or that my concepts of them are without internal articulations. Given only that two different conceptso have no structure, and thus vacuously have the same structure, it doesn’t follow that my concept of the one is qualitatively identical with my concept of the other. What follows is that I cannot distinguish those conceptso on the basis of their internal structures, not that my concepts of them are themselves without structure. Of course, X and Y are spatiotemporal individuals, whereas conceptso are not; and, conceivably, one might argue that where non-spatiotemporal entities are concerned, the structures of our concepts do mirror those of their objects. But Fodor provides no argument for such a view; and, more importantly, it is extremely implausible. Structurally identical spatiotemporal individuals can be distinguished by their differences in spatiotemporal location. But structurally identical conceptso could not be distinguished in this way. So far as conceptso can be distinguished from one another, it seems to be on the basis of their structures. In any case, Fodor’s tacit assumption (conceptualo atomism is necessary for conceptual atomism) is false. Quine on analyticity",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-213",
    "text": "Let us end this section by discussing Quine’s (1951) analysis of the analytic-synthetic distinction. Quine holds that, with a few trivial exceptions, all sentences are synthetic. (The exceptions involve cases where one term has been stipulated to have the same meaning as another.) Our argument against Fodor assumes that there are analytic truths. Indeed, we have made liberal use of this assumption in this work, and we must therefore consider Quine’s views on analyticity. It should be pointed out that Fodor (1998: 25, 45-46) agrees with Quine. Indeed, Fodor takes it as a foregone conclusion that Quine’s arguments are cogent, give or take some nuances. Here is the basic structure of Quine’s argument. Analyticity is to be understood in terms of synonymy. But synonymy must be understood in terms of analyticity. Therefore the concept of analytic truth is incoherent one. Let us now state Quine’s argument in full. If indeed “bachelors are unmarried males” is analytic, that is because “bachelor” is synonymous with “unmarried male.” Similarly, if “triangles are three-sided, closed, planar, straight-edged figures”, that is because “triangle” is synonymous with “three-sided, closed, planar, straight-edged figures.” What is it for two expressions to be synonymous? It is not merely for them to be insubstitutible salva veritate. “Rhenates” and “chordates” can be intersubstituted salva veritate but they are obviously not synonymous. For two expressions to be synonymous, intersubstitutions of them must preserve not only truth, but also meaning. But the concept of meaning is itself to be understood in terms of the concept of analyticity: ┌x has phi┐ has the same meaning as ┌x has psi┐ iff ┌x has phi iff has psi┐ is analytic. So analyticity is to be defined in terms of synonymy, and synonymy is to be defined in terms analyticity. Attempts to define analyticity are doomed to failure, since they are necessarily characterized by the same vicious circularity as attempts to inductively justify induction; and the concept of analyticity is therefore incoherent. In objection to what we’ve just said, it might be said that “rhenates” and “chordates” cannot be intersubstituted substituted salva veritate. “Smith believes that rhenates are rhenates” is true, but not “Smith believes that rhenates are chordates.” In intensional contexts, intersubstitutions of co-extensive expressions don’t generally preserve truth-value. So we can define “synonymous” is “intersubstitutable salva veritate”, breaking the vicious definitional circle. Quine considers this very point, and successfully rebuts it. The concepto of an...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-214",
    "text": "Quine explicitly assumes that the expressions flanking the biconditional must be synonymous if that sentence is to be analytic. But the expression “n is a unique even prime” obviously isn’t synonymous with the expression “n is one less than three.” So Quine is therefore wrong to assume that there is analyticity only where there is synonymy, and his argument therefore implodes. Conceivably, Quine might deny that (*) is analytic on the grounds that the expressions flanking the biconditional are not synonymous. But in that case, he would simply be redefining the term “analytic”, and his argument would have force only against an artifact of his own definitions. Let us develop this criticism of Quine’s argument. Sometimes when a sentence is described as “analytic”, what is meant is that it encodes an analytic proposition, where an analytic proposition is one that holds entirely in virtue of the structures of the conceptso composing it. An example of such a sentence would be: “there is no law where there is no government.” Surely it is not an empirical fact that there is law only where there is government; it is part of the concepto of law that instances of it presuppose the presence of government. But sometimes when a sentence is described as “analytic”, what is meant is that it is formally true. Even though no empirical knowledge (over and 666 above such as is needed to grasp its meaning) is needed to determine the truth-value of “there is no law where there is no government”, that sentence is not formally true. By contrast, a token of “I am here now” is formally true, as is a token of “if snow is white, then snow is either white or green.” As we discussed earlier, a sentence-token T belonging to language L is formally true iff it is a theorem of the semantic rules of L that T is true. Quine’s statement that analyticity is to be understood in terms of synonymy is therefore ambiguous. Let us consider each disambiguation of Quine’s statement. The concepto of formal truth is not to be defined in terms of that of synonymy. (A sentence or sentence-token T is formally true if its truth is a theorem of the relevant semantic rules. There is no mention of synonymy here.) So Quine’s argument implodes if by an “analytic” sentence, Quine means one that is formally true. Let us now...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-215",
    "text": "We said that, on one disambiguation of the term “analytic”, a sentence is analytic iff it expresses a logically true proposition. (Given how we are using the term “logically true” in this context, it is clear why this analysis is not guilty of any circularity.) Quine did not believe in propositions or in meanings generally, and would thus reject this characterization of analyticity. At least part of the reason that Quine rejects the notion of meaning (and, thus, of propositionality) is that he is a nominalist: he believes in spatiotemporal individuals, but not in platonic abstracta – there are instances of properties, but no properties (except in so far as properties can be identified with, or otherwise reduced to, instances of properties). In Quine’s view, there are noises and ink-marks, but no propositions (except in so far as propositions can be constructed out of noises, ink-marks, and the like). My own view is that nominalism is wrong. But we don’t have to refute nominalism to show that Quine’s position is indefensible. Consider the sentence (or, if you prefer, a token of the sentence): “there is no law where there is no government.” That sentence is not formally true, i.e. it is not a theorem of the relevant semantic rules that it is true. But given those semantic rules, and given no additional empirical information, it follows that it is true. In general, a sentence (or sentence-token) S, belonging to language L, is analytic exactly if, given the semantic rules of L, and given no other empirical information, S’s truth follows. This definition of “analytic truth” satisfies two relevant conditions. First, it doesn’t involve the notion of synonymy. (So supposing that it is correct, Quine’s argument is blocked.) Second, that definition doesn’t involve the notion of a proposition, except in so far as the conceptso semantic rule and following from involve that notion. These are conceptso that Quine himself accepts and that surely must be accepted. It would be absurd to deny that there are semantic rules, even though there are obviously different reasonable views as to what semantic rules are. It would also be absurd to deny that certain statements follow from other statements. (Somebody who denies that statement is affirming the statement: the statement that nothing follows from S follows from the statement that S is a statement. So somebody who denies that statements ever follow from statements is...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-216",
    "text": "But (3) and (4) are not logically equivalent. Given that the one is true, it does not analytically follow that the other is true. If (3) and (4) have the same truth-value, that is entirely a matter of a posteriori fact. Any one operational definition is purely analytic. But when one attempts to give multiple (partial) operational definitions of a concept, one has to make sure that those definitions are empirically consistent with one another – otherwise the concept defined is incoherent. For example, there is nothing incoherent in supposing that light takes m (≠n) time to travel from one end of O to the other, but that O can be brought into coincidence with y. For the sake of argument, suppose that to be true. In that case, given both (1) and (2), the statement “O has length L” entails both that L can, and also cannot, be brought into coincidence with y. To avoid saddling the term “length” with a broken and incoherent concept, we must make sure that our various operational definitions of that term are mutually consistent; and that can be done only through empirical work. Supposing that we (partially) define “length” in terms of (1) and (2), but we haven’t yet established the empirical equivalence of those definitions, we are left with a situation where a true statement (“O has length L”) analytically entails two other statements, namely (3) and (4), but where it remains an empirical question whether both of those statements are compatible. But, granting that there is a sharp distinction between analytic and synthetic statements, this is not a tenable situation. If S1 is true, and analytically entails S2 and S3, then it is ipso facto settled whether both of S2 and S3. The distinction between the analytic and the synthetic appears to have broken down; and the statement “if O has length L, then it takes light n nanoseconds to travel from one of O to the other” isn’t non-arbitrarily categorized as either analytic or synthetic. What was just said about “length” is true of each member of an extensive and important class of expressions. Many terms begin as expressions of lay-discourse and are later appropriated by science. Having been thus appropriated, they are redefined, and usually thereby rendered both more precise and more comprehensive in extension, in light of scientific theories. Terms like “heat” and “temperature” have been existed as...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-217",
    "text": "What (5*) and (6*) make clear is that, where each of (5) and (6) is concerned, the definition of “Smith” actually being given is simply: “Smith” names x, for some x. The reason that (5) does, whereas (6) does not, entail that somebody gave money to Brown’s charity is that (5) is not just a definition: it consists of a synthetic statement (“somebody x uniquely gave money to Brown’s charity”) conjoined (as it were) with a definition (“x is Smith” or “x is named ‘Smith’”). The purely definitional component of (5) is given by a bare singular proposition (x is named “Smith”); the remaining part of (5) is part of the pre-definition, as opposed to the definition per se, of “Smith.” What we just said about (5) is true of (6). So, ultimately, each of (5) and (6) defines “Smith” in the same way, namely: “Smith” names x, for some x. But (5) and (6) create different pre-definitional information, and this creates the conundrum (or illusion thereof) just described. For obvious reasons, expressions cannot be defined in a vacuum; definitions must be made in terms of phenomena that are known to both speaker and auditor. But it doesn’t follow that those phenomena always enter constitutively into the definition itself. In some cases, they are among the means used to give the definition, and are not internal to the definition itself. What we just said about “Smith” is true of “length”, “mass”, “heat”, “hardness”, and other such terms. Each of (5) and (6) can be seen as fixing the referent, not giving the meaning, of the term “length.” If this is right, then the content of (1) is given by the statement:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-218",
    "text": "(1*) There is some property P such that anything x (of the appropriate shape) has P exactly if x can be brought into congruence with object y, and “length L” refers to P. And the content of (2) is given by the statement:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-219",
    "text": "So where each of (1) and (2) is concerned, the strictly definitional component is given by the bare singular proposition: “the expression ‘length L’ refers to P.” For exact analogues of the reasons given in connection with “Smith.” It is true that (1) doesn’t have the same analytic consequences as (2). But this doesn’t indicate that a statement can simultaneously entail, and fail to entail, some other statement. It merely corresponds to the banal fact that different synthetic statements have different consequences. The distinction between reference-fixing and meaning-giving has far-reaching implications as regards scientific methodology. One example of this concerns a doctrine called “operationalism.” According to this doctrine, a term T is scientifically meaningful iff it is operationally definable, i.e. if for any object (or ordered n-tuple of objects) x, there is some observable phenomenon E and some observable operation O such that T describes x iff E results when O is applied to x. Hempel (1965: 123-134) argued compellingly that operationalism is untenable. But the term “operationalism” is ambiguous, depending on whether the term “define” is taken in the reference-fixing or meaning-giving sense. If it is taken in the latter sense, Hempel’s arguments against operationalism are entirely cogent. But those arguments are not cogent if “define” is taken in the former sense. At the same, “operationalism” is eviscerated if it is taken to be the view that an expression T denotes a scientifically respectable concept exactly if observable outcomes of observable procedures may fix the referent of T. It is easily seen that, relative to that definition of “definition”, there is no unique operational characterization of any phenomenon that has observable effects and that, consequently, operationalism is reduced to the triviality that, in some cases, a theoretical (or otherwise unobservable) phenomenon may have an observable effect. So Hempel’s arguments against “operationalism” are cogent, so long as that term is taken in a way that does not eviscerate it. The ambiguity of “ambiguity”",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-220",
    "text": "is true on one disambiguation, but false on another. If by “the English language” is meant the set of semantic rules that, at this instant in time, characterize the language spoken in Australia, England, and so on, then that statement is false. But that claim is true if by “the English language” is meant a series of sets of semantic rules such that, first, the set of rules operative in Australia, New Zealand, and so on, is a member of that series and such that, second, there is a certain kind of spatiotemporal continuity between any two installments in that sequence. So (7) is false on the “synchronic” meaning of “the English language”, but true on the “diachronic” meaning of that expression. Words change their meanings. (There is “semantic shift”, as linguists put it.) This inevitably creates ambiguity since, during the period of semantic shift, some people continue to use the term in the old way. (In fact, semantic shift usually, though not necessarily, occurs in consequence of an absence of uniformity of usage.) But while the ambiguities associated with words like “bank” or “dumb” are easily recognized as such, and thus tend not to lead to confusion, the ambiguities created by semantic shift are less likely to be recognized as such, and what are in fact purely terminological differences come to be seen as having a substantive dimension. (We might say that “bank” is an instance of “synchronic ambiguity”, since its ambiguity is not a reflection of change in its usage, and that “temperature” is an instance of “diachronic” ambiguity, since its ambiguity between molecular, phenomenological, and other concepts is a reflection of language-change.) Synchronic ambiguities are (relatively) stable: “bank” has meant both river’s edge and financial institution for hundreds of years. By contrast, diachronic ambiguities are unstable, almost by definition, and they typically quickly give way uniformity of usage and thus to synchronic non-ambiguity. For obvious psychological reasons, if a term is used non-uniformly on Monday, and uniformly on Tuesday, people will tend to regard as deviant those Monday-usages of the term that don’t conform to its Tuesday-usage. Semantic shift thus tends to create the illusion that, during the unstable interim-period, people were simply using the expression in question wrongly. A related point is that people tend to mistake continuous changes for identities. So because semantic shift usually happens continuously, there is often little recognition that it has...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-221",
    "text": "Suppose that the concepto knowledge were conceptuallyo complex, i.e. that it consisted of other conceptso. In that case, for obvious reasons, it would consist of the conceptso belief, true, justified, and perhaps also the conceptso non-accidental and reliable. Supposing that the concepto knowledge does consist of these other conceptso, it follows straightforwardly that cognitive operations with that the concepto knowledge should demand more intelligence and more energy than cognitive operations with conceptso like justification, belief, and truth. After all, thinking knowledge would necessarily involve thinking justification, truth, and so on, but not vice versa. So thinking knowledge would necessarily be more demanding, in terms of intelligence and energy than thinking any of these constituent conceptso. But the empirical data doesn’t bear this out. Experiments show that people process claims about knowledge more quickly and effectively than they do claims about justification, belief, and the like. The non-experimental empirical data is consistent with this. Most three year olds make true claims involving the concepto knowledge. (“I know that dogs bark.” “I know that I have to go school tomorrow.”) But, apart from the odd prodigy, no three year old ever talks about justification. What we just said about the concepto of knowledge seems to be true of conceptso generally. Any four year old can grasp true propositions about money (“I have a dollar in my pocket”) and about linguistic communication (“Daddy just told me to leave his office”). But how many four year olds could grasp the conceptso of which, if our philosophical analyses are right, those conceptso decompose? How many four year olds could grasp the conceptso into which John Searle, for example, analyses the concepts of money and linguistic communication? And supposing that they can grasp these constituent conceptso, will their cognitive operations with them be as expeditious or as accurate as their thoughts about the concepto of money? Surely not.[184]",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-222",
    "text": "You obviously grasp conceptso. You grasp the conceptso knowledge, justification, truth, causation, and various others. But does all cognitive activity consist in the manipulation of conceptso? Is all mental activity conceptual? Dogs and cats have minds, and those minds process information. But do dogs and cats grasp conceptso? A dog can be aware of an individual stick, an individual bone, and individual person. But does a dog grasp the conceptso stick, bone, and person? Many would answer by saying “no.” If that is right, then not all cognitive activity involves concepto manipulation and, in fact, conceptual activity would be a very evolved and derivative form of cognitive activity. Of course, what we’ve said so far hardly constitutes an irrefutable proof that there is non-conceptual cognitive activity. But right now I would like to operate on the plausible assumption that there is such activity. That said, we will momentarily encounter some good reasons to accept that assumption; and in chapters 22-23, we will encounter what I regard as conclusive evidence of its correctness. What is the difference between grasping instances of a concepto and grasping the concepto itself? What is the difference between grasping individual instances of (say) redness and grasping the very concepto of redness? Here is the answer that I would propose. To grasp a concepto is to grasp what different concrete situations have in common. To grasp the concepto redness (or squirrel or rock…) is to have some understanding of how red (or squirrelly or rocky…) situations resemble each other. If this is right, then grasping conceptso is not a pre-requisite to grasping instances of conceptso. The opposite is the case: grasping situations is a pre-requisite to grasping conceptso. Suppose that you see what is in fact an instance of redness. Even if you have a concept of (say) redness, it isn’t as though your perception is the result of your exercising this concept. Innumerably many chromatically different possible situations correspond to your concept of redness. Given only that you are thinking of some object as being red, your mental activity leaves it quite indeterminate what the actual color of that object is. This suggests that your sense-perceiving a situation cannot possibly consist in your exercising the concepts that you have.[185] What we just said about your concept of redness is true of practically any other concept. (I say “practically” in acknowledgement of a class of exceptions that...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-223",
    "text": "It is demonstrable that the concepto triangle is capable of infinitely many, non-trivially different analyses. This fact is inexplicable if we say that conceptualo analyses showed how conceptso decomposed into other conceptso. It is not possible for the concepto xxx triangle to decompose into the concepto side, and also to fail to thus decompose. But given that both (a) and (b) are adequate analyses of the concepto triangle, this is what we must say if we take the view that an analysis of a concepto shows how it decomposes into other conceptso. One could resist this by denying that both (a) and (b) are genuine analyses of the concepto triangle – by insisting that, for example, (a) constituted an analysis whereas (b) did not. But such a position would be completely arbitrary; and it would be inconsistent with the fact that what counts as an illuminating an analysis is a function in large part of the context – of what xxx our starting assumptions and dialectical objectives are. We can avoid both self-contradiction and arbitrariness by saying that conceptualo analyses show that there are two different, but equally adequate, ways of conceptualizing a given bundle of non-conceptualo information. In that way, we don’t have to take the arbitrary view that either (a) or (b) xxx is not an adequate analysis; and we don’t have to take the self-contradictory view that the concepto triangle both does, and does not, decompose into the concepto side. As we will see in Chapter 24, this approach also enables us to explain how conceptualo analyses can be informative; and we will also see how the same is not true of the view that an analysis of a concepto shows how it decomposes into other conceptso. If these remarks are correct, it is clear what we must say about analytic conditionals, for example:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-224",
    "text": "Every cognitively normal person is able to make extraordinarily delicate judgments about other people’s emotions, about art and music, and about the behavior of physical bodies. But only the most erudite people can even begin to articulate the grounds for these judgments. One could conceivably take the view that it is only when one can articulate the grounds for one’s beliefs that those beliefs are principled. But such a view would be radically implausible.[190] It is more reasonable to say what we are naturally inclined to say, namely: such judgments are at least sometimes principled, but the principles in question are not always easily articulated and they often fall outside the scope of introspective awareness. Consider the following scenario. Jones listens to performances of thousands of different pieces, one third of which are unmistakably instances of rock ‘n’ roll, the other two thirds of which are unmistakably not xxx instances of that genre. Jones has no difficulty distinguishing the pieces that are instances of rock ‘n’ roll from those that are not. When Jones classifies a piece as being rock ‘n’ roll, he does so on the basis of its melodic, rhythmic, and contrapuntal properties. (We are setting aside the skeptical possibility that Jones is simply making lucky guesses over and over again.) In classifying a given piece as rock ‘n’ roll, Jones is not making a conjecture; he is not making an inductive leap into the future. Rather, he is conceptualizing the data that is already at his disposal. Given that piece X has such and such musical properties, it thus follows conceptuallyo or analytically that it is an instance of rock ‘n’ roll. Of course, it is not analytic that X has such and such properties, and it is not analytic that X is an instance of rock ‘n’ roll. But given that X has such and such properties, it follows conceptuallyo, and not inductively or probabilistically, that it is rock ‘n’ roll. This shows that the concepto of rock ‘n’ roll has analytic structure, and also that Jones’ classifications embody a knowledge of that structure. Before we proceed, we should note that the points just made furnish a refutation of Fodor’s first argument for atomism. Would Jones be able to define the term “rock ‘n’ roll”? No. It is unlikely that anyone is able to give an unexceptionable definition of that term.[191] But it obviously doesn’t follow...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-225",
    "text": "We’ve already seen some reason to hold that there is overlap between the extensions of the conceptso non-conceptual knowledge and sub-personal knowledge. But given only what we’ve seen, it would be premature to say that these two conceptso have identical extensions. It remains a possibility that at least some sub-personal knowledge is conceptual in nature. Indeed, if Chomsky’s views are at least approximately correct, the sub-personal realm is replete with manipulations of conceptso. We’ve also seen that the concepto of procedural knowledge is closely related to the concepto of sub-personal knowledge. But that connection is probably not one of co-extensiveness. Much knowledge-how is personal knowledge. At the personal level, I know how to speak English, how to tie my shoes, and how to ride a bike. If cognitive scientists are right, this knowledge-how expresses sub-personal knowledge-that. For example, my ability to speak English derives from a sub-personal understanding of conceptso like NP-deletion and c-command.[197] But given that at least some knowledge-how is personal, it follows that the extensions of the conceptso sub-personal knowledge and procedural knowledge do not coincide. At the same time, it doesn’t follow that those extensions are completely disjoint; for it remains a possibility that some knowledge-how is sub-personal. It is not clear exactly what the connections are between the conceptso sub-personal knowledge, non-conceptual knowledge, and procedural knowledge. But what is clear is that Fodor’s argument is vitiated by a failure to take these conceptso into account. This is ironic since few thinkers, if any, have done as good a job as Fodor in defending theories that posit sub-personal cognition.[198]",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-226",
    "text": "For the sake of argument, suppose that conceptual non-atomism is correct. In that case, for any concept C that you have, you have C in virtue of having various other concepts C1…Cn. So, for example, if you have a concept of triangularity, you have that concept in virtue of having concepts of straightness, flatness, number, and so on. If you have a concept of Socrates, you have that concept in virtue of having concepts of space, time, causality, hemlock, and so on. But, supposing that non-atomism is correct, how exactly is your concept of triangularity constituted by your concepts of straightness, flatness, and number? How exactly is your concept of Socrates constituted by your concepts of hemlock, sarcasm, and personhood? The answer is that, if non-atomism is right, your believing that x is a triangle consists in your believing that x is a closed, planar, three-sided, straight-edged figure (or, at any rate, in your having some other comparable belief, e.g. that x is the area bounded by three straight lines such that any two, but not all three, of them intersect). Your believing that x is Socrates consists in your believing that x is a unique dialectician to have died of hemlock poisoning (or in your having some other comparable belief). In general, if non-atomism is correct, whether you have a concept of a given entity is a function of what you believe. This means that non-atomism has a number of obviously false consequences. Suppose that you believe of Socrates that he was a talented wrestler in his youth. In that case, if non-atomism is correct, your believing that x is Socrates consists in your believing (inter alia) that x was a talented wrestler at some point. In that case, anything that is not a talented wrestler ipso facto fails to satisfy the description encoded in your concept of Socrates. So anything that was not a talented wrestler fails to meet the preconditions that, given the structure of your concept, would have to be met for you to believe it to be Socrates. It follows that you couldn’t possibly learn, or even come to believe, that Socrates was not a talented wrestler. If non-atomism is right, what you believe about the things that your concepts are concepts of determines what your concepts are concepts of. A corollary is that your beliefs about a given thing are frozen. What you believe...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-227",
    "text": "Given that I have a concept of the number two, I can then go on to have all manner of beliefs, both true and false, about that number. I can believe falsely that Smith has two mansions (when he in fact has none); I can believe falsely that two is not a prime number; and so on. A corollary is that, given that you and I both have concepts of that number – in other words, provided that each of us knows the truth of some proposition like (2) -- there is no limit to how much we may disagree about it. I may believe that Smith has two mansions, and you may disagree. I may believe that the number two is the class of all pairs of objects; you may disagree. To be sure, if non-atomism is right, then in order for both of us to have beliefs about the number two, we must share some beliefs. For us to agree or disagree about the number two, we must both accept (2) or, at any rate, some other comparable existence-claim. This puts limits on how much, from a non-atomist’s viewpoint, two people can disagree about the number two. We cannot disagree as to whether it is the successor of one; nor can we disagree as to whether it is a number.[200] But it does not follow from the non-atomist’s position that you and I have to be complete lock-step as to what we think concerning that number. Nor does it follow that a person’s beliefs about that number cannot change. All that follows from the non-atomist’s position is that certain core beliefs cannot be given up. But this is not an unreasonable requirement. Indeed, its negation seems unreasonable. Could you really believe of the number two that it wasn’t a number, or that it was actually the successor of four (as opposed to one)? It seems that, if you believe of x that it is not a number, you ipso facto don’t believe that it is the number two, and that if you believe of x that it is greater than four, you ipso facto don’t believe it to be the immediate successor of one. Fodor argues that, if one concedes even this much, one must also concede that everything a person believes about that number is constitutive of his concept of it, and that a person cannot change...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-228",
    "text": "But when I sincerely utter “Socrates was wise”, what I am affirming is confined to what is to the right of the semantic-operator. We’ve discussed at length how people instinctively keep non-linguistic (pre-semantic) information to the left of the relevant operators, keeping only the relevant linguistic (semantic) information to their right. Supposing that you are the person to whom I utter that sentence, you must find your way to its literal meaning by way of your concept of Socrates. (We are supposing that you speak English.) This concept, though different from mine, will lead you to the same literal meaning; and when you affirm or deny (or otherwise operate with) “Socrates is wise”, what you are affirming or denying is exactly what I affirmed. The miracle of language is precisely that it allows people who have different concepts of a given thing to communicate about that thing. The peculiarities of the individual’s concept of that thing become irrelevant. Let us bring these points to bear on Fodor’s view. First, Fodor is right to say so far as (3) constitutes my concept of Socrates, I cannot cease to believe that Socrates is not an object x such that, on the occasion in question, Smith and Brown were not talking about x. But, given that fact, there is no limit to what I may come to believe or disbelieve about Socrates. I can come to believe that he studied in Egypt, and I can later come to retract that belief. Further, what we just said about me is true (mutatis mutandis) of you. Given that (5) constitutes your concept of Socrates, you cannot come to believe that Socrates was not the protagonist of The Republic; but given this fact, there is no limit to what you can subsequently come to believe, or cease to believe, about Socrates. Finally, because each of us knows what is meant by tokens of “Socrates was wise”, even though we grasp that literal meaning in different ways (corresponding to the differences in our respective concepts of Socrates), that does not affect our ability to mean the same thing by utterances of that proposition. For some x, the proposition x was wise is what both you and I affirm through sincere utterances of “Socrates was wise.” And so long as I know some proposition like (3) and you know some proposition like (5) – in other words, so...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-229",
    "text": "Fodor argues that conceptual non-atomism is identical, or equivalent, with a doctrine to the effect that, if x has content C, x’s having that content supervenes on, or is identical with, x’s having a certain inferential role. So x is Smith’s belief that O is a triangle exactly if, in virtue of having x, Smith is disposed to make certain inferences, e.g. he is disposed to infer O has three sides and O is flat and so on. Let (IRA) be our term for the doctrine just described, since that doctrine gives an inferential-role account of mental content.[202] According to Fodor, conceptual non-atomism is either identical with (IRA) or at least presupposes the truth of that doctrine. Supposing that a concept of flatness, of straightness, of the number three, and so on, are constitutive of one’s concept of triangularity, that is because for one to believe that x is a triangle just is to believe that O is flat, three-sided, and so on. So given non-atomism, it seems reasonable to say that x (some brain-state) is one’s belief that O is a triangle exactly if, in virtue of having x, one beliefs, or is disposed to infer, that x is flat, three-sided, straight-edged, and so on. It thus seems that non-atomism and IRA are identical or at least equivalent. Supposing that this is correct, and also that Fodor’s argument against non-atomism is cogent, it follows that IRA has the same problems as non-atomism, and must therefore be rejected. We have already seen that the second of these suppositions is false. But let us set that aside for now, and let us focus on the question: is non-atomism identical with IRA? It is worth knowing the answer to this question even if, as we have argued, Fodor’s arguments against non-atomism are misguided; for it might turn out (and, in fact, it will turn out) that IRA has problems that warrant its rejection and that warrant the rejection of non-atomism, if non-atomism presupposes IRA. First of all, Fodor is entirely right to reject IRA. It is obviously false to say that a brain-state (or anything else) has a given content in virtue of its inferential role. Since there are inferences only where there is already content, nothing can have content in virtue of its inferential role. So far as, in virtue of having x, I have a tendency to infer that O...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-230",
    "text": "Nonetheless, there is a doctrine that is similar to IRA that is not absurd (but that we argue to be false, on the grounds that it is a version of functionalism). Suppose that, in virtue of having x, I have a disposition not to infer, but only to form the belief, that O is flat, closed, three-sided, and so on. In that case, it might plausibly be said that x is, or realizes, a belief that O is a triangle. The idea, appropriately generalized, would be this. Let x be some brain-state (or other characteristic) of person P. There are certain beliefs B1…Bn such that x has content C exactly if, in virtue of having x, P is disposed to form all, or at least some chosen subset of, B1…Bn. The content of a brain-state (or anything else) supervenes not on its inferential, but on its transitional, role. This doctrine provides a transitional-role analysis of mental content. Let us therefore refer to it as TRA. Christopher Peacocke advocates a version of TRA. In due course, we will discuss the viability of his analysis and of TRA-analyses generally. But right now I would like to address a narrower question. Supposing, if only for the sake of argument, that TRA is correct, does that doctrine have the defects that Fodor ascribes to non-atomism? Supposing that TRA is correct, does it follow that I cannot change my beliefs about Socrates, or that two people cannot have disagreements as to whether Socrates was a good orator or not? No. What we said about non-atomism (in the context of defending it against Fodor’s third argument) is true mutatis mutandis of TRA. Let B be some brain-state of mine; and suppose that, in virtue of having B, I am disposed to accept O is flat and O is three-sided, and other such propositions. In that case, according to TRA, B is (or realizes) a belief that O is a triangle. Now suppose now that I come to believe (falsely) O is green. In that case, given a belief that x=O, I do indeed have a disposition to believe that x is green. But does it follow that I am incapable of grasping the very idea of O’s not being green? Does it follow that I mistakenly believe greenness to be definitive of O? No. Once again, we must distinguish between, on the one hand, the information...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-231",
    "text": "There is a significant problem with non-atomism, but it isn’t one of the problems attributed to it by Fodor. Let us start by considering our specific version of non-atomism; we will subsequently show that what we say in connection with our analysis is true of non-atomism generally. According to our analysis, my concept of Socrates consists in my knowledge of some existence-claim. But in order to grasp an existence-claim, one must already grasp various conceptso. To grasp the proposition somebody x was uniquely a great dialectician to die of hemlock-poisoning, I must grasp the concepts hemlock dialectician, and so on. We seem to be launched on an infinite and vicious regress if we say of our grasp of those conceptso what we said of our grasp of Socrates. To avoid that regress, we must say that, ultimately, conception does not consist in knowledge of existence-claims. But in that case, our analysis is erroneous. All versions of non-atomism analyze the having of a given concept in terms of the having other concepts. For example, Peacocke (1992, 1996) says that brain-state B is one’s concept of addition exactly if, in virtue of having B, one is disposed to make certain judgments. Each of those judgments involves grasping some proposition, and thus involves grasping the various concepts of which that proposition is composed. So conception is analyzed in terms of conception, and we thus appear to be stuck with a vicious regress (or circle). This point is an extremely important one, and we will deal with it at length. Further, we will find that it does invalidate certain kinds of non-atomism. We will also see that, even though it does not invalidate our version of non-atomism, it does force us to make substantive additions to that analysis. Drawing heavily on Evans’ (1982) distinction between “conceptual” and “non-conceptual” content, we will make those additions in Chapters 22 and 23. There are different kinds of concepts. There are concepts of properties; there are concepts of hyper-properties (properties of properties); and there are concepts of individuals. As we will see, what we refer to as “properties” are really hyper-properties. There are important differences between our concepts of individuals, on the one hand, and our concepts of properties, on the other; and when we take these into account, the regress described a moment ago vanishes. But it is crucial that we address the objection to our analysis...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-232",
    "text": "(EA) As we’ve discussed, thought it systematic. If you can think Bob is ambivalent towards Mary and Seymour hates Ted, then you can think Mary hates Seymour and Bob is ambivalent towards Ted. Put another way: if one grasps the concepts loves, ambivalence, Ted, and so on, then one can grasp any permutation of those concepts. A person can think any (viable) permutation of the concepts that he grasps.[203] There is an important corollary. Suppose that, after issues relating to the performance-competence distinction have been taken into account, a person cannot think some proposition consisting of concepts C1…Cn. In that case, given that thought is systematic, it follows that one doesn’t grasp at least one of those concepts. We must make one last preliminary distinction. For obvious reasons, of both a psychological and a logical nature, one doesn’t think every permutation of every subset of the set of concepts that one grasps. But given any particular permutation of any particular such subset, one doesn’t have any special barriers to thinking it. In some cases, it may be difficult to do so. Maybe Smith grasps each of the relevant concepts, but he lacks the intelligence to think some particular arrangement of them; maybe Smith has the requisite degree of intelligence but has a psychological resistance to thinking that particular permutation. But these are obviously performance-related issues, and one can coherently consider what Smith’s mind would be like if it weren’t subject to these performative problems idealize, but were structurally the same as it is now. Here is an illustration. Suppose that Smith grasps Emily hates Frank and also Mom loves Dad. But, because of his psychological defenses, Smith is incapable of grasping Mom hates Dad. We can coherently imagine a mind structurally more or less identical with Smith’s that could think Mom hates Dad. Smith’s inability to think this thought doesn’t correspond to some systemic fact about his cognitive architecture, but only to his inability to exploit resources of that architecture. If indeed there is sub-personal mentation, the concepts involved are categorically sealed off from the concepts available to consciousness and, more generally, to the personal level of mentation. If cognitive scientists are right, then our sub-personal minds are continually solving simultaneous equations that would be unsolvable at the level of personal ideation for anyone other than, and possibly including, the world’s best mathematician. If cognitive scientists are right, there is...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-233",
    "text": "xxx I believe that Evans is entirely to hold that thought is systematic and that, leaving aside performance-based problems, any person is able to grasp any permutation of the concepts that he or she grasps. But given only that thought is systematic, it doesn’t follow that each of two separate cognitive units must be able to grasp any concatenation of concepts that belong either to the one unit or the other. So it doesn’t follow that one xxx must be able to combine a concept that one grasps at the personal level with one that grasps at the sub-personal level. Suppose that Smith grasps the concepts Bob, Jane, and loves and that Jones grasps the concepts Howard, Mary, and hates. Given only this information, the fact that thought is systematic doesn’t demand that anyone or anything be able to grasp the proposition Jane hates Howard or Mary loves Jane. What systematicity does demand is that Smith be able to think Jane loves Bob and Bob loves Jane, and that Jones be able to think Howard hates Mary and Mary hates Howard. In the argument just presented, replace each occurrence of “Smith” with an occurrence of “Smith’s xxx personal level of mentation” and replace each occurrence of “Jones” with an occurrence of “Smith’s sub-personal level of mentation.” (If you wish, you may also replace the expressions “Howard”, “Mary”, and “hates” with occurrences of expressions denoting concepts that, one might feel, are more appropriately associated with sub-personal thought: e.g. heavy NP-shift, c-command, differential equation.) The resulting argument shows that systematicity does not demand that concepts grasped by a given person at the sub-personal level necessarily be capable of being combined into units that can be grasped by that same person at the personal level. Systematicity demands that concepts within a given cognitive sphere or module be permutable. It doesn’t demand complete interpenetrability of every cognitive module.[204] We should also point out that, if cognitive scientists are right, sub-personal concepts combine and recombine with one another at least as freely as their personal counterparts. In fact, given how much information-processing is sub-personal, it seems xxx clear that sub-personal concepts are much more promiscuous than their personal counterparts[205], and that the former are therefore less counterexamples to systematicity than the latter. Evans takes it for granted that, were they to exist, sub-personal concepts would be frozen – incapable of being used except in certain...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-234",
    "text": "Supposing that it exists, sub-personal mentation consists in the following of rules – in the performing of derivations in accordance with various logical and methodological strictures. (In any case, the sub-personal mentation actually posited by cognitive scientists like Chomsky and Marr consists in acts of rule-following. Whether sub-personal mentation, supposing it to exist, must consist in such acts is a question we will set aside.) There can’t be rule-following without a rule-follower. So if there is sub-personal thought, that means that there is a sub-personal rule-follower (to whom we will refer as RF). But then we must explain how it is that RF can think. We generate a vicious regress if we say that RF’s cognitive achievements supervene on cognitive performances that are buried in his sub-personal psyche. On the other hand, if we say that we can explain RF’s ability to follow rules, and otherwise think, without imputing sub-personal though to him, we are conceding the explanatory uselessness of the idea that there is such thought.[206] Suppose that brain-state B realizes my thought that Socrates was wise, and that brain-state B* realizes my later thought that somebody was wise. As we’ve discussed, for me to have inferred that somebody was wise from my belief that Socrates was wise, it is not enough that B cause B*. It is necessary that B’s being a thought that Socrates was wise be what is causally responsible for B*’s subsequent existence and, in particular, its being a thought that somebody was wise. In fact, we’ve seen that even if this condition is met, I still might not have inferred the one proposition from the other. There is, we saw, some special causal relation R such that (given that B and B* realize, respectively, my thought that Socrates was wise thought and thought that somebody was wise) I have inferred somebody was wise from Socrates was wise exactly if B’s being a thought that Socrates was wise generates B* in manner R. Given this, suppose that, in fact, B’s being a thought that Socrates was wise does generate B* in manner R. In other words, suppose I have inferred somebody was wise from Socrates was wise. (Suppose that the inference is made at the personal level.) Where am I in all of this? Where is the person who makes the inference? If by a person, we mean some kind of an unpropertied entity underlying...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-235",
    "text": "Searle has another argument to the effect that behavior and conscious psychological phenomena ought not to be explained in terms of sub-personal cognitive processes: Let us start with a short story. Using a paper and pencil, you divide two multi-digit numbers. (So you are doing “long-division.”) During the period of time that you are carrying out this operation, the distance of Alpha Centauri with respect to your hand is increasing uniformly. So, during that period, the shape of your hand is a function of its distance from Alpha Centauri. The motions of your hand therefore accord with that rule, even though you are obviously not following it. The rules that you are following have to do with facts about symbolism and mathematics that have nothing to do with the distance of your hand from Alpha Centauri. Human conduct – what noises people make and how they move their bodies – may well be in accordance with the rules described by Chomsky, Marr, and other cognitive scientists. But it doesn’t follow that anyone is following those rules. So far as anyone thinks otherwise, he is failing to distinguish between following a rule, on the one hand, and acting in accordance with a rule, on the other. Of course, given only how people move their bodies, it doesn’t follow that they are not following the rules described by Chomsky. But to explain human behavior, there is no need to suppose that they are following those rules. So far as human behavior is not to be explained in terms of what is occurring at the level of consciousness, it can be entirely explained in terms of physiology. You ask me “how did your interview go?” I respond by saying: “I thought that I answered some of the interviewer’s questions creditably; but in other cases, my answers were spurious and the interviewer was visibly dissatisfied with them.” According to Chomsky, various unconscious cognitive processes mediated between auditory input and verbal output. But there is no need for such an extravagant hypothesis, given that a complete explanation of your response is obviously to be found in your physiological structure. There is simply no need to posit the manipulations of representations posited by Chomsky, and there is nothing to be gained by positing them. There are conscious mental phenomena, and there is pure physiology; and between the two, everything that needs to be explained can be...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-236",
    "text": "Searle is obviously right to distinguish between following a rule and acting in accordance with a rule. But, beyond that, Searle’s argument has little force. First of all, given only that there are two ways of explaining some phenomenon, it doesn’t follow that one of those explanations is superfluous. Physics gives us one explanation as to why Smith’s heart is racing. Biology gives us another explanation. But it doesn’t follow that either explanation is wrong or even that either explanation is unnecessary. Contrary to what Carnap (1934) argued, it is extremely unlikely that the information embodied in biological explanations could be recovered by strictly physical explanations. As Jackson and Pettit (2004d) show, higher-level explanations capture principled regularities that lower level explanations cannot capture, a consequence being that the former are richer in certain kinds of information than the latter. For this reason, as Jackson and Pettit make clear, higher level explanations are not merely inferior versions of lower-level explanations. Economic explanations are not approximate psychological explanations. Physiological explanations are not approximate microphysical explanations. And xxx psychological explanations are not approximate physiological explanations. So given only that there is a strictly physiological explanation as to why I utter a certain noise, it doesn’t follow that other explanations are not possible or that other explanations are not necessary. In particular, it doesn’t follow that Chomsky’s story is either wrong or unnecessary. For the moment, let us consider a psychological explanation that does not involve the supposition that there are unconscious (let alone sub-personal) psychological entities. You tell me that you want to drive to the store and you ask me where the car keys are. I tell you that they are on my desk. You promptly walk in the direction of my desk. Given what modern neuroscience tells us, there is every reason to believe that your bodily movements can be understood in strictly physiological terms. At the same time, your conduct can be understood, at least up to a point, in terms of what you desire (to drive to the store) and what you believe (that the car keys are on my desk). Given only that a physiological explanation is possible, it would be absurd to reject the psychological story. It would be equally absurd to reject Chomsky’s account of verbal behavior, given only that a physiological explanation of that behavior is possible. Of course, there are some obvious differences between...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-237",
    "text": "Despite what we might initially think, the possible evidence in favor of (H4) does not coincide with that in favor of (H1). If Smith has very strange beliefs about mathematics and about what people are capable of, he might walk on the grass even though he is attempting to comply with the rule described either stay of the grass or become a square circle. But ceteris paribus he will not walk on the grass if he is attempting to comply with the rule stay off the grass. Setting aside concerns of a generally skeptical nature, it is often possible to establish beyond a reasonable doubt that another person has or lacks a given concept. (For example, you can establish with reasonable certainty that a student of yours doesn’t have the concept of a fractal.) Therefore, it could in principle be established that Smith lacked the concept square circle, but that he had the concepts needed to grasp the rule stay off the grass. Supposing that we learned this about Smith, his avoidance of green surfaces would provide support for (H1) but not for (H4). Let R be the rule earlier described that assigns a certain configuration to my hand depending on its distance from Alpha Centauri. For reasons similar to those just given, the hypothesis that:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-238",
    "text": "Given certain reasonable background assumptions, (H5) xxx is strongly disconfirmed by my not responding a certain way to questions like “name the five stars that are closest to the Earth.” But given those same background assumptions, (H6) xxx is not disconfirmed by that same data. Also, if I were trying to follow R, it is virtually impossible that I would succeed in doing so. Given that I am not superhumanly intelligent, I couldn’t possibly know at each instant in the relevant time-interval how my hand was supposed to be moving. Second, even if I did have that knowledge, my hand-movements would necessarily fail to keep pace with that knowledge, given that there is a time-delay (albeit a small one) between the brain-event mediating my intention to move my hand and my subsequent hand-movement. My mis-adding two twenty-digit numbers is consistent with the hypothesis that my behavior is guided by the rules of arithmetic, but it is not consistent with the hypothesis that my behavior accords with those rules. My never drawing a perfect circle is consistent with the hypothesis that my behavior is often guided by the rule draw a perfect circle, but it is not consistent with the hypothesis that my behavior accords with that rule. When Chomsky says that we “follow” certain syntactic rules, he means that our cognitive and physical activity is guided by such rules. That hypothesis is confirmationally very different from the hypothesis that our conduct accords with such rules. One reason why those hypotheses are different is that there is necessarily a gulf between “performance” and “competence.” Because we have limited energy, memory, and intelligence, our attempts to follow rules don’t always succeed. So it is perfectly consistent with Chomsky’s view that, on at least some occasions, our thought and conduct do not perfectly accord with the rules that, according to Chomsky, we are following. It is precisely because being guided by a rule doesn’t involve acting in perfect accordance with it that Chomsky distinguishes between performance and competence. We can now weigh in on the debate between Chomsky and Searle. Chomsky noticed that our overt behavior – the noises and ink-marks that we produce, the movements that we make – is consistent with the hypothesis that linguistic activity results from our following certain kinds of rules. On this basis, Chomsky hypothesized that our linguistic activity results from our following rules of that kind....",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-239",
    "text": "For example, (H7) is, whereas (H6) is not, consistent with the supposition that Smith’s behavior doesn’t always accord with R. In fact, depending on the circumstances, (H7) is consistent with the supposition that Smith’s behavior never accords with R. Let us illustrate these ideas by assigning a definite value to R. Supposing that S is a sentence of the form ┌…the phi the psi… ┐, let R be the rule that says how S’s meaning depends on the values of phi and psi. (Examples of sentences having that form are “he saw the woman the old man warned him about” and “she threw paint on the car the man fixed.” So R says how the meaning of the former depends on the meanings of “woman” and “old man”, and it says how the meaning of the latter depends on the meanings of “car”, “man”, and “fixed.”) Smith’s being unable to assign the right meaning to the sentence “the girl the cat the dog the boy fed bit saw fell” is inconsistent with (H8) but perfectly consistent with (H7). In fact, if Smith is following R, it is a virtual certainty that his linguistic activity will not always accord with that same rule, given the distinction between competence and performance. So if Smith’s activity were to accord perfectly with R, that would be evidence that he was not following that rule. Conceivably, Searle might respond by saying the following:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-240",
    "text": "The problem is that X is following R is in fact confirmationally different from X is acting in rough accordance with R, 666 and those confirmational differences favor Chomsky’s view. Let R be some arithmetical algorithm. Ceteris paribus, I am more likely to follow R correctly when I am adding small numbers than when adding big ones. Ceteris paribus, I am more likely to follow R correctly when I am well rested than when I am severely sleep deprived. Ceteris paribus, I am more likely to follow R correctly when the relevant numerals are clearly visible than when they are hard to see. The presence of a performance-inhibiting factor can typically be established independently of the degree of success of the relevant performance. Your views as to whether I am well rested probably don’t have to be based on the success of my attempts to add numbers. The same is, of course, of your views as to whether I can see the relevant numerals and also of your views as to whether those numerals denote large or small numbers. A corollary is that the absence of a performance-inhibiting factor can typically be established independently of someone’s performance. Smith says that he is a world-class sight-reader. But every time I ask him to sight-read an easy piece, his performance, xxx while passable, is not that of a world class sight-reader. In other words, his attempts to comply with the relevant musical rules are not characterized by the level of success that would probably characterize those of a world-class sight-reader. Xxx There are various possible 666 explanations as to why Smith’s performance is mediocre that have anything more than an infinitesimally small chance of being correct. One is that he is not a world-class sight-reader. Another is that, although he is a world-class sight-reader, he was suffering from an acute vitamin B deficiency every time I asked him to play. Yet another is that somebody paid him a million dollars to simulate the performance of a mediocre sight-reader. Xxx If Smith really is suffering from a vitamin B deficiency, or somebody has paid him off, that can usually be established with reasonable certainty. In any case, the hypothesis Smith is a world-class sight-reader but he was suffering from a vitamin B deficiency every time I asked him to perform is confirmationally very different from the hypothesis Smith is a mediocre sight-reader, and...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-241",
    "text": "(a) and (b) are confirmationally very different. If X is actually following R, then his not perfectly according with R is to be explained in terms of the presence of some performance-inhibiting factor. Xxx Because the presence or absence of such a factor can be established with reasonable certainty, xxx the hypothesis that xxx Smith’s performance is to be explained in terms of his imperfectly following R is confirmationally different from the hypothesis that his performance is not to be explained in terms of his following R. For similar reasons, the hypothesis that our linguistic activity involves our following rules involving concepts like verb-deletion and heavy NP-shift is confirmationally very different from the hypothesis that our approximate compliance with such rules is not to be understood in terms of our following such rules. Chomsky’s hypotheses are therefore not evidentially interchangeable with hypotheses that don’t explain our behavior in terms of our following rules of the kind just described. So the question whether Chomsky is right is an empirical one. (There is a qualification to this. Searle maintains that the concept of sub-conscious thought is simply an incoherent one. If he is right about this, then the question whether Chomsky is right is not a strictly empirical one, and is at least partly conceptual. Searle holds that the concept of subconscious mental activity is in fact incoherent. [DELETE] We will examine Searle’s position, as well as his argument for it, in the last section of the present chapter.) 666 An important point made by Gareth Evans (1985: 322-344) helps make it clear that:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-242",
    "text": "and thus helps make it clear that Chomsky’s position is less frail than Searle makes it out to be. Evans points out that concepts and aptitudes are not frozen. If you speak Chinese there isn’t going to be any one Chinese sentence that you understand. Of course, it is perfectly possible to know the meaning of just one Chinese sentence. Somebody who doesn’t speak Chinese can be told what some one Chinese sentence means, or he can figure it out on the basis of context. But a genuine knowledge of Chinese will necessarily be “productive”, i.e. it will be expressed in an ability to understand a multiplicity of different Chinese sentences. Somebody who can hit just one sequence of keys cannot play the piano. 666 If you can play Mozart’s sonata in A-minor, then you can learn to play the sonata in C-minor. This isn’t to say that you will play the sonata in C-minor as well as you can play the sonata in A-minor; and it certainly isn’t to say that you can learn to play any piano piece that has ever been written. (Many pianists who can play Mozart cannot play Liszt.) But it is to say that, if you try to learn the sonata in C-minor, you won’t find that you hit a wall: you won’t find that you are completely incapable of playing the relevant sequence of notes. What we just said about aptitudes is true of concepts.[211] It isn’t as though somebody who grasps the concept of addition can add three and five, but can’t add any other two numbers. And it isn’t as though one’s knowledge that 3+5=8 will be confined to any one context. Suppose that Jones can figure out that Ted has a total of eight shoes on the basis of the information that Ted has exactly three shoes in one closet and exactly five shoes in another closet, and no shoes that are not in either of those two closets. In that case, Jones is going to be able to figure out that Larry has eight houses on the basis of the information that he has exactly three houses in Jamaica and exactly five houses in Brazil, and no houses that are not in Jamaica or Brazil.[212] If somebody’s writing “12+15=27” results from his following the rules of arithmetic, then he necessarily grasps the concepts involved in that rule, and his...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-243",
    "text": "You begin with some correct points, but end up with a very wrong one. Here are the correct points. If Timmy really knows arithmetic, then he should be able to figure out how many houses Bob has, given the information that Bob has two more houses than Charles and that Charles has three houses. Given only that Timmy can manipulate the right symbols in the right way, it doesn’t follow that he grasps arithmetic; for it could be that he knows how to manipulate the symbols even though he has no idea what they mean. In general, if a person grasps arithmetic, that knowledge will be expressed in ways other than his or her being able to rattle off sums and products. So far so good. But the cracks in your argument become obvious the moment we ask the question: Why is a person’s arithmetical knowledge expressed in these various other abilities? Why is a person who grasps arithmetic able to make judgments about the number of houses that Bob owns and about the number of shoes that Mona bought? Because a person grasps the concepts house, shoe, buy, and so on. But given that calculators don’t grasp these concepts, it would be absurd to suppose that their knowledge of arithmetic would be expressed in their making judgments involving these concepts. Let C be some concept that Martians grasp but that human beings do not grasp. It would be absurd to suppose that our arithmetical knowledge would be expressed in our making judgments involving that concept. Our arithmetical knowledge is expressed in terms of the concepts that are out our disposal, not in terms of those that are not. Similarly, a calculator’s behavior is expressed in terms of the concepts that are at its disposal, not in terms of concepts – e.g. boat, house, and shoe – that are not. My calculator’s concept of addition interacts with the few other concepts at its disposal at least as well your concept of addition interacts with the various concepts at your disposal. As you say, the behavior of my calculator is different from of a person who knows arithmetic. But this is precisely what we would expect, given that people grasp various concepts that calculators do not – just as we would expect a Martian’s knowledge of arithmetic to be expressed differently from a person’s knowledge of that domain, supposing that Martians...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-244",
    "text": "This objection inadvertently exposes a reason to hold that, even after the relevant background-facts are taken into account, a calculator does not act like an actual arithmetician. Suppose that Smith knows arithmetic but that he doesn’t know any of the symbolic conventions that (in our culture) are associated with a knowledge of arithmetic. So Smith doesn’t know that “1” denotes 1, that “×” stands for the operation of multiplication, and so on. For the very reasons given by the objector, it would obviously be absurd to suppose that Smith’s knowledge of arithmetic would be expressed in his writing down “7×9=63”, “1+12=13”, and so on. And if Smith did produce such inscriptions, then (supposing that we didn’t revise our views as to his symbolic knowledge) we’d have to assume that they were not expressions of his arithmetical knowledge. It would be absurd to suppose that somebody grasped the fact that “1” denoted one, that “×” stood for the operation of multiplication, and so on, but that he didn’t grasp the concept of denotation. And it would be absurd to suppose that somebody grasped the concept of denotation but that he didn’t grasp the more general concept of representation. Once it is granted that somebody knows the symbolic conventions associated with arithmetic, it is de rigueur to grant that he also grasps various other notions – notions that even CTM-hardliners would be unwilling to impute to calculators. Given these points, suppose that your calculator really does grasp the concepts of arithmetic. Unless it is granted that the calculator grasps the relevant symbolic conventions, along with the concepts that would be needed to have such a grasp, it 666 [space issue] would be absurd to suppose that the computer’s arithmetical knowledge would be expressed in its tokening expressions “7×9=63” and “1+12=13.” That supposition is as 666 absurd as the supposition that a calculator’s arithmetical knowledge would be expressed in terms of judgments about boats and houses. So if any case is to be made that, after their limited conceptual backgrounds are taken into account, calculators really do act like things that know arithmetic, it must be assumed that calculators have a rich backlog of semantic knowledge. In that case, there must be some independent evidence, i.e. evidence other than their tokening expressions of arithmetic, that they in fact grasp such concepts. But there is no such evidence; there is no independent evidence that...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-245",
    "text": "Wittgenstein’s so-called “private language” argument is meant to show that there cannot be a private language that is not a mere translation of a public language. Let me say what is meant by the italicized qualification. Obviously a person could create a private code for himself. I want to keep a diary. I know that my housemates will read it. So I invent a private code that they won’t understand. I replace each letter with the cube of the number giving the place of that letter in the alphabet. So instead of “b”, I write “8”; instead of writing “e” I write “125”; and so on. This private code is obviously parasitic on the existence of a public language. Wittgenstein doesn’t deny that there can be private languages in this sense. Wittgenstein denies that there can be private languages that are not thus parasitic. Before we give Wittgenstein’s argument, let us say a word on why it is thought to be important. It is widely thought that if there is sub-personal mentation, it is mediated by some kind of language. This view is held both by advocates and opponents of cognitive science. If this is right, then there can be no sub-personal mentation, supposing that Wittgenstein’s argument is indeed cogent (Fodor 1975, Dennett 1978: 91-95, Pylyshin 1984, Fodor and Pylyshin 1988). Advocates of cognitive science say that there is sub-personal mentation and thus some kind private language; and they say that the Private Language Argument must therefore contain some kind of error (Fodor 1975).[219] Opponents of cognitive science say that the Private Language is cogent and that, consequently, there is no private language and thus no sub-personal mentation. Here is my reconstruction of the Private Language Argument:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-246",
    "text": "(***) yesterday it was sunny. Here we can take one of two positions. On the one hand, we can say that Smith misunderstood the inscription of (*) that he was looking at: (So (*) really means: today it snowed. Since Smith thinks otherwise, he is wrong.) On the other hand, we can say that (*) now really does mean (***). But it is not hard to show that the first option is untenable and that we must therefore accept the second. Suppose that, one day, every English-speaker in existence suddenly came to believe that the sound “blue” meant red and that the sound “red” meant blue. (To simplify discussion, let us suppose that any books or records containing any indication of the previous usages of those terms were suddenly destroyed.) In that case, “blue” would mean red and “red” would mean blue. Of course, if I alone believe that “blue” means red and “red” means blue, I will be wrong. But I would be wrong only because there would be millions of other people whose usage of those terms didn’t correspond to my belief. Given that Smith is the only speaker of his language, his deciding that (*) actually means (***) is comparable to the case where every English speaker suddenly takes 666 “red” to mean blue; it is not comparable to the case where I alone 666 reverse the meanings of “red” and “blue.” Smith’s usage of a given expression (of his language) sets the standard. It would therefore be absurd to say that Smith has misunderstood an expression of that language. That would be like saying that the word “probably” really means demonstrably (i.e. capable of being shown to be true on strictly deductive grounds), since that is what “probably” meant five hundred years ago, and that every English speaker alive today is therefore wrong to take “probably” to mean having more than a 50% (but less than a 100%) change of being true. If this is right, then Smith cannot possibly be wrong as to what an expression of his language means. Any expression of his language means what he thinks it means. In that case, there is no wrong way to use any expression of that language. (Of course, matters would be different if other people started using those expressions. But, by hypothesis, the language in question is spoken only by one person.) If there is...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-247",
    "text": "Wittgenstein points out that if somebody misuses an expression belonging to a public language, there are consequences. If I tell my doctor “I feel enervated”, when what I mean is I feel overly energized, he will give me the wrong medication (assuming that he knows what “enervated” means and believes that I know what it means). As Wittgenstein points out, nothing comparable happens in Smith’s case. Wittgenstein holds that, for this reason, the concept of a rule doesn’t apply to Smith’s situation. A “rule” that can be broken with impunity is no rule at all. Since Smith has carte blanche to break the so-called rules of LM, it follows that there are no such rules. This line of thought confuses the consequences of breaking a semantic rule with the consequences of those consequences. Suppose that Jones promises to give me a million dollars if I manage to solve a difficult math problem. The solution to the problem is 712. I believe that the solution is 418. But I don’t speak English well, and I say “the solution is 712”, thinking that I have said the solution is 418. Jones gives me a million dollars. Here I broke the rules of English-semantics. (I misused an expression.) Because I broke the rules of English semantics, Jones took me to mean the solution is 712 when what I meant was: the solution is 418. So by itself my breaking the semantic rules of English had a negative consequence: I was misunderstood. In its turn, that consequence – negative though it was – had another consequence; and the goodness of the second consequence obviously outweighed the badness of the first. But my being misunderstood was, by itself, a negative consequence of my linguistic incompetence. A brief digression through meta-ethics may clarify the principle at work here. Bad consequences that are outweighed by good ones do not, in virtue of that fact, cease to be bad. Suppose that I catch a cold and thus cannot make my flight. The plane that I would have flown on crashes. By itself, my catching a cold is a bad thing: surely physical illness is a bad thing. That bad thing had a consequence which, for its part, was very positive. But it would be absurd to say that, because it had a good consequence, my being physically ill was good in and of itself. Similarly, it would be...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-248",
    "text": "We have seen that the Private Language is fallacious and therefore proves nothing. But why is it thought that, if it were cogent, it would warrant the rejection of the idea that there is sub-personal mentation? Why would sub-personal mentation necessarily involve a language? As we’ve seen, Fodor thinks that all thinking – and therefore all sub-personal thinking – involves a language. His view is that, if sub-personal mentation were to exist, it would necessarily involve some kind of internal code, by means of which different cognitive modules would communicate with one another. Many cognitive scientists agree with Fodor about this.[223] We’ve considered Fodor’s arguments on behalf of the idea that there must be a language of thought, and we’ve seen that those arguments are untenable. We’ve also seen positive reasons to think that there is no language of thought. But contrary to what both some cognitive scientists and Wittgensteinians think, the non-existence of a private language doesn’t have any bearing on the question whether there is sub-personal thought or, therefore, on whether the theories posited by Chomsky, Marr, and other cognitive scientists are correct. Those theories demand that there be sub-personal exchanges of information among different cognitive sub-systems. But it doesn’t follow that those exchanges involve a language. Given only that information-exchanges between people typically involve a language, it doesn’t follow that the same is true of information-exchanges within a single person. Computationalists often seem to say that any representational system is ipso facto a language.[224] But if that is correct, then thesis that we think in language is reduced to the triviality that we have thoughts. So to the extent that it is not trivial to suppose that there is a language of thought, there must be non-linguistic modes of exchanging and encoding information. 666 Given this, there is no obvious reason why cognitive science must hold that mental operations are linguistic. A consequence is that, even if it were cogent, the Private Language Argument would have no bearing on the viability of that discipline. Computationalists are actually conceding too much to Wittgenstein. Wittgenstein appears to have held that there can be no thought outside of a communal context, given that there can be no language outside of such a context. (Wittgensteinians are violently opposed to the idea that there can be non-communal thinkers. They think that Robinson Crusoe either doesn’t think – at most, he has thought-like...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-249",
    "text": "Smith is driving along. He sees a stop-sign. He knows of S and therefore stops his car. One analysis of this situation is as follows. S is some kind of abstract or hyper-real object, and Smith’s knowing about S consists in his beholding this object. He applies the information given to him in this platonic insight to his current situation. Because he applies this information correctly, he decides to stop his car. Here is what Wittgenstein says. For the sake of argument, suppose that the analysis just given is correct. If Smith applies his knowledge of the aforementioned hyper-real object in a haphazard or arbitrary manner, he will make the wrong decision: he will decide not to stop. Smith must therefore apply his knowledge of this object in a principled manner. This means that he must follow some principle or rule S1 that says how to apply S. But by the same logic, he must then follow some rule S2 that says how to follow S1. We have generated a vicious regress. Consider the function F(x)=x2. You haven’t considered each of the ordered pairs constitutive of this function. For example, you have not (let us suppose) considered F(937). How would you find out the value of F(937)? One is tempted to answer this by saying: “To grasp F(x)=x2 is to be aware of some platonic entity, and one figures out the value of F(937) through a principled application of the information embodied in this awareness.” In other words, one applies the first principle by knowing some second principle. But then the question that we asked in connection with the first principle arises in connection with the second, and we are no closer to explaining how you are able to produce the right answer. Wittgenstein then seems to suggest that principled behavior isn’t to be explained in terms of grasping anything at all. One sees; one reacts. There is no intervening grasp of platonic entities. One just does it. Wittgenstein makes it clear that, in his view, there is a distinction between principled and unprincipled behavior. But he seems to think that the difference lies not in anything that is internal to the subject’s psyche. As Wittgenstein himself puts it, if God were allowed only to see inside people’s minds, He wouldn’t always be able to distinguish between somebody who happened to make a correct guess as to the value of...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-250",
    "text": "(S*) To grasp S just is to knows of anything x having certain properties (red, hexagonal…) that one is ipso facto supposed to stop at x. Before we continue, we must distinguish (S*) from two other statements:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-251",
    "text": "If (S***) is right, then given every stop-sign x in the world, anyone who grasps (S) is aware of x individually, i.e. any such person knows of each stop-sign x in existence that one is supposed to stop at x specifically. Since that is false, so is (S***). (S**) is false for the reason that Wittgenstein himself gives: (S**) explains the grasping of principle (S) in terms of the grasping of some second principle (given anything x that is red, hexagonal, and so on, one is supposed to stop at x). So, just as Wittgenstein argues, (S**) merely passes the buck, leading to a vicious regress. But Wittgenstein’s argument doesn’t apply to (S*); and (S*) doesn’t falsely presuppose that each person who knows (S) is acquainted with every individual stop-sign. (S*) is to the effect that a person’s knowing (S) consists in his knowing of anything x that he encounters (or otherwise considers) and that he believes to be red, hexagonal, and so on, that x is, in virtue of having those very properties, such that one is to stop at it. Given that (S*) is true, knowledge of how to apply S is built into knowing S. There is no need to invoke knowledge of a second principle. Nor is there need to invoke a knowledge of every stop-sign in existence. Smith is driving along and he sees what is in fact a stop-sign. But he doesn’t realize that he is seeing a stop-sign. Because of unusual lighting conditions, his visual perception leads him to believe that what he is seeing is round and yellow, as opposed to yellow and hexagonal. So Smith doesn’t stop. Does this mean that Smith doesn’t grasp S? Of course not. To grasp S is for it to be the case that, for any object x that one considers, and that one believes to have the relevant properties (red, hexagonal…), one knows that, in virtue of having those properties, x is such that one must stop at it. Grasping S obviously doesn’t involve being infallible, or even reliable, at distinguishing things that are stop-signs from things that are not. Grasping S consists in its being the case that when one believes (whether truly or falsely) of an object that it has certain properties, one believes that one is ipso facto to stop at it.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-252",
    "text": "Here is a different way of articulating our thesis. This re-articulation is not needless repetition: for it will help us map what we have said about relatively simple rules, like (S), onto more complex one, like F(x)=x2. Grasping S consists in its being the case that, if one believes x to have certain properties (red, hexagonal…), and if one believes y to be a case of stopping at x, then one believes that, in virtue of those facts, the pair <x,y> is to be assigned to some class C; and in its also being the that if one believes x to have certain properties (red, hexagonal…), and if one believes y to be a case of not stopping at x, then one believes that, in virtue of those facts, the pair <x,y> is to be assigned to the complement of C. So grasping S consists in one’s believing that, for some class C, <x,y> falls into C if y is a case of stopping at x, where x is an object that is red, hexagonal, and so on, and that otherwise <x,y> falls into the complement of C. Thus, one’s grasping S consists in two conditions being met:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-253",
    "text": "To see why this is not the case, we need only remember what we said earlier about the non-conceptual basis of conceptual knowledge. You hear a song on the radio. You know that it is an instance of rock ‘n’ roll – not jazz, not classical, not hip-hop. You classify that song as rock ‘n’ roll on the basis of its properties – its harmonic and melodic modalities, its rhythms, and so on. Each of these properties can be characterized independently of the concept of rock ‘n’ roll, and you can grasp any one of these properties without having that concept. If Bach were to come back from the dead one day and hear that song, he would know that it had those melodic, harmonic, and rhythmic properties. But he would not, at least not immediately, have the concept of rock ‘n’ roll. If a piece falls under the concept rock ‘n’ roll, that is in virtue of its having properties that are ultimately not to be understood in terms of its falling under that, or any other, concept. A closely related point is that conceptual knowledge supervenes on non-conceptual knowledge. Your knowing that a certain piece falls under the concept rock ‘n’ roll is ultimately to be understood in terms of your grasping information that is not to be understood in terms of that piece’s falling under that, or any other, concept. In general, conceptual truths 666 supervene on non-conceptual truths 666, and conceptual knowledge supervenes on non-conceptual knowledge. Conceptual truths must be seen as articulations of non-conceptual truths, and conceptual knowledge is an articulation of non-conceptual knowledge. If one grasps a concept – be it the concept of rock ‘n’ roll or of exponentiation – one grasps it in terms of content that is ultimately non-conceptual. The operative word here is “ultimately.” It is not hard to see the non-conceptual basis for a truth of the form that song is an instance of rock ‘n’ roll. One hears the sounds – the melodies and harmonies, and the timbres of the instruments that generate them – and one superimposes a judgment (that is rock ‘n’ roll) on that mass of raw, non-conceptual information. But some judgments are often at many removes from their non-conceptual bases. The concept of exponentiation is grasped in terms of that of multiplication. The concept of multiplication is grasped in terms of that of addition....",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-254",
    "text": "For it to be unclear “how to apply” a concept C is for it to be unclear whether the object (or situation) in question satisfies the antecedent of (*) (or, more precisely, of the specialization of (*) that gives the content of one’s concept of C). There is a never a gap between grasping a concept and knowing how to apply it. But there is sometimes a gap between grasping a concept and knowing whether to apply it. Given a grasp of a concept C, one ipso facto knows of any object x satisfying the relevant boundary conditions whether C(x) is true or not. But one often doesn’t know whether those boundary-conditions obtain. Since there is no gap between grasping a concept and knowing how to apply it, Wittgenstein’s regress is blocked. Of course, there is a gap between grasping a concept and knowing whether some object meets the relevant boundary conditions. You can grasp the rule stop your car at signs having certain properties (red, hexagonal…) without seeing that the sign in front of you has those properties. (Maybe you aren’t wearing your glasses; maybe you are color-blind.) But doesn’t mean that you have to figure out how to apply your knowledge of that law to know what you should do if it should turn out that there is a sign with those properties in front of you. Knowledge of what to do, in the event that there is such a sign, is built into your grasp of that concept. It is obviously irrelevant that you do not know, for each object (or even for object that you consider), whether it is red, hexagonal, and so on. We must distinguish conceptual from pre-conceptual knowledge; we must distinguish knowledge of a concept from knowledge as to whether the preconditions for a concept’s applicability have been met. For exactly similar reasons, you can grasp the rule F(x)=x2 without knowing of each pair of numbers, or even of each pair of numbers that you consider, whether one squares the other. But, contrary to what Wittgenstein appears to argue, this doesn’t mean that some kind of vicious regressiveness is embedded in the concept of a concept. It corresponds only to the innocuous fact that it isn’t always obvious whether a given object satisfies the antecedent of a conditional proposition. The personal unconscious",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-255",
    "text": "It would make no sense to say that desks were not physical objects. A desk is a paradigm case of such an object. Leaving aside cases of insincerity or linguistic incompetence, anyone who said “desks are not physical objects” would be proposing a 666 redefinition of the term “physical object.” Somebody who says that there are unconscious mental states is producing a comparable redefinition of the term “mental state.”[229] Conscious states are paradigm-cases of psychological entities. To think of an object as being psychological is to think of it as being relevantly like those entities that form our experiences: it is to think of it as being a surge of joy, a perception, an urge, and so on. Our experiences are constituents of consciousness -- you don’t experience what you don’t feel, and a feeling is some kind of “modification” (for lack of a better word) of one’s consciousness. Thus, anything that is “relevantly like” an experience of ours must itself be a constituent of consciousness. We eviscerate the concept of mind if we admit that there are mental entities that are not constituents of consciousness, just as we eviscerate the concept of physicality if we admit that desks, rocks, and trees are not physical objects. Of course, there are dispositional mental entities – e.g. beliefs, aspirations, propositional attitudes generally, as well as character traits -- and these cannot be identified with constituents of consciousness. (Although it has conscious manifestations, my belief that 1+1=2 is not itself comparable to a tickle or a pain: it doesn’t vanish when I lose consciousness.) But this isn’t really a significant problem for the view that mentality is identical with consciousness. A belief that 1+1=2 is nothing more than a disposition to have certain conscious states, e.g. a disposition to think Smith must have two apples upon being told Smith used to have one apple and he has now been given a second one (and he never ate, or otherwise parted with, the first one). That disposition can be understood in strictly neurological terms. In general, in so far as beliefs, character traits, and so forth, are distinct from their conscious manifestations, they are to be understood in strictly physiological terms: as physiological propensities to have certain conscious states. There is nothing distinctively psychological about them. Hearts, livers, and bile-ducts give rise to conscious states. But it would obviously be absurd to say that...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-256",
    "text": "This view is untenable, the reason being that it implicitly denies the existence of beliefs, aspirations, and propositional attitudes generally. 666 Right now I am conscious of the moon. (I can see it through the window behind my computer.) But the moon is not a constituent of my consciousness. Obviously those who identify mentality with consciousness do not mean that something is a part of a person’s mind only if he is conscious of it. They mean that something is a part of a person’s mind only if that thing is a constituent of his consciousness. There is no denying that beliefs, character traits, and so on, are mental entities. There is also no denying that my belief that 1+1=2 is not a constituent of my consciousness. For the sake of argument, let us take a dispositionalist view as to the nature of that belief, i.e. let us regard that belief as being mere physiology, so far as it isn’t identical with the conscious states or overt behaviors that manifest it. Let B be the brain-state (or neural-structure) that mediates that belief, i.e. this disposition or set of dispositions. 666 In light of this, suppose I am told “Bill used to have exactly one apple; he didn’t eat it or otherwise lose possession of it; and he has just been given another apple.” In response I say: “In that case, Bill now has two apples.” (Let us suppose that I produce this utterance for the right reasons: I produce it because I know what those sounds mean, and I know that, under the circumstances, the meaning that they bear is one that can correctly be affirmed.) As we discussed earlier, it cannot be B simpliciter that causes me to produce that utterance. (It is not the rock that breaks the window – it is the rock’s moving with a certain velocity…) If it isn’t B’s encoding the proposition that 1+1=2 that causes me to produce the utterance just described, then we don’t have a case where my utterance manifests a belief. Given that B mediates my belief that 1+1=2, and given that my utterance of “Bill has two apples” was produced intelligently – i.e. it was produced in consequence of my having the relevant beliefs and not in consequence of, say, my having some kind of involuntary laryngeal spasm – it follows that it must have been B’s encoding a...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-257",
    "text": "xxx Languages are systematic: a natural language can express any viable permutation of the concepts expressed by any sentence belonging to it. If a language can express the proposition Tom loves Mary, then it can also express the proposition Mary loves Tom. To take another example: If a language can express the proposition: supposing that they were anatomically capable of playing the piano, penguins would find Bach’s contrapuntal compositions easier to perform than Schumann’s non-contrapuntal compositions, then it can also express the proposition: supposing that he were anatomically capable of playing the piano, Schumann would find Bach’s non-contrapuntal compositions easier to perform than penguins’ contrapuntal compositions. Languages are “systematic.” Like language, thought is systematic. This property of thought is easily explained if it is supposed that we think in a language. The systematicity of thought provides some evidence that we think in a language. Xxx To speak English is to have internalized various semantic rules. A precondition for being able to manipulate these rules is that one’s thought be systematic. This is a matter of logical, as opposed to causal, necessity. Your understanding “Tom loves Mary” consists in your being able to compute the identity of the proposition meant by that sentence (or, strictly speaking, occurrences thereof) on the basis of the relevant semantic rules. The very act of applying those rules to a new sequence of expressions is itself an instance of the systematicity of thought. Further, knowledge of the recursive rules involved the assignment of Tom loves Mary to “Tom loves Mary” can only be understood in combinatorial terms, and such knowledge therefore presupposes cognitive systematicity. Consider the expression “loves.” That expression must be defined contextually: an utterance of ┌x loves y┐ is true iff x loves y. (Of course, this point is not self-evident. In a moment, we will see why it is true.) Since “x” and “y” are variables, understanding the rule just described consists being able to substitute different constants for those variables. It involves being able to understand the result of substituting “Bob” for “x” and “Samantha” for y; and, by the same token, it involves being able to understand the result of substituting “Samantha” for “x” and “Bob” for y. In response to this, one might say that it is possible to understand “loves” without being able to understand different sentences of the form ┌x loves y┐ and, consequently, that an understanding of...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-258",
    "text": "The statement that languages are necessarily perfectly systematic is false. We can imagine a language L that has a single, semantically simple symbol that means Mary hates Bob, but that doesn’t have distinct symbols for Mary, Bob, or the relation of hitting. In that case, even though L can express the proposition Mary hates Bob, it cannot necessarily express the proposition Bob hates Mary. There doesn’t seem to be any reason in principle why a language might not consist only of semantically simple expressions that expressed whole propositions. Such a language wouldn’t be systematic at all. So given only the supposition that a representational medium is a language, it doesn’t follow that it is systematic. Thus, given only the supposition that we think in a language, we don’t have any explanation as to why thought is systematic. Of course, given the supposition that we think in a language along with the supposition that the language in question is systematic, we do have such an explanation of the fact that thought is systematic. But it must then be explained on empirical grounds why that internal language is systematic. And in that case, the supposition that we think in a language explains the systematic character of thought only to the extent that there is some other, independent explanation of that fact. Therefore, the systematicity of thought is to be explained in terms of that other, independent explanation, and the supposition that we think in a language becomes completely gratuitous. As we’ve just seen, given only that we use languages, it doesn’t follow that we use systematic languages. So it is an open, empirical question why the languages that we use are systematic. Here is one possible answer to that question. We cannot say what we have to say through a language that is unsystematic; an unsystematic language wouldn’t do justice to our thoughts – just as a palate consisting only of two colors wouldn’t do justice to Cezanne’s artistic vision. For this reason, we prefer language L to language L* if ceteris paribus L is more systematic than L*. Given this preference of ours, we tend to use systematic modes of expressions. Unless thought were systematic, it is hard to see why ceteris paribus systematic languages would do a better job than non-systematic languages of expressing our thoughts. Once again, it turns out that the systematicity of language is to be understood...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-259",
    "text": "First of all, the productivity of language seems to be an aspect of its systematicity.[234] Productivity is the permutability of sentences; systematicity is the permutability of expressions in general. Given that productivity is a kind of systematicity, it follows that everything we just about the latter is true of the former and, therefore, that Fodor’s third argument has the same defects as his second. Also, the premise of argument #3 is false or, in any case, is only contingently true. As we saw, there is nothing absurd in the supposition that a language L might contain a primitive expression meaning Bob loves Mary, but no expression meaning Mary loves Bob. Given obvious extensions of what we said a moment ago, in connection with argument #2, it follows that argument #3 does not go through. Argument #4 for SCT: grasped but unaffirmed propositions",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-260",
    "text": "When you say “either snow is white or penguins are mammals” or “if penguins are mammals, then some mammals live in Antarctica”, you are not asserting that penguins are mammals. Not every assertible constituent of an utterance is itself asserted. Similarly, not every believable constituent of a thought is itself believed. You can believe either snow is white or penguins are mammals without believing either disjunct. Given that language has a corresponding property, this property of thought is plausibly explained by assuming that we think in a language. Given what we’ve said so far, the obvious criticism of this argument is that this property of language is to be explained in terms of the corresponding property of thought, and not vice versa. I believe that this criticism is cogent, and that there are special reasons to think that this particular argument of Fodor’s is guilty of explanatory error just cited. Before we develop our criticism of argument #4, we need to clarify some points concerning the concept of sentential-constituency. It would be deeply arbitrary to say that the occurrence of “snow is white” in",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-261",
    "text": "In particular, it would be arbitrary to say that the occurrence in (*) did have assertoric force, whereas its counterpart in (**) did not. (*) and (**) make different statements, of course. But that isn’t because “snow is white” has assertoric force in one of them but not the other. It is because of the specific meanings of “or” and “and.” For exactly similar reasons, the occurrence of “snow is white” is no more asserted in “it is true that snow is white” than it is in “it is false that snow is white.” What this shows that is that any sentence that is a constituent of another sentence ipso facto lacks assertoric force – even if, because of the verbiage in which that occurrence is embedded, the proposition meant by that occurrence is affirmed. A corollary is that any sentence-occurrence that has assertoric force automatically forms a sentence (or sentence-token, to be more precise) unto itself. More generally, any sentence-occurrence that has any kind of force – be it assertoric, imperatival, interrogative, exhortatory…-- is a sentence unto itself, and is not a constituent of another sentence. There is one last preparatory point to make. Obviously only sentences can be asserted. You can’t assert “Socrates” or “red”, unless your utterance is elliptical for a complete sentence, e.g. “the color of my new shirt is red” or “Socrates is my favorite philosopher.” In light of these points, let us ask: what does it mean to say that not every assertible constituent of a sentence is itself asserted? Given that any constituent of a sentence is ipso facto unasserted, and given that nothing other than a sentence can be asserted, it means nothing more, and nothing less, than that there are complex sentences. It means, in other words, that there are sentences that are composed of other sentences. Similarly, to say that thought has a property parallel to the one just described is to say nothing more, and nothing less, than that there are complex thoughts -- thoughts that consist of other thoughts. This brings us to what appears to be a fundamental difference between thought and language. As we’ve discussed, there is a definite sense in which a sentence has minimal units of significance. But, by all appearances, the same is not true of thought. (In this context, “thought” refers not just to discursive mentation, but to anything mental that is...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-262",
    "text": "Let us consider yet another argument given by Fodor on behalf of SCT. This argument, it will be seen, is in a different vein from the four just considered. We will refer to it as “Fodor’s argument from induction” (FAI): (FAI) Obviously much of our thinking consists in the making of inductive inferences. But Goodman showed that any data that warrants an intuitively reasonable inductive inference also warrants an intuitively unreasonable one. Let D be the fact that every emerald observed before time t has been green. Given D, it is reasonable to infer that:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-263",
    "text": "where x is grue just in case x is green before time t and blue after that time. Nonetheless, there is presumably there is some legitimate, as opposed to purely subjective, reason to prefer (G) to (B). In general, notwithstanding Goodman’s correct point, there must be some reason to reject those hypotheses that we characterize as “counter-inductive” in favor of those that we characterize as “inductively reasonable.” (I am taking it for granted that somebody who prefers (G) to (B), given (D), is ceteris paribus better at inductive reasoning than somebody who has the opposite preference.) The difference lies in the fact that, given our various background beliefs, accepting (G) instead of (B) would lead to a simpler and more integrated body of beliefs than would accepting (B) instead of (G). Given our various background beliefs, considerations of simplicity warrant our believing (G) as opposed to (B), even though by itself (D) confers no more weight on (G) than it does on (B). Given data D1…Dn, hypothesis H is ceteris paribus preferable to hypothesis H* if acceptance of H is theoretically simpler than acceptance of H*. (Of course, theoretical simplicity must be distinguished from psychological simplicity. Theoretical simplicity is a property of the relationship between hypothesis and data. Psychological simplicity is a property of the relationship between belief in a hypothesis and belief in data.) We seldom make bent inductions: when our inductions are wrong, it is (almost) never because they are in the same category as (B). This means that ceteris paribus we prefer simple to complex hypotheses. This in turn means that we have some way of comparing hypotheses in respect of how simple they are (or, more precisely, in respect of how simply they can be assimilated into our existing beliefs). Thus, encoded in our thinking is some kind of “simplicity metric”, without which we would make bent, wrong inductions. Simplicity, in the relevant sense, is to be understood in terms of the syntaxes of sentences. Suppose that L is a scientifically viable method of coding hypotheses into sentences and that, given any proposition P, there is a unique sentence S(P) of L that encodes P. [To facilitate our exposition of Fodor’s argument, let us prescind from the fact that, in this context, use of the term “scientifically viable” might constitute vicious circularity, given that it is a near synonym of “inductively viable.”] In that case, H’s...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-264",
    "text": "(ii) Let S1…Sn be the sentences, or sequences of sentences, belonging to L that express inductively sound arguments. There is some property PHI such that the derivation tree of Si has PHI just in case 1≤i≤n. Thus, for some property PHI, the statement there is a syntactic characterization of inductive reasonableness in language L is equivalent with the statement for any sentence S belonging to L, S expresses an inductively reasonable claim exactly if S’s derivation-tree has PHI. So sensitization to syntax is sensitization to facts about how sentences are assigned meaning. So far as one’s thinking is driven by facts about how expressions of language L are assigned meaning, one’s thinking is about L, and not in L. So supposing that we think in a language, it would be viciously regressive to say that our thinking were driven by a sensitivity to facts about how its expressions were assigned meaning. Since sensitization to syntax is sensitization to facts about how sentences are assigned meaning, it follows that, so far as we think in a language, our thinking is not driven by the syntaxes of its expressions. The only way to block this would be to say that, where that internal language is concerned, the term “syntax” has a meaning entirely different from the homonym of that term that is used in connection with public languages. But in that case, the statement “thinking, and therefore the making of inductions, is a syntax-driven affair” ceases to have any identifiable meaning. For reasons discussed earlier, it would be no use to counter-respond by saying that our thinking is syntax-driven in that it is morphology-driven, and morphology can be aligned with syntax.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-265",
    "text": "We have seen some reasons to doubt the cogency of Fodor’s arguments on behalf of SCT. But given only that Fodor’s arguments don’t go through, it doesn’t follow that SCT is wrong. But there are some reasons to think that SCT is in fact wrong. The standard argument against SCT is this. Given any expression belonging to a public language, what that expression means is derivative of human thought. Therefore it is viciously regressive to suppose that thought is itself linguistic.[239] Xxx I believe that the argument just given is cogent. (In a moment we will consider some possible objections to it.) But the premise of that argument is liable to be misunderstood. Given only that word-meaning is parasitic on human thought, it doesn’t follow that Grice’s analysis of meaning is the right; it doesn’t follow that, if E has meaning M, that is because people mean M by E. Nor does it follow that human thought directly fixes what expressions mean. (There are very long sentences of English that have definite meanings but that have never been contemplated. So far as human thought fixes the meanings of such sentences, it does so by way of fixing the meanings of their constituents.) Nor, finally, does it follow that human thought single-handedly fixes what expressions mean. (Putnam is right: on Twin-Earth, tokens of “water” refer to XYZ, not H2O. But, as Putnam (1975) argued[240], Bob and Twin-Bob have exactly the same thoughts. ) What follows is that what people think is part of what fixes what expressions mean. (How it fixes it, and to what extent, is another question.) xxx This is obviously a reasonable point and, if it is right, then it is viciously regressive to suppose that we think in a language. The SCT counter-response is to say that the meanings of Mentalese symbols are not fixed by thought. But in that case it becomes questionable whether the so-called symbols of Mentalese deserve to be referred to as such, given how different they are from things that we know to be symbols. At this point, communication between advocates and opponents of SCT tends to stop. But my feeling is that, were it to continue, the debate might well take the following direction. Advocates of SCT would respond to the criticism stated a moment ago by saying that they are indeed extending the concept of a symbol, but that scientific...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-266",
    "text": "There are three important distinctions that relate to the study of language. (When I say “important”, I don’t necessarily mean “valid.” As we will see, one of them is quite spurious. The other two are legitimate.) They all bear a certain resemblance to one another, and are seldom carefully distinguished. But in this context they must be distinguished at all costs. Saussure (1966) distinguished “langue” and “parole.” The former refers to language per se, and the latter refers to the use of a language. David Lewis (1975) distinguished between LANGUAGES and languages*. (He used a different notation to mark this distinction.) LANGUAGES are sets of purely platonic objects: function-theoretic pairings of properties, individuals, and the like, with physical types or tokens. It is evident that such pairings are themselves platonic entities, and thus have no spatiotemporal co-ordinates. Languages*, on the other hand, are constituted by patterns of behavior and thought – by people producing certain noises and ink-marks in response to various stimuli. According to Lewis, the word “language” is ambiguous between LANGUAGES and languages*; and the word “meaning” is comparably ambiguous, sometimes referring to a purely function-theoretic relation (e.g. a function that assigns truth to an utterance of “that cat is mangy” exactly if there is a unique contextually salient cat x, and x is mangy) and other times referring to a psychological phenomenon (as in “what I meant is that you should buy some new clothes”). By way of anticipation, Saussure’s distinction is legitimate, whereas Lewis’ is not. Let us now discuss the third distinction (one we will find to be valid and, indeed, of the highest importance) – that between distinct, but historically connected, languages. If we think of languages as sets of semantic rules, then the referent of the word “English” in 1980 is not identical with the referent of the homonymous word in 2006, thanks to (for example) the introduction of various new terms relating to the internet. At the same time, there is obviously a legitimate disambiguation of “the English language” on which that expression has not changed its referent in the last twenty-six years. Let us say that “the English language” refers to the same “languageH” (the sub-script stands for “historical”) as the homonym of that expression twenty-six years ago, but that “the English language” refers to a different “languageSR” from its homonym twenty-six years ago (the sub-script stands for “semantic rule”).",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-267",
    "text": "This is false. The term “linguistic meaning”, I will argue, never refers to function-theoretic pairings, and the term “language” never refers to a set of such pairings. The statement “a language is a set of function-theoretic pairings of individual, properties, and so on, with physical tokens (or types)” is false on every disambiguation of the term “language.” Lewis is right to say that the word “language” is ambiguous. But it is not ambiguous in the way that he thinks. Similarly, Lewis is obviously right to distinguish between semantic and psychological meaning. But he is (so I will now argue) wrong to think that the former is a purely function-theoretic relation. Obviously Saussure is right to distinguish between languages and the use people make of them. But a language is as much a spatiotemporal entity as the use people make of it. Langue and parole are both spatiotemporal entities. Not all spatiotemporal entities are identical with events. Given that an event is a change in spatiotemporal conditions, it follows that not all spatiotemporal entities are events. A langue is a spatiotemporal condition. Parole is a series of events. But both langue and parole are spatiotemporal entities. Here we must head off a source of deep confusion. Lewis is, I believe, entirely right to say that a language is a set of semantic rules. The English language is the set consisting of rules like: “Socrates” refers to Socrates, “Plato” refers to Plato, and so on. The English language is not a series of noises and ink-marks; it is not even a series of ink-marks and noises coupled with the socio-psychological conditions that caused them. When I say “that rabid dog is running towards us”, my utterance is caused by (inter alia) my awareness of existing semantic rules, the same being true of any other utterance of any language. If utterances constituted language, this would not be possible. The psychological state that was the proximal cause of my producing that utterance was itself a causal consequence of the existence of the English language: ceteris paribus, if it weren’t for the existence of the English language, I would not have had that mental state; and the dependence referred to here is causal, not logical or analytic or constitutive. Thus, the mental state that precipitated my saying “that dog is running towards us” is not constitutive of the English language: if that mental were thus...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-268",
    "text": "A set of semantic rules is not a set of platonic entities; it is not a set of function-theoretic assignments of properties, individuals, and so on, to physical tokens. A set of semantic rules is constituted by psychological entities of some kind (understandings that hold among people), and also by the social and environmental underpinnings of those entities. Of course, the proximal cause of any utterance is a psychological entity. (You see a rabid dog running towards you. Because of your semantic knowledge, you respond by saying: “there is a rabid dog running towards me!” The distal cause of your utterance is an external state of affairs – some dog running towards you. But the proximal cause is your perception of that state of affairs.) But such proximal causes are never constitutive of the semantic rules that make up a language. So even though a language is constituted by psychological entities, and also by understandings among people that implicate facts about their shared socio-physical environment, a language is nonetheless not constituted by speech-acts or by the psychological states that proximally cause such acts. Speech-acts, as well as their immediate psychological antecedents, are effects of the existence of semantic rules, and are therefore not constitutive of such rules. Since languages are constituted by such rules, it follows that neither speech acts nor their proximal causes are to any degree constitutive of language. Lewis’ “language*” is not Saussure’s parole, and Lewis’ “LANGUAGE” is not Saussure’s langue. As Lewis defines them, the terms “language*” and “LANGUAGE” don’t refer to anything that is actually referred to by the term “language.” Lewis’ terms refer, respectively, to language-use and to sets of platonic entities. We’ve just discussed why the term “language” never refers to language-use. In the upcoming section, we will see why “language” never refers to sets of platonic entities. Language-change is not to be identified with language-use. This fundamental truth is obscured by the fact that the set of events constitutive of language-change overlaps to a large degree with the set of events constitutive of language-use. The word “language” is indeed ambiguous – but not in the way that Lewis thinks. The expression “the English language” sometimes refers to set of semantic rules that are operative at a given time, and it sometimes refers to a series of such sets. In the sentence “people use language to communicate with one another”, the word “language”...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-269",
    "text": "So far I have asserted without argument that semantic rules are spatiotemporal entities and are therefore not to be understood as mathematical functions from physical tokens to truth-values or properties. It is not hard to supply the needed argument. Given any two objects, there is some set or ordered pair consisting of them. The ordered pair <”Plato”, Richard Nixon> exists no less than the ordered pair < “Plato”, Plato>. There is no semantic rule that assigns Richard Nixon to “Plato.” Obviously, the existence of the just mentioned ordered pair is not enough for that. By parity of reasoning, the semantic rule that assigns Plato to “Plato” cannot be identified with the ordered pair < “Plato”, Plato>. There is a rule or function that assigns truth to the sentence “Plato was wise” exactly if Plato was wise. But there is also a function that assigns truth to the sentence “Plato was wise” exactly if Richard Nixon was wise. There is no English semantic rule to the effect that “Plato was wise” is true exactly if Richard Nixon was wise. So given only that there is a function of the kind just described, it doesn’t follow that there is a semantic rule assigning truth to “Plato was wise” exactly if Richard Nixon was wise. It follows that semantic rule assigning truth to “Plato was wise” exactly if Plato was wise cannot be identified with a function that assigns truth to that sentence (or, more exactly, to tokens thereof) exactly if Plato was wise. For exactly similar reasons, the semantic rule that assigns the proposition, or meaning, Plato was wise to (occurrences of) “Plato was wise” cannot be identified with any ordered pair (with, for example, the ordered pair < “Plato was wise”, Plato was wise> or with any mathematical function that assigns that proposition to instances of that physical type. Obviously the semantic rule that assigns Plato was wise to “Plato was wise” does exist. But, as we have just seen, that semantic rule cannot be identified with a mathematical function or, equivalently, with an ordered pair of some kind.[242] One might counter-respond by saying:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-270",
    "text": "The expression “possible but unused language” is a veritable synonym of “non-existent, but possibly existent, language”, and this counter-response is therefore purely verbal. For the sake of argument, let us suppose that the objector is right; let us suppose there is some language, albeit an unused one, containing a semantic rule R whereby “Plato” refers to Richard Nixon. Right now people couldn’t possibly use R. Right now, if you used “Plato” to refer to Richard Nixon, you would simply be mis-speaking. Of course, we could imagine the English language evolving in such a way that “Plato” became a name for Richard Nixon. But that evolution would involve creating conditions that allowed people to refer to Richard Nixon as “Plato.” It wouldn’t consist in people simply using R. If it exists, R is not available for the using. And if it ever becomes available for the using, that is not by virtue of the mere existence of the ordered pair < “Plato”, Richard Nixon>, but because the system of communication used by speakers of English will have undergone some kind of structural change. But in that case, it is the resulting structural condition, not the ordered pair, that makes it possible to refer to Richard Nixon as “Plato.” At no point does anyone manage to refer to Nixon by using that ordered pair. What we just said about that ordered pair is true of any abstract structure – it is true of an abstract function that assigns truth to ┌Plato has phi┐ exactly if Richard Nixon has phi. The idea that semantic rules are purely function-theoretic entities is thus a non-starter. The Gricean approach",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-271",
    "text": "Given only that the function-theoretic analysis of meaning is wrong, 666 it doesn’t follow that the concept of expression-meaning is to be understood in terms of that of speaker’s meaning. It is the other way around: the concept of speaker’s meaning must be understood in terms of that of expression-meaning. As Searle showed (1969), one can affirm that Plato was wise with the sounds “Plato was wise” only if the latter already means the former. In general, one can affirm P by means of S only if S already means P. Of course, to affirm P, one doesn’t have to use an expression that has P for its literal meaning. I may convey the proposition your wife is having an affair with the sentence “sometimes things aren’t as they seem.” But that is because, the circumstances being what they are, there is an existing symbolic relationship – albeit not one 666 of literal meaning -- between that sentence and that proposition. A consequence is that one can try to affirm only that Plato was wise with the sound “Plato was wise” only if one believes that the latter means the former. In other words, one can mean the proposition Plato was wise with utterance of “Plato was wise” only if one believes that the latter already means the former. In general, one can mean P with S only if one believes that S already means P. It doesn’t follow that, in order to mean P with an utterance of S, one must believe that S literally means P. (Here we need only echo what we said a moment ago.) I can 666 mean the proposition your wife is having an affair with the sound “sometimes things aren’t as they seem.” But that is because I believe that, the circumstances being what they are, there is an existing symbolic relationship – albeit not of literal meaning -- between that sentence and that proposition. So one cannot affirm P with S unless S already means P; and one cannot even try to affirm P with S unless one believes that S already means P. Thus, in direct opposition to what Grice held, the concept of speaker’s meaning is thus to be understood in terms of that of expression-meaning.[243] Griceans respond to this by saying that expression-meaning is “conventionalized” or “fossilized” speaker’s meaning. According to this view, Grice’s analysis shows how it is...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-272",
    "text": "There is one problem with LOT that we haven’t yet discussed. In my view, it is the most significant of the many problems with that doctrine. (In this context, the term “sentence” will cover both sentence-types and sentence-tokens.) Consider the sentence: “the cat is on the mat.” The meaning of that sentence is what is referred to as a “proposition.” Presumably, propositions have structures at least approximately like those of the sentences that express them.[245] In fact, this last statement appears to be a tautology. A sentence must belong to this or that particular language – it must be a sentence of Chinese or English or French. Where there isn’t a systematic way of assigning propositions to sentences, there is no language. Where there is such a system, there is ipso facto a function that establishes an isomorphism between sentences and proposition. And where there is such a function, there is ipso facto a resemblance between sentences and propositions. In any case, it seems overwhelmingly likely that the proposition expressed by “Caesar killed Brutus” has a constituent corresponding to Caesar, to the relation of killing, and to Brutus. [246] (As we will see later, there is more to that proposition than that – otherwise it wouldn’t be different from the proposition Caesar killed Brutus or from the unordered set (Caesar, the relation of killing, Brutus). But we will deal with these issues later in this chapter.) The fact that sentences decompose into a finite number of discrete parts constitutes a serious problem for LOT. Much information is not digital. Consider your current visual perception. It doesn’t decompose into minimal units of significance. Suppose you actually saw Smith punching Jones. Your perception of that event involved a perception of various segments of the cigar. But Smith was not a minimal or otherwise discrete part of the representational content of that perception; and no concept, or Fregean sense, of Smith was such a constituent. What we just said about Smith is true of Jones and the relation of punching. Indeed, it is true of anything that is the semantic content of any one of the expressions composing a sentence that describe the state of affairs in question. Your perception of Smith involved perceptions of parts of Smith’s body. Indeed, it involved a sequence of such perceptions. Each of these perceptions involved yet other perceptions. Of course, you don’t have an infinitely high-resolution...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-273",
    "text": "But the phenomenology is surely constitutive of the aesthetic reaction, and is not merely an effect of it. This is not to say that every affective response you have to a piece of music is constitutive of a genuinely aesthetic response to it. A piece of music can trigger an emotional reaction that has nothing to do with your estimation of its merits. But it is hard to believe that all music-induced phenomenology is in this category. It seems that a being that had no phenomenological reaction to a piece of music (apart from those that are purely perceptual) would fail to have an aesthetic reaction to it. So it is not an option to say that one’s aesthetic reaction to a performance of the 21st piano concerto has a digital structure, given that the phenomenological aspects of one’s reaction obviously don’t have such a structure. At the same time, it is very unnatural to say that aesthetic reactions are strictly subjective. Aesthetic reactions track objective realities. Within limits, one is right to like certain compositions more than others. Schubert’s music is liked much more now than it was in his life-time (even after we set aside the social conditions that made it hard for him to have music widely performed). Surely this is because Schubert was ahead of his time musically, and not because people just happened to have a change in taste. Given that aesthetic reactions strongly appear not to have a sentential structure, what we must say is not: “aesthetic reactions are completely subjective; no musical compositions are better than others; no one is a better composer than anyone else.” Rather, we what must say is: “awarenesses of objective fact are not always embodied in sentential or para-sentential structures.” In my judgment, the nihilistic views about aesthetics and ethics that were advocated by the positivists were expressions of the view that anything truth-evaluable must be sentence-like. Given how counter-intuitive it is to suppose that no musical compositions are better than others, or that no acts are morally better or worse than others, this alone should make us re-think the idea that mental content is sentential or para-sentential. But what is more important than any of the arguments just given is the obvious fact that our perceptions, and para-perceptual entities such as mental images, very much seem not to have a structure remotely comparable to that of sentences....",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-274",
    "text": "Let us begin with a few points about the history of the problem that we will be discussing. Gareth Evans (1982: 122-129) deserves credit for making the distinction between “conceptual and “non-conceptual” content. By “conceptual”, Evans meant “propositional”; and by “non-conceptual” he meant, “non-propositional.” Given this distinction, the question immediately arises as to whether we are dealing with two fundamentally different kinds of content or only with two different conceptions or representations of what is, ultimately, some one kind of content. Evans held that “non-conceptual” content is not conceptual content in disguise – that it must be understood on its terms, and not in terms of the sentences (or propositions) in terms of which it can, to at least some degree, be embodied. Evans’ argument for this position is as follows. Perceptions are much more “fine-grained” than sentences. What you see is never just red. It is always some hyper-specific shade of red. Since language uses broad rubrics like “red”, it fails to do justice to the structure of perception. McDowell (1994) has a famous counter-argument. We can refer to anything that we see – e.g. any specific shade of red – with a demonstrative expression (“that exact shade of red”). In this way, according to McDowell, Evans’ argument is neutralized. Of course, McDowell is quite right that one can refer to anything that one sees. But it doesn’t follow that the structure of a sentence is at all like the structure of a perception. If anything, the exact opposite follows. Suppose that I use the expression “that exact shade” to refer to some specific shade of red that I am seeing. The expression “that shade of red” obviously doesn’t have a structure comparable to my perception of the red surface in question. The former decomposes into the words “that”, “shade”, and so on. The latter does not so decompose. One can invent new words to refer to specific shades of red (and sounds and fragrances and…) that one experiences. For example, I might stipulate that “R” is to refer to some specific shade of red that I am now seeing. Being a simple expression, “R” has no semantic structure. But surely my perception of the red surface in question is not completely without any articulations. The spuriousness of McDowell’s argument is seen by giving an argument exactly analogous to it. Pointing to some elephant, I say “that elephant weighs...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-275",
    "text": "A token of “this shade of red is darker than that shade” may compare two maximally specific, perceptually present shades. But the rules that assign meaning to such a token involve only general rubrics, e.g. red and distal object. So, from a semantic viewpoint, that token is built out of general categories. But the content of your visual perception of a dark red car next to a light red car seems not to decompose into the concepts dark, light or red. In fact, the content of that perception seems not to decompose into any concept into which the semantics of a sentence-token used to report that content would decompose. So even if a sentence-token attributes a specific property to a specific object, the content of that token decomposes into general categories. Since the same appears not to be true of sense-experience, we have reason to believe that there are fundamental differences between linguistic and perceptual representations. McDowell (1994) has another argument against the viability of the distinction between conceptual and non-conceptual content. People can say what they see, hear, and so on. I see Smith punching Jones. I can report this fact: I can say “Smith punched Jones.” Perceptual content can be verbalized. Therefore the information borne by sentences must either be identical with, or significantly similar to, that borne by perceptions.[248] This argument is really a generalization of the first argument, and it is therefore no surprise to see that it involves the same non-sequitur. Given only that we can articulate what we sense-perceive, it doesn’t follow that sentential content is structurally similar to perceptual content. A curve can be represented as a series sequence of line-segments. But a curve is not a sequence of line-segments. One might counter-respond by saying the following:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-276",
    "text": "But this exposes an even deeper problem with McDowell’s second argument. It very much seems that any sentence is, at best, an approximate representation of the information borne by any sense-perception. Suppose that I see Smith punch Jones, and I then say “I saw Smith punch Jones.” First of all, I cannot just see Smith. I can see Smith only by seeing a state of affairs involving him. Similarly, I cannot see any instance of the relation of punching except by seeing a state of affairs in which such an instance is embedded. Consequently, if I say “I saw Smith punching Jones”, my statement is, at best, an extremely approximate and course-grained representation of the content of my visual perception. Of course, that statement does put some limits as to what the representational content of my perception was. But I am by no means pinpointing that content. (If I were to draw a giant box around a small rock, I would be putting some limits as to the size of that rock, but not very specific ones.) Of course, the approximateness of my verbal representation can be lessened. I can say: “I saw Smith punch Jones; and Smith was wearing a green shirt and he looked sweaty and upset…” By adding more and more verbiage, I can narrow the gap between sentential and perceptual content. But it very much seems that, given any finitely long verbal description of what I saw, some content will always be left out – just as, given any finite number of line-segments, the exact shape of the curve will not be represented. It thus seems that Evans’ fineness of grain argument ultimately prevails. (Later I will try to substantiate our intuition that any finitely long sentence will always leave out some perceptual content.) McDowell might counter-respond by pointing out that I can use a demonstrative-expression to refer to the exact content of my visual perception. I can say, for example, “I will never forget the content of this visual perception.” But this counter-response wouldn’t support McDowell’s position, since the expression “this visual perception” doesn’t have a structure remotely comparable to its referent. As Russell (1956) pointed out, at least one of the expressions composing a sentence must correspond to a universal. So the content of any given sentence is built up out of general rubrics. Since the same appears not to be true of the...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-277",
    "text": "It is not hard to find support for the view that perceptual content is fundamentally different from sentential content.[249] Consider the operations that can be performed on sentences – disjunction, conditionalization, negation, generalization, and so on. These operations cannot be performed on maps or on other graphical representations. You cannot form the disjunction of two maps. Of course, maps A and B can be disjoined if you stipulate that A and B are equivalent to sentences (or series of sentences) S and S*, and that juxtaposing those two maps in a certain way tokens the disjunction of S and S* But in that case, as Rescorla (2003) points out, A and B are no longer functioning as maps. By the same token, A and B would cease to function as sentences if you were to consult the internal structure of A to find out how to drive to Bakersfield.[250] None of the recursive operations that can be performed on sentences can be performed on maps. But this is only a special case of the more general principle that no recursive operation that can be performed on expressions of any kind can be performed on maps. A sequence of maps doesn’t compose a sentence. Of course, one could stipulate that an expression meaning x is larger than y results if a map of x is placed to the right of a map of y. But such a juxtaposition of maps would not itself be a map and, in that context, the two maps in question would be functioning as maps. These points about maps correspond to points about visual perceptions. Like maps, visual perceptions are analogue-representations. Two visual perceptions cannot be conjoined or disjoined or negated. More generally, none of the recursive operations that can be performed on expressions can be performed on visual perceptions. This suggests that the information encoded visual perceptions is fundamentally different from the information encoded in sentences.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-278",
    "text": "It is said that “Smith” denotes an “individual.” Notice that, etymologically, “individual” means undividable. But from a metaphysical and also a representational point of view, so-called individuals, like Smith and Jones, are anything but undividable. (If, like Plato, you believe that souls are indivisible, then assume that “Smith” and “Jones” refer to rocks or plants.) And yet from a linguistic point of view they are undividable: “Smith” and “Jones” are minimal, undividable units of significance. In this section, I want to show that LOT cannot be right, the reason being that language must necessarily represents as fundamental what is extremely derivative from the viewpoint of how we mentally represent the world. Even though, linguistically, “Smith” is a minimal unit of significance, Smith himself is best thought of, not as an “undividable” or even as a thing at all, but rather as a property of sequences of sets of properties of properties. And even though “red” is semantically basic, neither the property of redness nor any instance thereof is in any sense fundamental. Instances of properties, I will argue, are abstract commonalities holding among situations; they are not components of situations. The world isn’t built up out of instances of properties; and our perceptions of the world are not out representations of such instances. (Your perception of the red square doesn’t consist in a perception of an instance being red conjoined with a perception of squareness.) But any sentence necessarily decomposes into units that represent these highly derivative entities (if “entity” is even the right word: see below) as basic. Properties versus hyper-properties",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-279",
    "text": "First of all, the term “red” doesn’t denote anything of which there could possibly be a spatiotemporal instance. No fire-truck or rose or pool of liquid is just red: it is some specific shade of red. (There are no general terms indicating the exact shade of any specific red object. One must use demonstrative expressions to indicate any maximally specific shade of red – any kind of redness that can actually be seen.) What we generally refer to as “properties” are actually properties of properties. Suppose that R1 is the specific shade of red object had by object x1 (some fire-truck), that R2 is the specific shade had by x2 (some rose), and so on. R1 is something of which there could be, and are, instances in the spatiotemporal world; the same is true of R2, R3, and so on. By contrast, the thing denoted by “red” is something that R1…Rn have in common. So “red” denotes a property of properties, not a property simpliciter. There is no denying that R2 is a bona fide case of a property. In virtue of having that specific shade of red, the rose surely has a property. Of course, what we just said about R2 is true of Ri, for any i. At the same, each of R1…Rn is itself an instance of redness. Thus, redness is a property of properties; it is a hyper-property. There is some property that all and only those objects instantiating R1 have in common, the same being true of Ri, for arbitrary i. So far as there is some property that all and only red objects have in common, that is by virtue of there being some property that all and only R1…Rn have in common. x1 (the fire-truck) and x2 (the rose) don’t have quite the same color. Strictly speaking, they have different colors. (Language is approximate in so far as it puts them in the same color-category.) In any case, it is a datum that x1 and x2 differ chromatically. It is a datum that the difference between them is comparable to, though much smaller than, the difference between a blue and a green object. The difference between x1 and x2 is to the chromatic difference between a diamond and an emerald what the difference between 3.1 and 3.2 is to the difference between 2 and 978,965. We are dealing with different degrees of some...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-280",
    "text": "Let r1 be a specific instance of R1. r1 is not a constituent of the situation in which it is found. There will never be an instance of color without an instance of shape or an instance of temporal (or spatial) location. Language separates out what are, in actuality, completely inseparable. The color of the rose cannot be detached from its shape or its location. Situations are not assemblages of property-instances. On the table, there is an object that is square and green. Let S be this situation. S is not composed of an instance of greenness (or of some specific shade thereof), and an instances of squareness, and an instance of being on the table. When we verbally describe the situation, we use different terms to denote these different property-instances. But the composition of the sentence isn’t comparable to the composition of the situation. There couldn’t be an instance of squareness that wasn’t an instance of a certain size and instance of having a certain location. We use sentences to describe situations. But situations are not structured in the same way as sentences. The question then arises as to how sentences can be even approximately accurate representations of situations. Ian Hacking (1975) refers to this as the “articulation problem.” What we just said about situations is true mutatis mutandis of our perceptions of them. Seeing that there is a box of a specific color and shape on a specific table does not consist in producing a mental representation of multiple property-instances and then assembling them. Your seeing the box on the table does not, and could not, consist in your having a mental representation of some specific shade of green, and also of some specific shape, and then somehow putting these representations together. Of course, you don’t have to see the box as green. You might see it as red. But what we just said (mutatis mutandis) would apply to this situation: your seeing the box wouldn’t consist in your combining a mental representation of an instance of squareness with a representation of an instance of redness. Perceptions are not assemblages of representations of property-instances. The consequences of these points for SCT",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-281",
    "text": "Since instances of properties are not detachable parts of situations, they are better thought of as ways as “dimensions of similarity.” For two situations to instantiate some property is for them to be similar in some respect. Their being similar doesn’t follow from their instantiating that property. Rather, I will argue, their being similar along some dimension is their both instantiating that property. Obviously expressions like “instance of squareness” and “instance of R1” (where R1 is a maximally specific shade of red) meaningful. But given any instance of any property – given anything that can be described as an “instance of R1” – that instance cannot be distinguished, except in a purely notional sense, from various instances of what are obviously different properties. Given some specific instance of R1, that instance cannot be distinguished, except via a process of abstraction, from a certain shape and from a certain location. So to the extent that it denotes an isolable entity, a token of “that instance of R1”, or of “that instance of red”, denotes a kind of abstraction, and does not denote a constituent of the spatiotemporal world. (What is such a constituent is the situation in which that instance is embedded.) According to Russell (1905, 1918), a significant noun phrase that denotes a “purely notional” entity is one that doesn’t denote anything, and that must be understood contextually. “The average person” is obviously a significant expression. We could say that it denotes a purely “notional entity” or an “idealization.” But this would just be a dodge. When you say that “the average person needs more than four hours of sleep a night”, you are not saying that an idealization needs more than four hours of sleep a night: abstract objects don’t sleep. There is no x such that you are saying of x that x specifically needs only four hours of sleep. Evidently, “the average person” isn’t significant by virtue of picking some object out. It is significant by virtue of the fact that there is a rule assigning meaning to sentences of the form ┌…the average person…┐[252] If, as we’ve argued, expressions like “instance of red” and “instance of R1” denote (so to speak) purely notional entities, then they don’t denote anything and must be understood contextually. Another example may be appropriate. The expression “the temperature of this object” is obviously significant, and that is why it can be...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-282",
    "text": "Semantically, “Smith” (the expression, not the person) is a simple entity, the same being true of any proper noun. But from the viewpoint of metaphysics and also of perceptual representation, Smith is not a simple entity. In fact, it isn’t even clear if, from those viewpoints, he is an entity at all.[254] (Once again, if you believe that people are indivisible, or otherwise metaphysically special, then suppose that “Smith” refers to a rock or a carrot.) During any given interval of time, Smith’s existence supervenes on the occurrence of innumerable events – psychological, metabolic, cellular, molecular, atomic, and ultimately sub-atomic. At any given instant, i.e. during any arbitrarily small period, Smith’s existence can thus be though of as a set of states of affairs. (Here the word “set” is being used in a loose sense.) Thus Smith’s existence as a whole, i.e. from this birth to his death, is realized by a sequence of sets of states of affairs. So Smith is anything but a simple entity. Given any event E involving Smith, E’s occurrence supervenes on those of innumerable lower-level states of affairs. More precisely, E occurs in virtue of the fact some causal sequence, consisting of a series of sets of states of affairs, acquired some property that it didn’t previously have. So if it is true, “Smith suddenly realized that 7+5=12” holds in virtue of the fact that some pattern of mass-energy displacements took a new turn. In terms of metaphysics (though not of semantics), the occurrence of “Smith” in that sentence parses out. Smith is only notionally separable from the various processes that constitute him. For the reasons given a moment ago, it follows that occurrences of “Smith” ultimately parse out – like occurrences of “the rod’s having a temperature of 78°” is true of “Smith” and “the average man.” We saw earlier why Smith must be represented in terms of a description, even though (if direct-reference theorists are right) “Smith” is semantically simple. So, in thought, Smith is not represented as simple. This point of ours, as well as our arguments for it, may not meet with universal acceptance. But what cannot reasonably be debated is that, in perception, Smith is represented only in so far as some situation in which he is embedded is represented. Thus, considered as an isolable entity, Smith is a non-entity from the viewpoint of sense-perception. Revisiting the distinction between...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-283",
    "text": "This line of thought relates to a point that we defended in Chapters 4. When someone says that he saw Smith, he is making a judgment about what was given to him in a visual perception; he is not giving a mere report as to what was given to him.[255] What was actually given to the percipient in sense-perception is, at most, some piece of existential information that Smith satisfies. Let us discuss the nature of the judgment just referred to. (Doing this will involve a brief repetition of points made in Chapter 1.) Smith has an identical twin, Twin-Smith. Twin-Smith is now in Finland. You are now in Delaware, and so is Smith. You know all of this. You see Smith. As we discussed, given only the information encoded in your visual perception, you could just as well be seeing Twin-Smith. When you say (correctly) “I saw Smith, not his twin”, you are not merely reporting what you saw; you are making a judgment about what you saw, and that judgment incorporates your knowledge that Twin-Smith is in Finland. What is given to you in sense-perception is not Smith is wearing a green shirt but is (so far as it can verbalized) more along the lines of: something x, standing in a certain place, and having such and such features, is wearing a green shirt. When you judge that you saw Smith, you are judging that Smith is the one who satisfies that description, i.e. that he is the right value of “x.” But what is it for Smith to satisfy this description? Smith’s satisfying that description consists in its being the case that the state of affairs that is given to you in your perception has a certain continuity with other states of affairs; and Twin-Smith’s not satisfying that description consists in its not being the case that the state of affairs that is given to you in your perception has that same kind of continuity with those states of affairs. Smith is not hidden behind a veil consisting of some state of affairs. Given only that you must judge that you are seeing Smith, and that this fact cannot be encoded in strictly perceptual information, it doesn’t follow that your senses are imperfect or that sense-perception is a flawed medium. What follows is a fundamental metaphysical fact about Smith. Smith’s being the person in the green shirt...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-284",
    "text": "Earlier we briefly discussed some reasons why any language must contain expressions denoting broad rubrics, as opposed to perceptible entities. Here we will develop those points. Suppose that there is some proper noun N whose semantic content is some specific situation. Two people who have not both personally witnessed that situation cannot use that noun to communicate with each other – unless, of course, they have some way of indicating what is meant by that noun that does not presuppose both their having witnessed that situation. That second method of communication must itself involve some symbol (or set of symbols) S. What we just said about N would be true of S: if S’s semantics cannot be understood in terms of situations that both people have personally experienced, then its usefulness as a means of communication between those two people involves some third symbol (or set of symbols) S*. Sooner or later, we must arrive a system of communication that does not presuppose experiences of numerically identical situations. We therefore need a system of communication whose building blocks refer to what is common to different situations: a system whose basic units refer, not to concrete entities, but to abstract commonalities among concrete states of affairs. Given a system of communication of the kind just described, there is no difficulty creating ways of referring to specific situations, even to specific psychological events – events that cannot possibly be experienced by distinct individuals. But reference to such situations will be achieved through symbols that indicate commonalities among distinct situations. I can refer to a specific experience by saying “the pain I am feeling right now, in this part of my foot”; and this expression is meaningful and intelligible to others. But the expression through which I refer to this experience is constructed out of expressions that don’t refer to anything specific and that have for their meanings abstract commonalities holding among different states of affairs. The more a system of communication depends on its users having shared experiences, the less able that system is to say what is not already known. The more abstract the significations of the expressions composing a system of symbolism, the less a system of communication depends on its users having shared experiences. This means that ceteris paribus the more powerful a system of communication is, i.e. the more able it is to impart what isn’t already known,...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-285",
    "text": "In this section I will argue that what we refer to as “individuals” – people, rocks, trees, vases – are better thought of as properties of worlds. This will confirm the points already made about the viability of LOT. It will also provide a basis for the positive answer that we will give (in the next chapter) to the question “what are propositions and how, if it all, are they different from the information encoded in our perceptions?” Suppose that S1…Sn are the various mass-energy displacements occurring in the space-time region occupied by Smith. In that case, any possible world that comprises S1…Sn comprises Smith. So Smith’s existence is realized by or supervenes on the occurrence of S1…Sn. At the same time, we don’t want to say that Smith is identical with any such sequence; for presumably Smith could have had experiences and done things other than those which he in fact had and did. Nonetheless, Smith is not modally infinitely elastic. There are surely some limits as to how he might have differed. To be sure, he didn’t have to become a lawyer; he could have become an actor instead. But Smith couldn’t have been a rock or a carrot. Less trivially, if Kripke’s (1972: 110-115) plausible views on the essentiality of origins are correct, Smith couldn’t have had parents different from those that he actually had. More generally, in any possible world where he exists, Smith’s beginnings must be much the same as they are here. So supposing that s1…sm are the events that, in actuality, initiated Smith’s existence, any possible world where Smith exists is one that comprises either s1…sm or events that are (in some respect) significantly like them. Smith exists in a world W exactly if certain events or states of affairs hold in W – exactly if, to use Kenneth Taylor’s (1998) suggestive expression, W’s “quantum” is “rippled” in a certain way. There is a different way to put this. (Here I am going to use a metaphor that I will soon re-use in my effort to give a precise answer to the question “what are propositions and how, if it all, are they different from the information encoded in our perceptions?”) Suppose that God wanted to make Smith exist in some world W. He would have to wrench W’s quantum in the right way; He would have to make sure that certain mass-energy...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-286",
    "text": "As we noted, Evans held that there is “non-conceptual” content. Others have disagreed. We’ve seen some reasons to think that Evans is right. But to arrive at a definite resolution of this dispute, we must make it maximally explicit what is, or could be, meant by the term “non-conceptual content.” It is a truism that sentences have meaning. (In this Chapter, “sentence” is to be taken to mean “sentence-token”, wherever appropriate.) Further, it is a truism – a matter of terminology – that these meanings are propositions. The question “is there non-conceptual content?” seems to amount to this: “Are there representational entities whose content is not a proposition (or set of propositions) and, further, whose content is, in some fundamental way, not even proposition-like?” We’ve already seen that the answer to this question is: “yes.” But, in the present author’s view, no unexceptionable answer to the question “what are propositions?” has ever been produced. And so long as that question remains unanswered, the opponent of non-conceptual content can take refuge in the obscurity of the notion of propositionality. I believe that, given some of the points made in the last chapter, we can develop a creditable analysis of what propositions are, and can further undermine the credibility of the view that there is no non-conceptual content.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-287",
    "text": "Let us briefly discuss some of the existing answers to the question “what are propositions?” First, there is Russell’s answer. The proposition meant by “Smith punched Jones” is some kind of a structure that consists of Smith, the relation of punching, and Jones. (Let us set aside the problems relating to the tense-marker.) The problem with this answer is that, while it may be right, it is excessively vague. We want to know what exactly the just-discussed structure is. The most obvious answer to this last question is: “that proposition is the set (Smith, the relation of punching, Jones).” I do not think that, historically, anyone has given this exact answer. But it is worth considering because the problems with the answers that have been given can be understood, up to a point, in terms of the problems with this answer. First of all, if the proposition meant by “Smith punched Jones” is the set (Smith, the relation of punching, Jones), then the proposition meant by “Jones punched Smith” must also be that set. In that case, those propositions would be identical. They are not; so the proposition meant by “Smith punched Jones” is not that set. In general, the problem with the answer being discussed is that it cannot distinguish between distinct propositions that have the same constituents. Many (probably most) contemporary authors do hold that the proposition meant by “Smith punched Jones” is a set. They deal with the problem just discussed by saying that it is a structured set (R. Moore 1995: 101, Cresswell 1985: 446-452, King 1995, 1996, 1997, Perry 2000: 213). So Smith punched Jones is the ordered pair <<Smith, Jones> the relation of punching>, whereas Jones punched Smith is the ordered pair << Jones, Smith> the relation of punching>. In general, propositions are structured sets; and distinct propositions that have the same constituencies are different structurings of those constituencies. There are two problems with this position. The proposition Smith punched Jones is true or false. But the set <<Smith, Jones> the relation of punching> is neither true nor false.[258] This problem is not necessarily insuperable: if we identify some relation R such that <<Smith, Jones> the relation of punching> has R with respect to all and only those worlds where Smith punched Jones is true, then we can identify <<Smith, Jones> the relation of punching> with that proposition, and we can identify its being...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-288",
    "text": "Frege’s (1891, 1892) view regarding the proposition Smith punched Jones is that it is a structure of some kind or other. (He said very little as to what exactly that structure would be.) But Frege denied that it is Smith and Jones per se that are constituents of that structure, and he held that it is senses of Smith and Jones that are such constituents. In Chapter 3, we saw why, if the semantic content of “Smith” is a sense, then the proposition meant by “Smith punches Jones” becomes an existence-claim, as opposed to the atomic proposition that it obviously is. This is not to mention that, given Kripke’s (1972) points, it isn’t really an option to say that the semantic content of “Smith” is a sense. From this viewpoint, Frege’s view is a step backwards from the view that Smith punches Jones is an ordered n-tuple of the kind just discussed. Frege made a point that could be interpreted as being attempt at a partial answer to the question “what is the proposition Smith punched Jones?” Frege said (correctly, no doubt) that this proposition has as a constituent the “concept” x punched y. The proposition Smith punched Jones is what results when the variables (or empty-spaces) are “saturated” with Smith and Jones (or with the corresponding senses). There are at least two problems here. First, as Davidson (1967) said, until we are told what “saturated” means, Frege has given us only a metaphor. Obviously the word “saturate” is being used metaphorically. Frege has told us that a proposition is what results when that concept is completed in some way or other by (senses of) Smith and Jones. But he hasn’t told us what the nature of that completion is. And until we know that, we don’t know anything that we didn’t already know. There is another problem. What is the concept x punched y? Sometimes Frege answers this by saying that it is what is had in common by all and only Smith punched Jones, Mary punched Fred, Larry punched Harry, and so on. So concepts are abstract features of propositions; they are what different propositions have in common. But, in that in case, propositions cannot be composed of concepts. There is, of course, an obviously parallelism between this point and the point we made earlier concerning the constituencies (or lack thereof) of concrete situations. So if we see...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-289",
    "text": "According to Carnap (1937) and Clarence Lewis (1946) , a proposition is the class of its logical consequences. This thesis is often expressed in terms of sentences: “the content of a sentence is the class of its analytic [or logical] consequences.” [260] There are some serious problems with this view. Xxx First of all, the statement “propositions are classes that contain their logical consequences” is viciously circular, given that those consequences are themselves propositions. One way to block this vicious circularity would be to say that the consequences of a proposition are not propositions. Whatever merits this position has, it is obviously not an option for someone who denies that there is any fundamental difference between propositional and non-propositional content. There is another problem with the view under examination. Presumably the proposition Smith punched Jones has one constituent corresponding to Smith, one corresponding to Jones, and one corresponding to the relation of punching. (This is not to deny that it has other constituents. But it presumably has at least those three.) A related point is that the sentence “Smith punched Jones” surely has a decomposition not wholly unlike that of the corresponding proposition. But it hard to see how the class of logical consequences of Smith punched Jones could have a structure at all like that of that sentence or that proposition. This fact is important from the standpoint of somebody who wants his theories to explain, or at least be consistent with, the fact that languages can be learned and that propositions can be grasped. As Fodor (1975, 1998) makes clear, anyone who understands “Smith punched Jones” can also understand “Jones punched Smith.”[261] Anyone who can understand “Mary is tall”, and “Fred is short” can also understand “Fred is tall” and “Mary is short.” These facts are hard to explain unless it is assumed that the things meant by “Fred is tall” and “Fred is short” have a constituent in common corresponding to the word “Fred” – unless, to generalize this point, it is assumed that the things meant by sentences at least typically have discrete constituents corresponding to the expressions composing those sentences. The class of logical consequences of “Fred is tall” (or of Fred is tall) does not have any discrete part corresponding to “Fred.” In any case, it would take considerable artifice to find any such part. Why these points are consistent with our analysis of...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-290",
    "text": "The points just made might seem in tension with the analysis given in the last chapter. Such expressions, we argued, are to be understood contextually; they are not to be understood by pairing them off with the right entities, since such entities are not to be found. But in the last paragraph we argued that the thing meant by “Fred is tall” must have a constituent corresponding to Fred (and to tallness). Given an analysis due to Richard Montague (1974), this tension is easily eliminated. If Montague is right (as I believe he is), Russell conflated two different notions. He conflated the idea of having a referent with that of having an isolable meaning. Consider the sentence “something snores.” For the reasons that Russell and Frege gave us, “something” doesn’t refer to some ambiguous object. On this basis, Russell said that it has “no meaning in isolation” and must therefore be defined contextually. But given only that an expression must be defined contextually, it doesn’t follow that it has “no meaning in isolation.”[262] We can see the expression “something” as having for its semantic content a function that assigns truth to a property (or concept) phi exactly if phi is instantiated. We don’t want to say that “something” refers to such a function, given that “something snores” doesn’t say of some function that it snores. But not all forms of signification are identical with reference. Actually, it was Frege who gave a cogent argument for this last point. Consider an arbitrary sentence – e.g. “Smith punched Jones.” One might be tempted to say that “punched” refers to the relation of punching. But if we replace the occurrence of “punched” with an expression that uncontroversially does refer to that relation, e.g. “the relation of punching”, the result is “Smith, the relation of punching, Jones.” Since that string of words is not a sentence, it follows that the occurrence of “punched” does not – at least not merely – refer to the relation of punching. So unless one takes the demonstrably false view that meaning is categorically identical with reference, there is no barrier to saying that “something” has for its meaning a discrete entity, notwithstanding that “something” cannot be defined denotatively and must therefore be defined contextually. In general, given only that some expression “parses out”, it doesn’t follow that it doesn’t have a discrete signification. In fact, given any expression...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-291",
    "text": "We’ve already discussed two difficulties for the view that the proposition Smith punched Jones is identical with the class of its logical consequences. There is another well known problem. Smith punched Jones has the same logical consequences as Smith punched Jones and 1+1=2, even though those are distinct propositions. Given this fact, it is not an option to say that Smith punched Jones is identical with the class of its logical consequences. If we were to hold onto the view that propositions are identical with classes containing their logical consequences, we would have to say that Smith punched Jones was identical with some ordering of those consequences and that Smith punched Jones and 1+1=2 was identical with a different ordering of those same consequences. In general, we would have to say that propositions were orderings of their own logical consequences, and that analytically equivalent propositions were different orderings of the same propositions. Otherwise, equivalent propositions would be no more distinguishable than the unordered sets (2,4,6) and (4,6,2). But here there arises an analogue of a problem already discussed. It isn’t clear what the right structuring would be; and the view just discussed is entirely programmatic until that structuring is identified. So the view in question is, from that viewpoint, comparable to the view that Smith punched Jones is <<Smith, Jones>, punched>. The former view, like the latter, is correct only given some as of yet unknown fact about the structures of propositions. But knowledge of the identity of that structure is precisely what we want from an analysis of propositions.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-292",
    "text": "This view combines elements of all of the views thus far discussed. It is the view that a proposition is a function from worlds to truth-values. So Smith punched Jones is a function that assigns truth to worlds where Smith punched Jones and falsity to worlds where Smith didn’t punched Jones (but where Smith and Jones exist), and either falsity or no truth-value to worlds where either Smith or Jones doesn’t exist. This view is the core of a doctrine called “possible world semantics” (PWS)[263] Any adequate assessment of the merits and demerits of PWS would be quite an involved task.[264] Fortunately, given our purposes, only a few brief remarks are necessary. If by a “world” is meant a set of propositions, then it is viciously circular (and regressive) to say that propositions are functions from worlds to truth-values. If we say that worlds are non-propositional representations, then we are conceding that there is non-propositional content – this being exactly the point that we are trying to establish in this chapter. If we say that worlds are concrete entities, like our world, then PWS involves the dubious view that, for each possible proposition, there is an actual world where it is true. PWS also has the problem that it cannot distinguish between 1+1=2 and triangles have three sides, given that those propositions are true in the same possible worlds. Advocates of PWS deal with this by saying propositions are structured assignments of truth-values to worlds (Lewis 1975, Cresswell 1985: 446-452). So even though 1+1=2 and triangles have three sides assign the same truth-values to the same worlds, they do so in different ways. In one case, the concept of addition is involved in the assignment; in the other case it is not. In one case, the concept of triangularity is involved in that assignment; in the other case it is not. Supposing that this is right, propositions end up being individuated by their internal structures. Even though Smith punched Jones and 1+1=2 assigns the same truth-values to the same worlds as Smith punched Jones and triangles have three sides, they have different internal structures; and for this reason they are different propositions. Given this, proposition-individuation can, and must, be understood entirely in terms of a proposition’s internal structure. We have no idea what Little Timmy’s belief is if we know only that his belief is true in every world. That...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-293",
    "text": "(i) 1+1=2 (ii) there are continuous functions that cannot be differentiated at any point. (iii) There are infinitely many primes. (iv) Arithmetic is incomplete. (v) Triangles have three sides.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-294",
    "text": "If we want to know what Timmy believes, we need to know the identities of constituents of the proposition believed in, and we need to know how those constituents are arranged in that proposition. But given that information, there is no need to know in what worlds that belief is true, since we already have all the information we need to answer the question “what is the identity of the proposition that Timmy believes to be true?” Of course, given an answer to that question, we know in which worlds that proposition is true and false (i.e. to which worlds it assigns truth and falsity). In other words, we know what is sometimes referred to as the “extension” of that proposition. But, as we’ve just seen, a proposition’s extension is, by itself, useless in the way of indicating that proposition’s identity, since infinitely many distinct propositions will have the very same extension. So if it is to avoid falsely identifying 1+1=2 and triangles have three sides, PWS must see propositions as being individuated by their structures. But in that case, the extensions of those propositions drop out; and PWS ends up being a version of the theory, already considered, that a proposition is a structure of some kind. PWS thus ends up collapsing into (a close relative of) the view that Smith punched Jones is the ordered pair <<Smith, Jones>, punched>. There is yet another problem. Suppose that there is only one concrete world. In that case, snow is green and coal is purple assign the same truth-values to the same worlds, since they both assign falsity to this world and this world is the only one. So if those propositions are to be given different extensions, we must 666 embrace the dubious view that there are, indeed, different concrete worlds. (We’ve already discussed why it is not an option, at least not in this context, to identify worlds either sets of propositions or with non-propositional representations.)[265]",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-295",
    "text": "According to David Lewis (1986), a proposition is a “property of a world.” Let P be the proposition Smith punched Jones. That proposition is true in some possible worlds and false in others. For that proposition to be true in a world W is for W to have certain properties; it is, to use Taylor’s expression, for W’s quantum to be rippled in a certain way. Here is another way of thinking about it. Suppose that God is given a blank world W and that he wants P be true in it. What will he do? He must do more or less the same thing as an artist who wants to paint a portrait on what is now a blank canvass. An artist cannot just project an image of Lincoln onto a canvass. He must do so one drop of paint at a time. And even if an artist could instantaneously project Lincoln onto a canvass, that would consist, not in his not having to put the requisite thousands of paint drops on the canvass, but in his being able to put them all there simultaneously. Similarly, even God cannot just make P be true in W. He must do so by wrenching W’s quantum into shape – by guaranteeing the occurrence of the right micro-events. Even He cannot make P be true in a world W whose micro-constituents are qualitatively identical with those of a world W* where P is not true. Even God must comply with metaphysical necessities. As Wittgenstein (1922) said, even God cannot create a world where one and one don’t make two. In wrenching W’s quantum into shape, what is God doing? He is making a dent in it – he is doing to it what the artist does to a canvass or, to use a more apt analogy, what a metal-worker does to a sheet of aluminum. He is making it instantiate the right property. So for P to be true in W is for W to instantiate a certain property. (The property in question is not, it will be noticed, the trivial one of being a thing x such that P is true in x. The property in question can, and ultimately must, be understood independently of P and, indeed, of any one of its constituents.) So P is a property of worlds, and P is true in a world if that world...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-296",
    "text": "There is much truth in this analysis, and it is dramatically better than the others we considered. The analysis that I will propose draws heavily from it. But there are two reasons why Lewis’ analysis is unacceptable as it stands. If I say to you “Smith punched Jones and 1+1=2”, I am not telling you anything about how this world differs from others that I am not telling you by saying either “Smith punched Jones” or “Smith punched Jones and triangles have three sides.” (At the same time, in uttering any given one of those sentences, I am giving you information – though not spatiotemporal information – that I would not be giving you in uttering either of the others.) So if Smith punched Jones is a property of worlds, i.e. if it is a way that certain worlds are, that property is not different from Smith punched Jones and triangles have three sides or Smith punched Jones and 1+1=2. Incidentally, Lewis (1986) is aware of this, and he bites the bullet. He takes the logical positivist view that the three propositions just mentioned are actually identical. But it is probably best to assume with most philosophers that such a view is not correct, and to proceed accordingly. Some abbreviations will help us state another problem with Lewis’ analysis. Let P1 be the proposition Smith punched Jones; let P2 be the proposition Smith punched Jones and 1+1=2; and let P3 be the proposition Smith punched Jones and triangles have three sides. No two of P1, P2, and P3 have the same decomposition. But, as we just saw, given any one of those propositions, there is no property that a world W has in virtue of that proposition’s being true in W that W doesn’t have in virtue of in virtue of either of the other proposition’s being true in that world. So if they are properties of worlds, any two of P1, P2 and P3 are identical and thus have identical decompositions. So Lewis’ analysis cannot accommodate the fact that distinct propositions can be analytically equivalent. Nor can it accommodate the related fact that any proposition has a unique decomposition into a finite number of discrete parts. Our analysis: propositions as sets of properties, truth as instantiatedness",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-297",
    "text": "We’ve considered a number of answers to the question “what is a proposition?” and found them to be inadequate, at least for our purposes. I would like to propose a different answer. The core of our view is present in Lewis’ analysis: propositions are properties, and they are true when instantiated. Truth is instantiatedness. Actually, we will see that propositions are sets of properties, not properties per se, and that for a proposition to be true is for a set of properties to be instantiated. But there is obviously a deep kinship between our proposal and Lewis’. There is a plant next to my desk. Let D be that plant. D is green. Hence the proposition:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-298",
    "text": "is true. What is involved in (*)’s being true? It is true in virtue of the fact that various properties are instantiated. The property of being a certain kind of object (a plant) is instantiated in a certain place and time, and the property of being green is instantiated by that object.[266] If various properties are instantiated in a certain place, at a certain time, then (*) is true. If those properties are not instantiated in that place, at that time, then (*) is false. This suggests that (*) is a set of properties, and that for (*) to be true is for the members of that set to be instantiated. The problem is to identify a set that has the right ordinal or structural properties. More exactly, the problem is to identify a set that satisfies two requirements. First, (*) is true exactly if all the members of that set are instantiated. Second, facts about the membership of that set can be put into an intuitively satisfying correspondence with facts about the decomposition of sentences like “D is green” (and “that plant over there is green”) and therefore with facts about the decomposition of (*). This problem can be solved Let us begin with a point that we discussed a moment ago, when we were evaluating Lewis’ analysis. There is some property – we will refer to that property simply as “#1” -- that a world has in virtue of the fact that (*) is true in it. That very property (#1) is had by a world in virtue of that fact, in it, any one of the following is true in that world:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-299",
    "text": "and so on. #1 cannot be identical with (*). This is an immediate consequence of the considerations that put forth in defense of our rejection of Lewis’ analysis. At the same time, (*) is true in W iff #1 is instantiated. Given this, I propose that DP is identical with a set S one of whose members is #1, and I propose that each of (i)-(iii) is a set that has #1 as a member. I further propose that for any given one these propositions to be true is for the members of the corresponding set to be instantiated. But, to account for the decompositional differences holding between any two of the four propositions in question, I will also propose no two of these sets have exactly the same members (even though they share #1 along with, as we will see, some other properties). For a moment, let us speak as semanticists, and not as metaphysicians. As semanticists, our inclination is to say that “D is green” decomposes into (inter alia) “D” and “green.” In any case, our inclination is to say that “D” and “green” are well-formed parts of “D is green” and, consequently, that these expressions correspond to isolable constituents of (*), i.e. of what is meant by “D is green.” And, as semanticists, our inclination is to say that each of these morphemes corresponds to some discrete and ultimate constituent of what is meant by (*). We’ve already discussed why the things that we refer to as “individuals” – vases, plants, people, animals, and so on – can be thought of as properties. That is how we will think of them in this chapter. Given this, let #2 be the property corresponding to “D”, and let #3 be the property corresponding to “green.” Finally, let S be a set that contains all and only #1, #2, and #3. Given that S comprises #1, it immediately follows that (*) is true if the members of S are instantiated. In fact, the converse follows as well. If #1 is instantiated, then so are #2 and #3. So (*) is true exactly if all of #1, #2, and #3 are instantiated. Notice that S has one part corresponding to “D”, another part corresponding to “green”, and a third part corresponding to a certain way of “combining” those two parts. A world instantiates #1 iff it instantiates #2 and #3 and...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-300",
    "text": "(a) D exists; (b) there is an instance of the property of being green; and (c) D instantiates that property. We may naturally identify (*) with S, and (*)’s being true in a given world with the members’ of S being instantiated in that world.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-301",
    "text": "Obviously (**)’s existence presupposes, and thus depends on, that of Smith and Jones (and also the relation of hitting). Further, if (**) is true, then so are the propositions something hit Jones, and Smith hit something, and also something hit something. The truth of (**) thus depends in a certain way on facts about Jones, Smith, and the relation of hitting. There is more to say in this vein. (Here we must keep it firmly in mind that Smith and Jones, land so-called individuals generally, can be thought of as properties.) (**)’s existence presupposes, not just that of Smith, Jones, and the relation of hitting, but also of a certain “synthesis” (whose nature has yet to be described) of these three things. And (**)’s being true in W involves more than there being instances in W of Smith, Jones, hitting, Smith’s hitting somebody, and somebody’s hitting Jones. Those instances be combined in W. After all, if Smith hit Brown, and Aaron hit Jones, then all of the properties mentioned will be instantiated in W, but (**) won’t necessarily be true there. In any case, there is considerable evidence for our view that the concept of propositional constituency is to be understood in terms of the concept of dependence. X is a constituent of proposition Y iff Y depends on X in a certain way. Of course, this is extremely vague, given that there many ways that one thing can depend on another. But it is just a jumping-off point for our analysis of propositional structure; and that analysis will replace this vague statement with a precise one. Before we continue, we should deal with an apparent problem with our analysis. The proposition:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-302",
    "text": "can be true without Smith’s hitting anyone or Jones’ being hit by anyone or, in fact, anyone’s hitting anyone. But notice that this is a molecular proposition, and that, as such, it affirms a relationship not between Smith and Jones, but between propositions. Notice that those two propositions – and not Smith, Jones, or the relation of hitting -- are the immediate constituents of (***). Notice also that, just as the truth of Smith hit Jones depends on facts about its immediate constituents, so the truth of (***) depends on facts its immediate constituents. So given only that (***) doesn’t imply any particular fact about Smith or Jones or the relation of hitting, there is no reason to reject our view that constituency-relations are to be understood in terms relations of dependence. In any case, we will deal with molecular propositions in a moment. Let us once again look at (*). (*)’s existence presupposes that of D. (Remember how (**)’s existence presupposes that of Smith and Jones). (*)’s being true in W involves there begin instances in W of D and of the property of being green. (Remember how (**)’s being true in W involves there being instances of Smith’s hitting somebody, somebody’s being hit, and so on.) Now let us look at S in light of these facts. S’s existence presupposes that of D (and, of course, of the property of being green). In order for all of S’s members to be instantiated in W, it is necessary that both D and the property of being green be instantiated there. But, as we discussed, this is not sufficient. So far, then, there are significant parallels between (*) and S, and also between (*)’s being true and S’s being such that all its members are instantiated. After this point, it becomes hard to determine to what extents facts about S parallel facts about the structure of (*). This is because we know so little about the latter. So far as we have such knowledge, it is given vague statements such as those already discussed, e.g.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-303",
    "text": "But by identifying (*) with S, and (*)’s being true with S’s members all being instantiated, we can fill in these gaps in our understanding, without violating our pretheoretic intuitions, vague though they may be, as to the nature of propositional structure. (#) was our starting point. But (#) is obviously unacceptable as it stands. The truth of (*) is probably constitutively, and not just causally, dependent on facts about physical law – on facts about protons, electricity, gravitation, and so no. It is very hard to believe that D – that very plant – could exist in a world governed by different physical laws or forces, or in a world that didn’t comprise electrons or protons or any of the micro-particles found in our world. So it is very hard to believe that D could exist in a world where there were no gravitation. But clearly the concept gravitation is not a constituent of (#), at least not in remotely the same sense as the concept green or the concept D; and the same is true of the concepts electricity, proton, photosynthesis, and so on. So though it may be true, even truistic, (#) is not enough; it doesn’t tell us why D is a constituent of (*), whereas the concept of electricity is not. But our analysis can help solve this problem. D is a member of S. (When discussing S’s membership, we referred to D as #2; but obviously that isn’t important.) Similarly the property of being green (#3) is a member of S. By contrast, the concepts of electricity, gravitation, and so on, are not members of S. So by identifying S with (*), we replace (#) with a precise and clear statement – a statement that agrees with (#), so far as the latter goes but that, unlike (#), isn’t unclear or otherwise exceptionable. If S’s members are instantiated, that entails (inter alia) that D is instantiated and that the property of being green is instantiated. By contrast, it doesn’t entail any statements regarding gravitation, electricity, or photosynthesis -- even though, quite possibly, the members’ of S being instantiated is constitutively dependent on facts about gravitation, electricity, and so on. In conclusion, if we identify propositions with sets of properties, and a proposition’s being true with all of its members being instantiated, then we can give clear, precise, and extensionally correct answers to important questions...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-304",
    "text": "Before we deal with molecular proposition, it may be appropriate to give one illustration of our analysis of atomic propositions. This is because (*), the proposition in terms of which we illustrated our analysis, has minimal relational structure; and it is thus worthwhile to show that our analysis doesn’t break down when applied to relationally richer propositions. Given this, let us consider (**) once more. It is pretty clear that Smith, Jones, and the relation of hitting are constituents of it. It also seems clear (though this point has a more theoretical quality) that (**) also has as constituents the “propositional functions”: Smith hit y, x hit Jones, and x hit y. It is also clear that these things must be “combined” in some special way if (**) is to result. It is clear that not just any arrangement of those entities will do. Frege explained why this last requirement must be met. We briefly discussed Frege’s argument in the last chapter. Here we must develop what we said. Consider the following list of expressions:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-305",
    "text": "(**F2) is no more a sentence, and no more encodes a proposition, than (**F). Obviously no expression would result from (**F2) no matter how many more denoting expressions we added to it. In general, a sentence is not a (mere) list or heap of referring-terms. So a sentence is more than a list of referring terms. What does “Smith hit Jones” have that each of (**F) and (**F2) lacks? “Smith hit Jones” is grammatical, whereas the other two are not. In “Smith hit Jones”, the expressions are appropriately inflected and they occur in the right order. This is not the case with respect to either (**F) or (**F2).[267] We’ve seen that we can’t turn (**F) into a sentence by adding more referring terms. We’ve also seen that it is facts about grammar – inflections, word-order, and the like – that are needed to turn (**F) into a sentence. It seems, then, that grammatical morphemes do not, at least not generally, refer. The ordinal information that they encode is not to be understood in terms of their referring to anything. Let us turn our attention back to (**). We’ve seen that among its constituents are: Smith, Jones, the relation of hitting, Smith’s hitting something y [or: the propositional function Smith hit y], x’s hitting Jones [the function: x hit Jones], and something’s hitting something [the function: x hit y]. But what we haven’t seen is how these things must be combined if a proposition is to result. And – what would seem to be a related point – we haven’t seen exactly what it is that the inflections in “Smith hit Jones” do. (In this context, I will use the term “inflection” to refer to all grammatically significant facts – e.g. word-order, intonation, and so on.[268]) We’ve seen that they “combine” the constituents just mentioned in some way or other; we’ve seen that they don’t do so by referring to anything; and we’ve seen that, as a result of their performing this (as of yet under-described) feat of “combining”, a proposition is meant by “Smith hit Jones.” But we haven’t put our finger on the identity of this mode of combination. But, given what we said in connection with (*), we may, I think, be able to do so. Let us begin with Lewis’ insight. There is some property – we will call it simply “#1*” – that a world has...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-306",
    "text": "Obviously this list goes on ad infinitum. So given that (**) is not identical with any of the propositions on that list., (**) is cannot be identical with #1*. But it is surely suggestive that (**) is true exactly if #1* is instantiated. Given this, let S2 be a set one of whose members is #1*. As we’ve discussed, Smith and Jones can be thought of as properties. Let #2* and #3* be those properties. It goes without saying that the expression “being hit by Smith” (which corresponds to the function Smith hits y) and “hitting Jones” (x hits Jones) and also “hits” (x hits y) correspond to properties. (Following tradition, we can think of the relation of hitting as a property of ordered pairs.) Let #4*, #5*, and #6* be those properties. Finally, let S2 be a set that has for its members all and only #1*-#6*. For obvious reasons, if #1* is instantiated, then so are #2*-#5*. And, as we’ve already discussed, (**) is true (in a given world) exactly if #1* is instantiated. It follows that (**) is true in a world exactly if all of #1*-#6* there. So, thus far, there is no reason not to identify S2 with (**), and (**)’s being true with S2’s being such that all its members are instantiated. Further, S2’s constituency is comparable, in an obvious way, to the constituency of (**), at least in so far as we know anything about the latter. We know that Smith, Jones, the relation of hitting are “constituents”, in some sense of the word, of (**). We also have reasons, given to us by Frege (and, since his time, by many others) to suspect that the functions x hits Jones, Smith hits y are also constituents (in some sense of the word) of (**). Further, we know that (**) is what results when these (or some subset of these) various entities are “combined” in some mysterious way. S2 has a constituent corresponding to each of the constituents of (**), and the mysterious operation of “combining” just mentioned can be understood in terms of facts about S2’s membership. S2 has a discrete part correspond to Smith, to Jones, to hitting, and so on. And we know exactly how #1*-#6* -- the parts corresponding to the Smith, Jones, and so on – relate to S2: they are members of it. That is as clear a...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-307",
    "text": "Before we discuss molecular propositions, let us discuss the bearing that our analysis of propositionality has on the viability of LOT. If our analysis is right, a proposition is a set of properties. Given what we said earlier, this means that any proposition is at an extraordinarily high number of removes from anything that could be the content of any experience (i.e. any perceptual or sensory experience). Let us now spell out why this is so. We’ve already seen why, so far as they cannot be identified with concrete situations, property instances are (contrary to what is generally thought) abstract commonalities among situations, and are therefore abstract. We’ve also discussed why terms like “red” are not properties of things whose instances can be encountered in experience, but are rather properties of such properties. We had to invent special terms – “R1”, “R2”, and so on – to denote the maximally specific shades of red that one sees. What is true of “red” is true of any expression with a fixed, as opposed to context-dependent, reference. Context-dependent expressions, e.g. “that exact shade of red”, can denote properties had by situations that can be experienced, i.e. seen, heard, touched, and so on. But context-dependent expressions must be built of context-independent ones; and the latter, as we’ve discussed, necessarily have abstract things for their significances. We’ve also discussed why terms like “Smith” and “Jones” are not as dissimilar as one might think from terms like “red” and “pain.” The former, no less than the latter, fail to have concrete situations for their semantic contents, and instead have for their semantic contents abstract commonalities among situations or worlds. If our analysis of propositions is correct, then a proposition is a set consisting of various properties. And in most cases those properties are really hyper-properties (properties of properties, or properties of properties of properties, or…) The only cases where the constituents of a proposition are mere properties, as opposed to hyper-properties, are the cases where those propositions are to expressed using demonstrative expressions like “that particular shade of red” (or neologisms like “R1”). For a proposition to be true is for the properties that are members of it to be instantiated, i.e. it is for all of those (hyper-)properties to have the higher-order property of being instantiated.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-308",
    "text": "(N**) is a molecular proposition. It is the proposition: it is not the case that Smith hit Jones. (N**) has two immediate constituents. These are (**) and the concept of negation. Jones is not an immediate constituent of (N**). (N**) is a statement about (**). (N**) says of some proposition that it isn’t true. If our analysis is correct, this is equivalent to saying that the members of S2 are not instantiated. At the same time, we want to hold onto the idea that a proposition is a set of properties, and that for a proposition to be true is for the members of that set to be instantiated. In other words, we don’t want to understand the concepts proposition and truth one way where atomic propositions are concerned, and a different way where molecular propositions are concerned. So we must show that (N**) is some set SN of properties, and that (**N) is true iff all of SN’s members are instantiated. This can be done. Remember #1* -- the property had in common by all and only those worlds where (**) is true. As we discussed, #1* is a certain way that a “quantum” can be rippled. Now consider all the worlds that aren’t rippled that way – that have ripples incompatible with the truth of (**). Let #N1 be that property. Of course, in this context we described #N1 negatively. We described it in terms of some proposition’s not being true. But, to echo a point made by Frege (1918), it doesn’t follow that #N1 is itself any more “negative” than #1. Any given state of affairs can be described positively or negatively. We can say “Brown failed to make it to the finish line” (negative characterization) or “Brown collapsed before the finish line” (positive characterization). The first sentence describes a state of affairs in terms the falsity of some proposition (Brown made it to the finish line); the second describes that same state of affairs but not in terms of the falsity of some proposition. Similarly, suppose we were so naturally aggressive that the normal course of events was to hit other people, and that it was more disruptive to our psychologies and cultures when people refrained from hitting others than when they actually did so. In that case, we might have a special verb “to frit”, meaning to refrain from hitting. So “Smith frit Jones” would...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-309",
    "text": "(&) has two immediate, proper constituents, namely: “that Smith hit Jones” and “it is not the case.” So if we count “it is not the case that Smith hit Jones” as a constituent (an improper one) of itself, (&) has three immediate constituents. Similarly, S3 has three members; and each of these members corresponds in an obvious way to the three main constituents of (&). So facts about S3’s membership neatly correspond to facts about the decomposition of (&) and therefore, presumably, to that of (N**); and facts about the conditions under which S3’s members are instantiated correspond neatly to facts about the conditions under which (N**) is true. So there is every theoretical incentive to identify (N**)’s being true with its being the case that the members of S3 are instantiated. Thus, far from warranting the rejection of our analysis, consideration of (N**) confirms it. What we said about (N**) is true mutatis mutandis of all molecular propositions. I discuss this at length in another work (Kuczynski 2005c), where I also discuss the structure of analytic propositions. But given that our concern here is mental representation – specifically, the viability of LOT – it isn’t necessary that we consider the concept of propositional structure in such detail. And given only what we’ve said thus far about propositions, the implausibility of LOT has been adequately demonstrated. Chapter 24 Peacocke on concept-possession",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-310",
    "text": "Like us, Christopher Peacocke rejects conceptual atomism. Further, Peacocke has ably defended a version of non-atomism. The purpose of this chapter is to evaluate Peacocke’s analysis. To do this, we will have to use some of the points that we’ve developed over the last two chapters. That is why we were not able to discuss Peacocke’s important work in an earlier chapter. Let us start with a point about terminology. In Chapter 16, we distinguished between “conceptso” and “concepts.” The latter are psychological entities; the former are platonic abstracta. In this chapter, we will once again use these terms in this way. Let there be some concepto C satisfying the following conditions. A belief in P coupled with a belief in Q leads directly, i.e. not by way of an inference, to a belief in P C Q; and a belief in P C Q leads directly to a belief in P and a belief in Q. In other words, given a belief in P and in Q, one is “primitively compelled”, as Peacocke puts it, to believe P C Q; and given a belief in P C Q, one is primitively compelled to believe P and also to believe Q. Under these circumstances, says Peacocke, we may conclude that C is the concepto of conjunction and also that you grasp that concepto. The concepto of conjunction has certain “possession conditions”, as Peacocke puts it, and you grasp that concepto because you satisfy those conditions.[269] It is obvious how to apply Peacocke’s analysis to various other conceptso. Let C be a concepto satisfying the following conditions. If you believe x falls under C, then you are primitively compelled to believe x is a closed figure, x has three-sides and x’s sides are straight; and if you believe all of those three propositions, then you are primitively compelled to believe x falls under C. In that case, C is the concepto of a triangle. There are some apparently compelling reasons to accept this analysis. First of all, intuition recoils at the notion of someone who believes that x is a triangle but has no disposition to believe that x is three-sided. To believe that x is a triangle just is (so it would seem) to believe (inter alia) that x is three-sided. This suggests that one’s grasp of a concepto necessarily involves a mental representation of the fact that certain transitions...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-311",
    "text": "You say that “intuition recoils” at the view that one could believe x is a triangle without believing, or at least being disposed to believe, that x is three-sided. But that intuition may just reflect the fact that it is obvious, at least to us, that triangles have three-sides. If you know that your friend Smith is miserable whenever it rains, then you are likely to believe that Smith is miserable if you already believe that it is raining. But it would be absurd to say that your concept of Smith is constituted by your having this disposition. And given only that you are likely to believe that x is three-sided if you already believe that x is a triangle, it is comparably absurd to suppose that your concept of triangularity consists in your having this disposition. But in light of what Peacocke says about conceptso, there is a compelling response to this. If x is identical with Smith, that is not in virtue of the fact that x is unhappy when it rains. But C is the concepto of triangularity only if x falls under C entails x is closed, x has three sides and x has interior angles that add up to 180°. So, whereas Smith is not individuated by the fact that he is unhappy when it rains, the concepto of triangularity is individuated by the fact that it has these analytic liaisons with these other conceptso. For C to be the concepto of triangularity just is (so it would seem) for C to be such that anything falling under it falls under these other conceptso. Given this, it makes little sense to suppose that one could grasp the concepto of triangularity without mentally representing at least some of these entailments. For the reasons given earlier, it thus seems necessary to suppose that a grasp of that concepto consists in a set of “inferentially unmediated” dispositions of the kind that Peacocke describes. In a word, if we give any weight to the intuition that a grasp of a concepto is inseparable from an appreciation of the validity of certain patterns of inference, it certainly appears that we have little choice but to accept Peacocke’s analysis. George Rey put forth some criticisms of Peacocke’s view. I will discuss what I believe to be Rey’s two most significant criticisms. One of those criticisms is spurious. But the other is...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-312",
    "text": "Since Peacocke’s analysis sees conceptso as being individuated by their analytic structures, it obviously presupposes that there is an analytic-synthetic distinction. Quine famously denied that there is an analytic-synthetic distinction, and many agree with Quine on this. So, as Rey points out, Peacocke’s position is wrong if Quine is right. Rey believes that Quine is right, or at least that he may be right; and he therefore holds that Peacocke’s position is either false or tenuous. As we saw in Chapter 16, Quine is not right. Nonetheless, the basic idea behind Rey’s criticism is not an unreasonable one. But the inadequacies that Rey ascribes to Peacocke’s position are better understood in terms of Kripke’s work than they are in terms of Quine’s. Peacocke’s position demands not only that some conceptso have some analytic structure, but that any two non-identical conceptso have different structures. So the concepto Socrates must have a distinct structure from the concepto Plato. We know from Kripke that “Socrates was bald” doesn’t entail anything not entailed by “Plato was bald.” Given this, a case can certainly made that the conceptso corresponding to “Socrates” and “Plato” do not differ in respect of analytic structure. In connection with this, it should be pointed out that Peacocke always illustrates his position in terms of conceptso belonging to arithmetic or mathematical logic: he never relates his analysis to conceptso like bird or Socrates or tree. Given this, it is hard to escape the feeling that Peacocke’s position fails to hold for anything other than a few artifacts and, therefore, that it probably doesn’t hold at all. Evaluating this criticism",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-313",
    "text": "Let us start with a story. Smith believes that n=32. He non-inferentially transitions from that belief to a belief that n=9. Trivially, there are two different views to take vis-à-vis Smith’s transition. On the one hand, we can say that it was either valid or invalid. On the other hand, we can say that it was neither valid nor invalid. Let us elucidate this second option. If I think “Socrates is wise” at 3:00 p.m., and think something was wise at 3:01 p.m., I haven’t necessarily made a valid inference. In fact, I haven’t necessarily made a valid inference even if my thinking Socrates was wise is what caused me to think something was wise. This can be shown in terms of a story that we told in Chapter 15. A hypnotist programs me to believe something was wise whenever my heart-rate goes above 100 BPM. When I discover that Socrates was wise, the resulting epiphany leads to tachycardia and thus, given the hypnotist’s programming, to my forming the belief that something was wise. Here no inference occurred. By the same token, if I believe that something was wise at 3:00 p.m., and a minute (or second) later form the belief that nothing was wise, I am not necessarily guilty of inferring a proposition from its negation. This can be shown through an obvious adaptation of the story just told. For similar reasons, given only that Smith transitions from a belief that n=32 to a belief that n=9, it doesn’t follow that his transition is valid; and if he transitions from a belief that n=32 to a belief that n=6, it doesn’t follow that his transition is invalid. If we say that Smith’s transition is either valid or invalid, then we are saying that it is answerable to norms. More specifically, we are saying that it must be consistent with the content of Smith’s belief that n=32. But in that case, Smith’s making that transition cannot be constitutive of his believing that n=32. In general, since there is normativity only where there is already a fixed content, norm-governed transitions cannot be constitutive of content. So if Peacocke’s analysis is to be correct, the transitions of which he speaks must not be answerable to any norms. The problem is that at least some transitions that are not norm-governed are not constitutive of anyone’s grasp of any concepto. The story we told...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-314",
    "text": "According to functionalism, brain-state B’s realizing a belief that Socrates was wise consists in its having certain consequences, e.g. its leading to a belief that something was wise. But if that is right, then B’s realizing such a belief cannot be what generates those consequences. Peacocke’s analysis is a form of functionalism. It is in virtue of its having certain effects that B realizes a belief that Socrates is wise. But in that case, it is hard to see why the just mentioned problem with functionalism isn’t a problem for Peacocke’s view. Admittedly, Peacocke doesn’t hold that all of the states of affairs generated by B determine what content it has. He seems to hold that the only relevant effects are those that B immediately generates. But this doesn’t help. Suppose that B leads to B2, which realizes a belief that something was wise, and that B2 leads to B3, which realizes a belief that something was sentient. If Peacocke’s analysis is right, B2’s having that effect is constitutive of its being a belief that something was wise. So B2’s having that effect is constitutive of something that is constitutive of B’s being a belief that Socrates was wise. For similar reasons, B3’s being a belief that something was wise is constitutive of something that is constitutive of B’s being a belief that Socrates was wise. At any given juncture, we encounter, at most, something that is constitutive (either directly or indirectly) of B’s being a belief that Socrates was wise. At no juncture, therefore, do we encounter anything could be an effect of B’s being such a belief. Never do we encounter anything that is an effect of my belief that Socrates was wise. This brings us to another issue. If Peacocke is right, conceptso are individuated entirely by their analytic liaisons. So conceptso are relations to other conceptso. Any given concepto is a node in a network that, in its turn, consists in nothing but more conceptso. It is hard to see how this picture can allow conceptso to make any contact with anything non-conceptualo. Right now, physicist Smith is having various perceptions. On the basis of these perceptions, along with a correct understanding of the conceptso electron, proton, weak force, and so on, Smith makes a correct inference as to the sub-atomic structure of object X. In general, what we perceive is relevant to how we understand...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-315",
    "text": "But this point of view rebuts itself. It is a datum that I am right to think grass is green and wrong to think penguins wear top hats. So the “auxiliary hypotheses” that the objector mentions must themselves be internal to the structure formed by the totality of all conceptso. Of course, a given perception 666 may warrant different beliefs, depending on what on what one already believes. If I believe that I am looking at myself in a normal mirror, perception P warrants the conclusion that I am eleven feet tall. If I believe that I am looking at myself in a mirror that is warped in a certain way, perception P warrants the view that I am six feet tall. But if any experience, or series of experiences, can correctly be conceptualized in any way at all, then it won’t matter what other experiences I’ve had. Under that circumstance, those other experiences will fail to provide a benchmark in terms of which I am to know how to conceptualize P. So to the extent that P warrants the view that I am of this as opposed to that height, it is because experiences other than P are to be conceptualized in certain ways and not in others. It is not an option to say that the principles linking conceptso to experience are external to those conceptso themselves. Whether a concepto is instantiated is typically to be decided on experiential grounds. It is only the basis of sense-perception that I can know whether somebody is wearing a blue-shirt, xxx i.e. it is only on the basis of sense-perception that I know the concepto blue-shirt wearer is instantiated. But in order for experience to warrant such a belief, the concepto blue-shirt wearer must already be such that certain kinds of experiences warrant the view that it is instantiated. Even though it is an empirical matter whether a given concepto is instantiated, it is not ultimately an empirical matter what kinds of experience would warrant the view that it is instantiated. Given the structure of the concepto blue-shirt wearer, it doesn’t follow that somebody is wearing a blue shirt. But given the structure of that concepto, it does follow that if one were to have certain sense-experiences, one would be right to believe that concepto to be instantiated. Most empirical judgments can be overturned by later experiences. (I say “most” because,...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-316",
    "text": "Let us start with some facts. I am disposed to believe x has more than two sides if I believe x is a triangle. I am disposed to believe m is larger than n if I believe m is what results when some positive number is added to n. Given a grasp of any concepto C, one’s beliefs tend to track C’s analytic structure. Peacocke’s analysis is meant to accommodate this important fact; and at first it seems to do a reasonable job. But we’ve also seen that Peacocke’s analysis is probably false. What should replace it? We need to produce a theory that, like Peacocke’s, accommodates the datum just mentioned but that, unlike Peacocke’s, doesn’t strip the mental causal potency and that, unlike Peacocke’s, doesn’t strip conceptso of experiential import. I believe that the elements of a solution may lie in some points that we made in the last two chapters. First of all, conceptso are not so different from properties. For x to have the property of triangularity just is for x to fall under the corresponding concepto. In fact, to many authors, the words “property” and “concept” are interchangeable. Admittedly, this line of thought must be qualified. The concepto successor of one is obviously different from the concepto predecessor of three. (This is because thinking x is a successor of one is different from thinking x is a predecessor of three.) But the property of being a successor of one doesn’t seem to be different from the property of being a predecessor of three. (This is because anything that has the one property ipso facto has the other: so being a successor of one is not different from being a predecessor of three.) Nonetheless, it does seem at least approximately true to say that conceptso just are properties. If only to facilitate exposition, let us proceed on the assumption that this is right. (Later we will argue that this assumption is correct.) In light of this, let us remember what we said about properties. Property-instances turn out to be abstract objects, contrary to what has generally been assumed. Properties themselves are commonalities holding among such abstract objects. The properties that are expressed by most natural-language predicates – e.g. “red”, “hot”, “square-shaped” – turn out to be commonalities holding among these commonalities: they turn out to be hyper-properties. The only natural-language expressions that denote bona fide first order...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-317",
    "text": "is not an analysis. This is because it is trivial. And x is a unique contemporary U.S. President iff x is George W. Bush is not a conceptualo analysis, even though it is non-trivial and true. This is because it is not analytic. So an analysis is given by a true, analytic, and non-trivial biconditional; and a partial analysis (e.g. if x is a circle, then x has a uniform curvature) is given by a non-trivial, analytic conditional. Now we can state the paradox of analysis: How can a correct analysis be informative, given that the concepto on the left side of the biconditional must be identical with the concepto on the right? If the concepto closed, two-dimensional figure of uniform curvature is different from the concepto circle, then (k) fails to delineate the structure of the latter, and thus fails as an analysis. But if those conceptso are identical, then (k) should be as trivial as (k*). What are we to say about this paradox? First of all, conceptualo analyses don’t state conceptualo identities. The concepto circle is not identical with the concepto closed, two-dimensional figure of uniform curvature. Those conceptso are different conceptualizations of the same situation-representations. Therefore, xxx given a few obvious adjustments, what we said in connection with the conceptso triangle and straight-edged explains why (k) is both non-trivial and true. If we don’t distinguish between conceptualo and non-conceptualo content, it is xxx quite impossible to explain how there can be such a thing as conceptualo analysis. Analyses expose internal, necessary relations between conceptso. But, as we just noted, they don’t expose conceptualo identities. Given this, if we say that all content is conceptualo, then we must say that conceptualo analyses expose the “depths” or the “structures” of conceptso. But that statement is easily shown to be false. The concepto class of all points equidistant form a given point in a plane is different from the concepto closed planar figure of uniform curvature. This is equivalent to saying that the kind of thought that you have in virtue of thinking that x falls under the one concepto is different from the thought you have in virtue of thinking that x falls under the other. In light of this, suppose we say that conceptualo analyses (when true) expose the “depths” or the “structures” of conceptso. In that case, we are saying that when you think:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-318",
    "text": "But when you think (i), you aren’t necessarily thinking (ii). When I think Sam is short and Mary is tall, the proposition Sam is short is a part of the content of what I am thinking. (ii) is no part of the content of what I am thinking when I think (i). One may say that, when I am thinking (i), I am “implicitly” thinking (ii). But, if taken as a psychological hypothesis, this is highly doubtful. If taken as a non-psychological, strictly logical thesis, it is just a misleading way of saying that (ii) is a correct analysis of what I think when I think (i). If one holds that conceptualo content is the only kind, then the paradox of analysis becomes unsolvable. But that paradox is quite solvable if we distinguish between conceptualo and non-conceptualo content. A concepto is a conceptualization of content that is not itself conceptualo; and an analysis of a concepto (a conceptualo analysis) is a re-conceptualization of that same non-conceptualo content. In this way we accommodate the fact that there is an internal connection between the conceptso circle and closed figure. But we are not forced to say the one concepto has the other as a veritable ingredient; and we are thus not forced to say that, when you think circle, you necessarily think closed figure. At the same time, we have explained why, if one grasps the first concepto, one has all but grasped the second, thereby explaining why conceptualo analysis produces a feeling of recognition – of seeing what one has already seen, through from a new perspective -- as opposed to a feeling of discovery de novo. Conceptso versus properties",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-319",
    "text": "To facilitate the exposition of our argument, we assumed that conceptso are identical with properties. According to this view, the concepto of being a triangle is identical with the corresponding property. This is not an unreasonable view, and some philosophers hold it. But it is one that must at least be qualified. The concepto closed three-sided, straight-edged, planar figure one is obviously different from the concepto area bounded by three straight-lines such that any two of them, but not all three of them, intersect. But it is hard to see how those conceptso could correspond to different properties. Supposing that x falls under the concepto closed three-sided, straight-edged, planar figure and y falls under the concepto area bounded by three straight-lines such that any two of them, but not all three of them, intersect, there isn’t necessarily any difference between x and y. In fact, x and y could be numerically identical. Where there are no differences, there are no differences in properties. It seems that we have one property and a multiplicity of conceptso. This doesn’t mean that conceptso are not properties. But it means that the statement conceptso are identical with properties must be qualified, lest it entail the falsehood that the concepto even prime is identical with the concepto successor of one. A point made by Frege (1954: 60-61) points us in the direction of what I believe to be a correct understanding of the relationship between conceptso and properties. If you say “x is a triangle”, you are ascribing a property to x. But for any individual x, the sentence ┌triangles are closed figures, but x is not a closed figure┐ is not self-contradictory. So there is no individual x such that, if you say “triangles are closed figures”, you are saying anything about x. This suggests that statements like:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-320",
    "text": "are true, the property of being a circle has a property in common with the property of being a triangle. They both have the property of being such that their instances are closed figures. The concepto closed three-sided, straight-edged, planar figure obviously has a different composition from the concepto area bounded by three straight lines such that any two of them, but not all three of them, intersect. That is why they are different conceptso. But both conceptso correspond to a property that is unique to the property of triangularity. The property of triangularity is uniquely such that all and only its instances are closed, three-sided, straight-edged, planar figures; and the property of triangularity is also uniquely such that all and only its instances are areas bounded by three lines any two of which, but not all three of which, intersect. An individual falls under the one concepto if it falls under the other. But this is not because that individual has a different property corresponding to each of those different conceptso. It is rather because a property (that of being triangular) had by that individual has a different property corresponding to each of those different conceptso. We have thus made some case for the view, presupposed by our analysis of analysis, that conceptso are properties. Chapter 25 Semantics versus Psychology",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-321",
    "text": "In this chapter, we will once again stop using the term “concepto” (and any derivatives thereof, e.g. “conceptualo”), since context will make it clear whether we are discussing concepts in the platonic sense or concepts in the psychological sense. It seems reasonable to suppose that one must know the semantic rules of any language that one knows and that linguistic ability is therefore posterior to cognitive ability. If this is right, then it is obviously viciously regressive to suppose that we think in a language. Advocates of SCT deal with this by saying that one doesn’t have to know the semantic rules of a language whose expressions mediate one’s own thoughts. It is necessary only that one be “built to conform” to those rules. In this chapter, we will see some reason to believe that, given a correct analysis of the concept of a semantic rule, there can be no language where there is no knowledge of semantic rules and that SCT is therefore guilty of vicious regressiveness.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-322",
    "text": "Grice had a certain view about this. But that view is not tenable, since it is subject to innumerable examples. To deal with this problem, Griceans have proposed modifications of Grice’s theory. But in addition to having an epicyclical and ad hoc quality, those modifications are themselves subject to counterexamples.[275] Further, as Searle (1969: 42-50), xxx and other authors make clear, there are systemic problems with Grice’s analysis. If I think that there is no pre-existing symbolic relationship between “Socrates was wise” and the proposition that Socrates was wise, then I cannot mean the latter by an utterance of the former. In general, a person cannot mean X by Y unless he believes there to be an existing symbolic relationship between X and Y. Since the essence of Grice’s theory is that linguistic meaning is derivative of speaker’s meaning, it seems that there is little hope for Grice’s theory or for any elaboration of it. That is why few currently advocate Grice’s theory of meaning. But given only that the Gricean theory is incorrect, it doesn’t follow that semantic relations are to be understood in non-psychological terms. We saw in Chapter 20 that they cannot in fact be understood in this way. I would now like to propose a third view. According to this view, semantic relations are to not to be understood in terms of what people mean, but they are to be understood in terms of what people think. Some conditions that a semantic theory must satisfy",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-323",
    "text": "Superficially, (HT) seems better than (HM). The concept of truth seems to be pre-linguistic. A cat can truly believe that you are about to feed it. A dog can truly believe that you are about to kick it. In general, non-linguistic creatures have true and false beliefs. And, of course, they can also have accurate (true) and inaccurate (false) perceptions. So true and false mental states are obviously antecedent to language.[276] Further, the notion of linguistic truth is plainly derivative of that of propositional truth. The proposition there is water on Earth was true long before there were any creatures or, consequently, any language.[277] So given the fact that truth is not a distinctively linguistic notion, it might seem that (HT) is not guilty of vicious circularity. But this is a mistake, and (HT) is viciously circular. The notion of truth is, indeed, not a distinctively linguistic notion. But the very question -- or, at least, one of the very questions -- that a semanticist must answer is “what is it for an expression to be true?” The question “what is it for ‘snow is white’ to mean that snow is white?” is scarcely different from the question “what is it for ‘snow is white’ to be true iff snow is white?” So even though truth is a pre-linguistic notion, (HT) is still viciously circular; for the very question that we are trying to answer is, in effect, “what is linguistic truth, and what is it for an expression to be true under such and such circumstances?” The first thing anyone trying to answer (EM) must do is to find some notion such that the concepts of expression-meaning (and expression-truth) can be non-circularly understood in terms of that notion. There is such a notion: it is the notion of success.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-324",
    "text": "The concept of linguistic success Let us set aside language for the moment, and let us instead discuss the game of tennis. The game of tennis is being played in a given context exactly if, in that context, certain things count as success as other things count as failure. If you hit a certain ball that has bounced no more than once on your side of the court into your opponent’s side of the court, and your opponent fails to do the same thing (mutatis mutandis), you have won a point, and you have thus had a success of a certain kind. (It is obviously irrelevant that points are measured in multiples of fifteen.) If you have a certain number of successes of this kind before your opponent, then you have another kind of success (you win a game). If you have a certain number of successes of this kind before your opponent, then you have another kind of success (you win a set). And so on. For a game of tennis to played in a context C just is for it to be the case that, in C, these things count as success, and that not doing them counts as failure. A game of tennis is being played in C exactly if those success-conditions and failure-conditions are operative, i.e. are instantiated, in C. So the game of tennis itself is a property had by situations exactly if, in them, those conditions apply. And a particular tennis-match, i.e. an instance of the game of tennis, consists in the instantiation of those conditions. Here we have to be careful. It is not as though the game of tennis exists first, and these rules subsequently impose some kind of structure on this antecedently existing entity. There is no such thing as tennis until it is the case that, in certain situations, one enjoys a certain kind of success iff one hits a ball (that has bounced no more than once in a certain place) over a certain kind of net, and the person standing on the other side of that net fails to do the same thing. The concept of success, in this context, is thus not to be defined in terms of the game of tennis. On the contrary, the game of tennis is to be defined in terms of that concept, and that concept is to be taken as a...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-325",
    "text": "Given these points, we can outline what I hope is a defensible analysis of the concept of a semantic rule. For the sake of simplicity, let us initially consider only assertoric utterances. There is some point of view from which an utterance of “Socrates was wise” is a success just in case Socrates was wise, and from which, more generally, an utterance of the form ┌Socrates has phi┐ is true iff Socrates has the property phi. This doesn’t meant that if you say “Socrates was wise”, and he in fact was wise, anything particularly desirable will happen to you. True utterances don’t necessarily bring one wealth, fame, or happiness. But it does seem to be a simple fact that, from one important perspective, an utterance of “Socrates was wise” is a success exactly if Socrates was wise, and an utterance of “Socrates was not wise” is a failure under that same circumstance. Here we have to recall a distinction that we made when discussing Wittgenstein’s Rule-following argument: the distinction between linguistic success per se and the consequences of such success. A detour through the game of tennis may once again be useful. If you beat your wealthy and vain father-in-law at tennis, you have enjoyed a kind of success (tennis-success). But the consequences of your tennis-success may be disastrous: he disinherits you, fires you from your sinecure at his firm, and so on. Similarly, if you say “Socrates was wise”, you deserve credit for a kind of success (linguistic success). But the consequences of that success may outweigh the success itself. For some reason, your boss hates anyone who thinks that Socrates had any redeeming characteristics. So he fires you when you say “Socrates was wise.” And had you instead said “Socrates was not wise”, the consequences of your linguistic failure might well have been outweighed by success of a non-linguistic kind. Comments very similar to those made a moment ago about tennis are true of language. It isn’t as though the English language exists first, and then there come into existence various facts about success- and failure-allocation of the kind just described. It isn’t as though the English-language exists first, and then it comes to be that one enjoys success if one utters “Socrates was wise” iff Socrates was wise and, more generally, if one utters a sentence of the form ┌…Socrates…┐ iff Socrates has property…x…The English language doesn’t...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-326",
    "text": "It is typically thought that the concept of language is to be understood in terms of the concept of truth, not of success. There are two reasons why this is not the case. Any attempt to understand linguistic meaning in terms of truth is bound to result in a theory that is either viciously circular or that fails to distinguish actual from merely possible semantic rules. As we saw in Chapter 20, we cannot explain the fact that “Socrates snored” means Socrates snored by saying that the relevant semantic rule is a function that assigns truth to an utterance of “Socrates snored” exactly if Socrates snored. After all, there is a function that assigns truth to an utterance of that same sentence exactly if Socrates did not snore. This shows that the mere existence of a function of the kind described is insufficient for the existence of an operative semantic rule. (A “non-operative” semantic rule is no more an actual semantic rule than a possible individual is an actual individual.) So a theory that identified semantic rules with functions from utterances to truth-values fails to distinguish semantic rules from their possible, but non-operative, counterparts. In response, one might say, as Lewis (1975) does, that an operative semantic rule is a function that people use. But then we must ask: what is for people to use a function that assigns truth to utterances “Socrates snored” iff Socrates snored? It is presumably for there to be an understanding among people that utterances of “Socrates snored” are to be considered true iff Socrates snored. But, as we saw a moment ago, such an understanding is itself to be understood in terms of the existence of semantic rules. An agreement that utterances of “Socrates snored” is to be assigned truth iff Socrates snored is not significantly from an understanding that such utterances are to mean Socrates snored; and obviously such an understanding is itself to be understood in terms of the concept of a semantic rule, and thus cannot in their turn provide an analysis of that concept. So if we identify semantic rules with functions from utterances to truth-values, our theory is either viciously circular or it fails to distinguish operative from non-operative semantic rules. There is a second reason why the concept of a semantic rule is not to be understood in terms of the concept of truth. Many well-formed utterances are...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-327",
    "text": "The meanings of sub-sentential expressions, e.g. “Socrates”, are to be understood in terms of their affect on the success-conditions of utterances in which they occur.[280] As we’ve discussed, an assertoric utterance of “Socrates was wise” is a success, in the relevant sense, exactly if Socrates was wise. More generally, ┌Socrates has phi┐ (or, equivalently, ┌…Socrates…┐) is a success exactly if Socrates has phi (or, equivalently, exactly if…Socrates…). Going up another level of generalization, E refers to O exactly if (assertoric) utterances of the form ┌…E…┐ are true exactly if O has the property…x… So even though an utterance of “Socrates” does not by itself have success-conditions (leaving aside cases where such an utterance is merely elliptical for a whole sentence), the semantics “Socrates” is to be understood in terms of the success-conditions of sentences of which it is a part. In response to this, it might be said that “Socrates” is to be defined non-contextually – that the semantics of “Socrates” is given by the non-contextual definition: “Socrates” refers to Socrates. But it would be meaningless to say that “Socrates” referred to Socrates but then to deny that, in virtue of having the form ┌Socrates has phi┐, a sentence had anything to do with Socrates or, more precisely, with Socrates’ having phi. When we say that “Socrates” refers to Socrates, we are saying that ┌Socrates has phi┐ is true iff Socrates has phi, that an appropriate answer to ┌does Socrates have phi? ┐ is a correct affirmation of that Socrates has phi or that Socrates does not have phi, that an appropriate response to an utterance of ┌Socrates, have phi! ┐ consists in Socrates’ coming to have phi in consequence of that utterance, and so on.[281] Of course, not everyone will agree with every aspect of what was just said. But what seem uncontroversial is that there is a certain kind of success S, such that it is constitutive of the semantics of “Socrates was wise” that assertoric utterances of it have S if Socrates was wise, and lack S otherwise. It is clearly constitutive of the semantics of assertoric sentence-tokens of the form ┌Socrates has phi┐ that any such token is a success exactly if Socrates has phi. Similar remarks apply to questions of the form ┌does Socrates have phi?┐ and to imperatives of the form ┌Socrates, have phi! ┐ Supposing that M is the actual semantics of “Socrates”,...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-328",
    "text": "Even though a token T of “was Socrates wise?” isn’t true or false, there is still some proposition P such that T is a success, in the relevant sense, exactly if P is true. As we discussed, T is a success exactly if the person to whom it is directed correctly affirms either that Socrates was wise or its negation. So the verbiage to the right of the “exactly if” in the last sentence picks out the appropriate value of P. Obvious adaptations of what we just said are true of all tokens of the form ┌…Socrates…┐, and not just of tokens of that form that are in the interrogative mood. And what we just said about “Socrates” is true of all utterances. This is not to say that all expressions refer. (In Chapter 22, we saw why, in light of an argument of Frege’s, it is not possible to maintain that expressions refer.) But it is to say that, given any meaningful expression e, e’s semantics is given by some proposition to the effect that, for any utterance T of the form ┌…e…┐, there is some proposition P such that T is a success exactly if P is true. No matter what views one has as to the semantics of “and” or “or” or case- or tense-markers, no one will deny that the semantics of such an expression is given in its entirety when it is said when it is appropriate to use sentences containing them. Supposing (what isn’t strictly true[282], but may serve as a convenient simplification) that a token of ┌P and Q┐ is true iff P is true and Q is true, then one knows everything there is to know about the semantics of “and”, it being irrelevant whether one also thinks (as Montague did) that “and” refers (to a function from pairs of sentences to truth-values) or whether one thinks (as the early Wittgenstein did) that it does not refer to anything. If two people agree as to whether the biconditional given a moment ago is correct, then they ipso facto agree as to the semantics of “and” – even though they may disagree as to the nature of what it is they are agreeing about. (Hilbert and Frege agreed that 7+5=12, even though they disagreed as to the nature of what it is that they are thereby agreeing about.) All of this may be...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-329",
    "text": "(*) There is a certain kind of success S such that E is a symbol of a public language (e.g. Urdu, English, Spanish) exactly if, given any token T of the form ┌…E…┐, there is some proposition P such that T has S exactly if P is true. For reasons already given, S is to be distinguished from monetary success, professional success, and any other garden-variety success. If (*) is even approximately right, then for something E to be a symbol of a public language is for it to be the case that E satisfies the following condition: given any utterance T of the form ┌…E….┐, there is some proposition P such that T has S exactly if P is true. Given that success and failure presuppose the existence of thought, it seems to follow that the existence of a thought is indeed a pre-requisite to that of anything having any significant resemblance to a symbol of a public language. This shows that if (*), or anything like it, is correct, then thought is prior to language, and that SCT is in fact guilty of the vicious regressiveness of which it is often accused.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-330",
    "text": "Before proceeding, I should make it clear what I do, and do not, hold. There is no doubt that (HB) is false. (For expository reasons, let us momentarily forget about the type-token distinction.) “Bob is at the store” is a complex expression. It means what it does because of what its components mean; it means Bob is at the store because of what is meant by “Bob”, “store”, “at”, and so on. So the reason that “Bob is at the store” means Bob is at the store is not that people agreed to let that particular expression have that particular meaning. But, right now, that is irrelevant. Here what I wish to ask is this: Leaving aside the question of whether it is true or even plausible, is (HB) circular? Is it characterized by the same kind of vicious circularity as (HM) and (HT)? My answer is “no.” But there are two reasons why many would say “yes.” Let us consider these before proceeding. The first reason is that the expression “linguistic” occurs in (HB). So far as (HB) seems circular, that has nothing to do with its content, and is strictly a matter of how it is formulated. First of all, there is no denying that some kind of pre-verbal communication exists. Within limits, including people, manage to make it clear to other creatures that they have certain intentions, feelings, and so on. When a dog growls at you, he is letting you know that you should back off. In general, language isn’t required for people to exchange certain pieces of information. Rather, language seems to be a way of extending the scope and precision of existing, non-verbal ways of communicating. As we just noted, the activity of exchanging information does exist among pre-verbal entities, albeit in an extremely modest form. That activity defines a unique field of endeavor: a sphere of conduct to which a special conception variety of success attaches. (Remember Aristotle’s point that, to each kind of endeavor, there corresponds a unique kind of success.) Let us refer to that sphere of conduct as SC. Given this, we remove the aforementioned circularity from (HB) by rephrasing it thus:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-331",
    "text": "Of course, (HB*) presupposes that our pre-linguistic ancestors – the ones who had no language before they themselves instituted it – are aware that SC exists. In other words, it presupposes that, at some level, they know there to exist among themselves an activity of exchanging information. But this is obviously a reasonable supposition; for it is not out of the question to suppose that pre-linguistic humans were intelligent enough to know that they had methods of communication. It is readily seen that (HB*) is not guilty of the just described circularity. But one might believe (HB), and also (HB*), to be guilty of another kind of circularity. It has been said that the very instituting of agreements presupposes language. If this is the case, then (HB) and (HB*) are indeed viciously circular. But given the points made a moment ago, it is hard to take this objection seriously. There is obviously non-linguistic communication. Obviously people sometimes make themselves understood non-verbally. In response to this, it might be said that such non-verbal understandings are parasitic on language. But it is implausible to hold that infants and non-human animals are categorically incapable of making themselves understood to one another. So, taken as an empirical point, the objection that all communication is linguistic seems to be false. As a counter-response, the objector might say that it is not an empirical, but an analytic point, that any exchange of information is linguistic. But if that is right, then any exchange of information is ipso facto linguistic, and the expression “linguistic communication” becomes a pleonasm, like “unmarried bachelor.” We’d then have to produce a new expression, e.g. “verbal behavior”, to distinguish between linguistic and non-linguistic behavior. But then all of the questions that we currently have in connection with the term “linguistic behavior” would re-arise in connection with the term “verbal behavior.” This shows that one is making a purely terminological point in saying that exchanges of information are necessarily linguistic. I will henceforth use term “linguistic behavior” to refer to the activity of expressing oneself through speech, writing, and the like, and will use the “non-linguistic behavior” to express oneself in other ways (e.g. by kicking over furniture, scowling, and the like). There is one last possible problem with our analysis: it presupposes that propositions can be grasped independently of language. For there to be understandings of the kind described by (HB) and...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-332",
    "text": "I am proposing that it is agreements among people that endow noises and ink-marks with linguistic meaning. Supposing this to be true, those agreements do not directly assign any meaning to whole sentences. They do so by way of agreements concerning the expressions that compose sentences – expressions like “Bob”, “store”, “at”, and “wet.” Here we confront an apparent problem for our analysis. Sub-sentential utterance don’t have success-conditions. Leaving aside cases where single words are merely elliptical formulations of complete sentences, there is no circumstance such that an utterance of “store” or “but” or “Fred” is a success (in the relevant sense) in that context. The concept of success, in the relevant sense, is inapplicable to utterances of “Fred” or “store.” The resolution of this difficulty is not hard to see, so long as we take into account the fact that expressions are to be defined contextually. This was point made by Frege (1884) and Russell (1905). And to solve our current problem, we need only generalize their insight. As we saw in Chapter 3, tokens of “Fred” refer to Fred exactly if, in virtue of having the form ┌Fred has phi┐, a sentence-token has for its meaning a proposition that is true exactly if Fred has phi. In other words, there is some x, such that x=Fred, and such that, in virtue of having the form ┌Fred has phi┐, a sentence-token encodes the singular proposition: x has phi. Put another way, occurrences of “Fred” refer to Fred exactly if, in virtue of having the form ┌…Fred…┐, a sentence-token encodes a proposition that has Fred as a constituent. (Right now we are going to consider only assertoric sentences. We will soon generalize what we say about such utterances to questions, imperatives, and so on.) In light of this, consider the following:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-333",
    "text": "(I said “noise (or ink-mark…)”, and not “expression”, because use of the term “expression” might have been viciously circular. For it seems that there can be bona fide expressions only in a context where there is already language.) What is the idea behind (F)? Consider the sentence “Fred is at the store.” As we’ve discussed, there is some x such that x=Fred and such that, from a strictly semantic viewpoint, an utterance of that sentence is a success exactly if x is as the store. Now consider the sentence “Fred is tall.” There is some x, such that x is identical with Fred, and such that an utterance of “Fred is tall” is a success, in the strictly linguistic sense, exactly of x is tall. Such examples can be generated ad libidum. Given these points, we may conclude the following. In virtue of having the form, ┌…Fred…┐, a sentence S encodes a piece of information P such that P has the form…Fred...and such that, the strictly semantic sense, S is a success exactly if P is true. So while utterances of “Fred” do not by themselves have success-conditions, whole sentences of the form ┌…Fred…┐ do have such conditions; and the semantics of “Fred” is given by giving the success-conditions of sentences falling into this category. So while it is true that no agreement among people directly gives meaning to “Fred is at the store”, and while it is also true that sub-sentential expressions do not have success-conditions, there is no reason to deny that sentence-level expressions are given meaning through agreements among people as to the success-conditions of whole sentences. “Fred” refers to Fred because of an agreement or understanding among people to the effect that, if a noise (or ink-mark…) has the form ┌…Fred…┐, there is some piece of information P such that P is about Fred and such that S is a success, in the relevant sense, exactly if P is true. (to echo what we said a moment ago: I said “noise (or ink-mark…)” instead of “sentence-token” since, in this context, use of the latter might have involved vicious circularity.) As we saw earlier, the relevant kind of success does not have to be understood in linguistic terms, and the relevant kind of agreement does not presuppose the existence of language. So in putting forth (F), we are guilty of no vicious circularity, and we are able...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-334",
    "text": "This objection muddles a subtle but crucial distinction. Given only that socratessnored means that Socrates snored, that socrateswastall means that Socrates was tall, and so on, it doesn’t follow that it is in virtue of having the form…socrates…that a noise makes a statement about Socrates. In other words, it doesn’t tell us that a noise’s making a statement about Socrates depends on its containing the sound socrates. It tells us that sounds of the form…socrates…have meanings that concern Socrates. But given only that those sounds to have those meanings, it doesn’t follow that it is in virtue of having the form…socrates…that those sounds have those meanings. Let L be a language that has three primitive symbols – namely, “socratessnored”, “socrateswastall”, and “socrateswaswise” -- whose meanings are, respectively, Socrates snored, Socrates snored, and Socrates was wise. Because they are semantically primitive, those sentences don’t have a semantic unit in common corresponding to the sound socrates. So it is not in virtue of the fact that they all contain that sound that they are all about Socrates. Of course, those sentences are semantically similar: after all, they are all about Socrates. And they are also acoustically similar: they all contain the noise socrates. But, as we just saw, it is not in virtue of their having that acoustical similarity that they have that semantic similarity. Their being similar in both respects is only a coincidence. (That is, it is a coincidence from a semantic point of view, though it may not be a coincidence from some other point of view.) If correct, the hypothesis under examination shows us why Grice’s story is compatible with the fact that socrateswastall means that Socrates was tall, with the fact that socrateswaswise means that Socrates was wise, and with the fact that socrateswasatthestore means that Socrates was at the store. But that hypothesis doesn’t show that the Gricean story is consistent with the one fact that is relevant in this context, namely: it is in virtue of the fact that it contains the sound socrates that a present-day utterance of “Socrates snored” makes a statement about Socrates. The hypothesis in question gives us the semantics of L, not of English. It gives us the semantics of a language all of whose expressions have English homonyms, but that isn’t English, the reason being that its sentences have completely different decompositions from their English counterparts. The word “why”...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-335",
    "text": "The relationship between “Fred” and Fred is not strictly parallel to the relationship between “wet” and the property of wetness. This point, or one like it, was made by Frege. The expression “the property of wetness” refers to the property of wetness. But “I sat on a wet chair” is meaningful and potentially true, whereas “I sat on a the property of wetness chair” is not meaningful or, therefore, potentially true. Our analysis, it might be said, models all semantic relations on the relationship between “Fred” and Fred and is thus in error. This objection is misguided. Our analysis is not to the effect that all semantic relations are to be understood in terms of the relationship between a singular term and its referent. I chose to illustrate my theory with discussions of singular terms. (For obvious reasons, that theory would have been much harder to take in if my initial illustrations had concerned adverbs or quantifiers.) The essence of our analysis is that semantic rules can be understood in terms of agreements to the effect that sentences having a certain property (e.g. the property of comprising “Fred” or “tall” or “or”) are ipso facto to have certain success-conditions. Obviously the specific agreements involved will vary from expression to expression, and also from expression-category to expression-category. But there is no difficulty extending what we said about singular terms to other kinds of expressions. In fact, our theory is especially well-suited to giving the semantics of expressions other than singular terms. Given any expression that is not a singular term, it is obvious that its meaning can be given only contextually. Conceivably, one might deny this, saying that “wet”, “tall”, and “intelligent refers to wetness, tallness, and intelligence. But that definition would be inadequate since it wouldn’t distinguish (for example) “wet” from “the property of wetness” – since, in other words, it wouldn’t provide the relevant syntactical information. So while it is true that our analysis demands that expressions be definable contextually, it is clear on independent grounds that expressions other than singular terms must be so defined, and we have seen that singular terms must be so defined. In fact, a slight generalization of a point made in Chapter 1 (p.15) provides an additional reason to hold that singular terms must be defined contextually. As we just saw, a definition is adequate only if it provides the syntactical properties of...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-336",
    "text": "A more substantive problem with our analysis has to do with the fact that it doesn’t apply to non-indicative sentences. But this problem is easily remedied. Non-assertoric utterances are, of course, neither true nor false. But, as we noted, given any such utterance S, there is some proposition P such that S is a xxx success, in the relevant sense, exactly if P is true. Suppose I ask you whether Smith went to the store. From a strictly linguistic standpoint, my speech-act is a success exactly if, upon hearing it (or otherwise encountering it), you correctly affirm either that Smith went to the store or its negation.[287] (For expository reasons, either pretend that you are Jones or substitute your actual name for each occurrence of “Jones” in the upcoming discussion.) So there is some proposition of the form…Smith…such that my utterance is a success exactly if that proposition is true. That proposition is not: Smith went to the store. Rather, that proposition is Jones correctly affirms whether or not Smith went to the store. Suppose that I order you to meet Smith at the store. From a strictly linguistic standpoint, my speech-act is a success exactly if, upon hearing it, you make it the case that you meet Smith at the store. So there is some proposition of the form…Smith…such that my utterance is a success exactly if that proposition is true. But that proposition is not: Jones meets Smith at the store. Rather, that proposition is Jones makes it the case that he meets Smith at the store.[288] Here is what this suggests. “Socrates” refers to Socrates exactly if, given an utterance S that has the form ┌…Socrates…┐, there is some proposition P having the form…Socrates…such that S is a success, in the relevant sense, exactly if P is true. The semantic rule that pairs off Socrates with “Socrates” is thus an understanding among people that assigns such success-conditions to utterances of that form. A book-length defense of this analysis is given in Kuczynski (2005c). What is important here is that, if this line of thought is even approximately correct, it follows that SCT is viciously circular. The reason, of course, is that such understandings presuppose the existence of thought and indeed, of specifically propositional thought. An advocate of SCT might counter-respond by saying that the representations mediating our thought are not assigned their meanings by rules of that...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-337",
    "text": "Conclusion Semantics isn’t pre-semantics. Content isn’t truth-maker. Data isn’t meta-data. In Part I, we found that, given these three distinctions, there are many reasons to reject content-externalism and many reasons to accept semantic externalism. Content externalism has some implausible consequences. It entails that one can rationally accept both a proposition and its negation; it strips the mental of causal powers; and it makes one’s knowledge of oneself as uncertain as one’s knowledge of the external world. We found that there is no reason to accept any of these highly revisionist views, since the relevant data can be accommodated without them. Advocates of content-externalism have attempted to reconcile that doctrine with our pre-theoretic views about self-knowledge and mental causation. But those attempts are failures. We found that Kripke’s argument for synthetic necessary truth involves a failure to distinguish between semantics and pre-semantics. We also found that a descriptivist conception of conception can be reconciled with the fact that, in at least some cases, having a concept of an object involves having a certain kind of causal connection to it. Our descriptivist conception of conception is incompatible with Fodor’s conceptual atomism. xxx But we found in Part II that atomism is false. Since atomism is false, so is SCT. Since SCT is false, so is CTM. We also found that, setting aside the erroneousness of conceptual atomism, there are good reasons to reject SCT and CTM. Two are of special note. First, in the arguments on behalf of CTM, the term “syntax” has at least three different meanings. Sometimes it refers to an expression’s morphology; sometimes it refers to its semantic decomposition; and sometimes it refers to its proof-theoretic relation to the semantic rules constituting the language of which it is a part. The expressions “form”, “algorithm”, and “mechanical procedure” are used in a comparably ambiguous manner. Many of the arguments for CTM collapse once these ambiguities are recognized. Second, supposing that Gareth Evans is right to distinguish between conceptual and non-conceptual content, it follows that not all mental content has a sentential structure. We found that Evans’ distinction is both defensible and theoretically fruitful. Content-externalism demands an acceptance of conceptual atomism and also of a strictly causal theory of conception. We have found that all three of these doctrines are false and that the relevant data can be modeled without them. Our model has the virtue of being entirely consistent with...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-338",
    "text": "Berkeley, George. 1934. An Essay Towards a New Theory of Vision. Oxford: Clarendon Press. Bilgrami, Akeel. 1992. “Can externalism be reconciled with self-knowledge?” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 323-341. Armonk, NY: M.E. Sharpe. Blackburn, Simon. 1984. Spreading the Word. Oxford: Clarendon.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-339",
    "text": "Brandom, Robert. 1998. Making it Explicit. Cambridge: Harvard University Press. Burge, Tyler. 1979. “Individualism and the Mental.” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 125-141. Armonk, NY: M.E. Sharpe. Tyler Burge. 1980. “Computer proof and a priori knowledge.” In Journal of Philosophy 77: 797-803 Burge, Tyler. 1982. “Other Bodies”. In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 142-160. Armonk, NY: M.E. Sharpe. Burge, Tyler. 1986. “Individualism and Self-knowledge”. In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 342-354. Armonk, NY: M.E. Sharpe. Cain, M.J. 2002. Fodor: Language, Mind and Philosophy. Cambridge: Polity Press.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-340",
    "text": "Coulter, Jeff. 1983. Rethinking Cognitive Theory. New York: St. Martin’s Press. Crane, Tim. 1991. “Social Content and Psychological Content.” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 284-304. Armonk, NY: M.E. Sharpe. Churchland, Paul. 1981. “Eliminative materialism and the propositoinal attitudes.” In D. Rosenthal (ed.), The Nature of Mind, 601-612. New York: Oxford University Press.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-341",
    "text": "Cresswell, Max. “Structured meanings.” In Meaning and Truth, J. Garfield and M. Kiteley (eds), 446-452. Davidson, Donald. 1967. “Truth and Meaning.” In The Philosophy of Language, A.P. Martinich (ed), 91-101. Oxford: Oxford University Press. Davidson, Donald. 1980. Essays on Actions and Events. New York: Oxford University Press.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-342",
    "text": "Davidson, Donald. 1980b. Inquiries into Truth and Interpretation. New York: Oxford University Press. Davidson, Donald. 1987. “Knowing One’s Own Mind.” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 323-341. Armonk, NY: M.E. Sharpe. Davidson, Donald. 2004. Problems of Rationality. New York: Oxford University Press. Davidson, Donald. 2005. Subjective, Intersubjective, Objective. New York: Oxford University Press. Dennett, Daniel. 1975. “Eliminative materialism and the propositoinal attitudes.” In In D. Rosenthal (ed.), The Nature of Mind, 502-507. New York: Oxford University Press.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-343",
    "text": "Fodor, Jerry. 1987. Psychosemantics. Cambridge: The MIT Press. Fodor, Jerry. 1987b. “Individualism and Supervenience.” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 192-218. Armonk, NY: M.E. Sharpe. Fodor, Jerry. 1990. A Theory of Content and Other Essays. Cambridge. The M.I.T. Press.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-344",
    "text": "Kaplan, David , 1975. “Dthat”. In The Philosophy of Language, A.P. Martinich (ed), 316-329. Oxford: Oxford University Press. Kaplan, David. 1975b. “How to Russell a Frege-Church.” Journal of Philosophy 72: 716-729. Kaplan, David. 1978. “On the Logic of Demonstratives.” Journal of Philosophical Logic 8: 81-98.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-345",
    "text": "Lepore, Ernie. 1994 “Conceptual Role Semantics.” In A Companion to the Philosophy of Mind, S. Guttenplan (ed), 193-200, 193-199. Blackwell: Cambridge, MA. Lewicki, Pawel and Hill, Thomas and Czyzewska, Maria. 1992. “Nonconscious acquisition of information.” American Psychologist 47 (6): 796-801. Lewis, Clarence Irving. 1946. An Analysis of Knowledge and Valuation. Cambridge: Harvard University Press.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-346",
    "text": "Lewis, David. 1984. On the Plurality of Worlds. Oxford: Blackwell. Loar, Brian. 1985. “Social Content and Psychological Content.” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 180-191. Armonk, NY: M.E. Sharpe. Loewer, Barry. 1999. ‘A Guide to Naturalizing Semantics.” In A Companion to the Philosophy of Language, B. Hale and C. Wright (eds), 108-126. Oxford: Blackwell.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-347",
    "text": "McGinn, Colin. 2002. The Making of a Philosopher. New York: Harper Collins. McKinsey, Michael. 1991. “Anti-individualism and privileged access.” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 355-361. Armonk, NY: M.E. Sharpe. Merricks, Trenton. 2001. Objects and Persons. New York: Oxford University Press.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-348",
    "text": "Montague, Richard. 1974. “The Proper Treatment of Quantification in Ordinary English.” In Formal Philosophy, Richard Thomason (ed). New Haven: Yale University Press. Moore, Robert. C. 1995. Logic and Representation. Palo Alto: CSLI Publications. Nagel, Ernest. 1962. The Structure of Science. Indianapolis: Hackett Neale, Stephen. 1990. Descriptions. Cambridge: The M.I.T. Press. Neri-Castañeda, Hector. 1989. Thinking, Language, and Experience. Minneapolis: University of Minnesota Press. Pap, Arthur. 1958. Semantics and Necessary Truth. New Haven: Yale University Press. Pap, Arthur. 1962. Introduction to the Philosophy of Science. New Haven: Yale University Press. Peacocke, Christopher. 1989. “Perceptual Content.” In Themes from Kaplan, J. Almog, J. Perry,, H. Wettstein (eds), 297-330. Oxford: Oxford University Press. Peacocke, Christopher. 1992. A Study of Concepts. Cambridge: MIT Press. Peacocke, Christopher. 1996. “Précis of A Study of Concepts.” In Concepts, E. Margolis and S. Laurence (eds), 335-338. Perry, John. 2000. The Problem of the Essential Indexical and Other Essays. Palo Alto: CSLI Publications.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-349",
    "text": "Platts, Marc. 1979. The Ways of Meaning. London: Routledge & Kegan Paul. Putnam, Hilary. 1975. “The Meaning of ‘Meaning’”. In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 1-52. Armonk, NY: M.E. Sharpe. Putnam, Hilary. 1996. “Introduction to The Twin-Earth Chronicles.” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), xv-xxii. Armonk, NY: M.E. Sharpe. Pylyshin, Zenon W. 1984. Computation and Cognition. Cambridge: The M.I.T. Press. Quine, W.V.O. 1951. “Two dogmas of empiricism.” In The Philosophy of Language, A.P. Martinich (ed), 26-39. Oxford: Oxford University Press. Quine, W.V.O. 1953. From a Logical Point of View. Cambridge: Harvard University Press. Quine, W.V.O. 1960. Word and Object. Cambridge: MIT Press. Quine, W.V.O. 1970. Philosophy of Logic. Cambridge: Harvard University Press. Recanati, François. 2004. Literal Meaning. Cambridge: Cambridge University Press. Rescorla, Michael. 2003. “Is Thought Explanatorily prior to Language?” Unpublished Dissertation. Department of Philosophy. Harvard University. Rey, George. 1996. “Resisting primitive compulsions.” In Concepts, E. Margolis and S. Laurence (eds), 339-343.. Richard, Mark. Propositional Attitudes. 1991. Cambridge: Cambridge University Press.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-350",
    "text": "[4] Stich (1978: 590-591) powerfully explains why it is not an option, even for the content-externalist, to say that Max and twin-Max are psychologically different. [5] McGinn holds that content-externalism is correct and that, consequently, one’s mind is spread out all over the cosmos. See McGinn (1986: 20-30). McGinn then argues that this consequence of content-externalism is innocuous since the mind is not a “substance.” It is extremely unclear what it means to say that the mind is not a “substance.” But what is clear is that there are representational mental events. Once this is granted, it follows that, if content-externalism is correct, your mind has long gone stars as veritable constituents. It follows that content-externalism is false, given that your mind came into existence only a few decades ago. [6] Matters are actually not quite as simple as this. Given only the just described differences between W and W*, it is still possible that they are dynamically different, even though kinematically they are the same. See Schlick (1919) and Reichenbach (1958). The thought-experiment has to be developed further to generate the result that Poincaré wants. But these subtleties are obviously not relevant here. [7] This is John McDowell’s position. See McDowell’s commentary on Chapter 6 of Evans’ Varieties of Reference (Evans 1982: 203-204).",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-351",
    "text": "[8] It is an open question in the philosophy of science whether there can be two different but equivalent ways of modeling the same data. [9] Loar (1985) is a soft content-externalist. So are Jackson and Pettit (2004b). Chalmers’ (1996) argument for dualism involves a version of soft content-externalism. [10] Fodor (1998). [11] Fodor (1990). [12] Sellars (1963) made a strong case for non-atomism. Non-atomism is now generally, but not universally, accepted. Bonjour (1985) discusses why non-atomist must be accepted. Fodor (1998) argues that it must be rejected. In Kuczynski (2003, 2004), I provide non-Sellarsian arguments for non-atomism. Elsewhere (Kuczynski 2007c), I have argued that a version of Sellars’ argument was given by Berkeley in A Theory of Vision and, in fact, that Berkeley’s version is superior to Sellars’. [13] This general line of thought lurks beneath the arguments found in Fodor (1990). But it is not explicitly stated there. Nor, to my knowledge, is it explicitly stated anywhere in the externalist (or, for the matter, the internalist) literature. [14] We will defend this claim in Chapters 13 and 14. But it is not a new or controversial claim. See Carnap (1937, 1956) and Gödel (1953). [15] Of course, spatiotemporal points and lines, and so forth, lack causal powers. But they are not occupants of space-time. Rather, they are sets of space-time coordinates. [16] See MacDowell’s commentary in Evans (1982: 203-204). [17] I am borrowing an argument given by Russell (1919: 165). [18] See Kim (1993: 339-367). [19] Stroud (2001) describes sense-perception as “predicative.” I am using this term in the same way as Stroud. [20]",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-352",
    "text": "See Fodor (1983) for a classic discussion of the “modular” nature of sense-perception. [22] Russell (1927: 94) makes a similar point when he writes: “Prejudice tells you that you see the same [Russell’s emphasis] table on two different occasions; you think that experience tells you this. If it really were experience, you could not be mistaken; yet a similar table may be substituted without altering the experience…there is nothing to show that one identical entity causes the two sensations.” See also Russell (1948: 271-294).",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-353",
    "text": "[26] The stock example of this is Meinong’s view that “the square circle” and “Pegasus” do refer to objects, albeit ones that “subsist” and do not “exist.” See Russell (1905). [27] See Soames (2001, 2005). [28] Kripke (1972: Lecture I). [29] Kripke (1972: Lecture II). [30] Kripke 1972: Lecture II. [31] Of course, one could say this:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-354",
    "text": "This position cannot be summarily dismissed; and I will not dismiss it. But, for our purposes, it is enough to note that the objector’s point seems quite false. Cases like the one just described are pervasive. There are many cases where no ostensive or descriptive definition is involved in our appropriation of a proper name. We hear the term being used and – presto! – can use it ourselves. If the objector’s point is correct, we are not really using any of these terms: we are merely mentioning them. When we produce sentences containing them, we are talking not about people, but about symbols denoting people. But this seems false. I have never been given a descriptive or ostensive definition of the term “Charlemagne.” But it certainly appears as though I can make statements about Charlemagne, and not just about “Charlemagne.” I am thus going to operate on the assumption that I can make statements about Charlemagne himself. [32] It is not guilty of the circularity that Kripke (1972) rightly ascribes to one of Russell’s theories concerning the semantics of proper names. [33] As we discussed earlier, words undergo phonetic degradation and alteration as they change hands. The first person who uses the word “Argo” might pronounce it one way; the people who “pick up” that name from that person might pronounce it differently. But this fact obviously doesn’t affect the principles governing appropriation of that word. Brown might pronounce “Argo” one way; Smith might pronounce it differently; you might pronounce it a third way; the people to whom you transmit this word might pronounce it a fourth way. After a few transmissions, what is left might bear little resemblance to Brown’s pronunciation. In some contexts, that fact is of importance. But that fact has no bearing on our point that, whenever somebody “picks up” a name – whenever they add it to their lexicon in manner (ii) – it is in virtue of their acquiring knowledge of a uniquely individuating description of the kind we have been describing. It is obvious how these points apply to names like “Socrates.” The word that Socrates’ own acquaintances used to refer to him was not “Socrates” (although that word probably had some phonetic similarities to “Socrates”). Nonetheless, however distorted “Socrates” may be relative to the word that the Ancient Greeks used, the principles governing the “picking up” of that word are the...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-355",
    "text": "[42] The point just made – that what is linguistically simple is seldom, if ever, what is actually simple, and that facts about language saddle us with some very wrong views about logic and metaphysics – is made very clearly by Russell himself in a number of places. For example, see Russell (1959: 238-245). [43] Merrick (2001) holds that people are ultimate constituents of the spatiotemporal world. Otherwise, his view is in close agreement with ours. If, like Merrick (and Plato and Bishop Butler), you believe that people are fundamental constituents of spatiotemporal reality, then replace my mention of “Socrates” with mention of an inanimate object. [44] See the previous footnote. [45] An argument very similar to this one is given by Andrzej Boguslawski (1994). Anticipations of some aspects of our argument are found in Recanati (2003). [46] Bach (1984). [47] For reasons that are not important in this context, (*) is only an approximately statement of the general rule for semantic descriptions. A less approximate statement of that rule is:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-356",
    "text": "[48] Of course, even a linguist’s knowledge of these rules is sub-personal. That is, the knowledge that enables the linguist to speak grammatically is sub-personal. In his capacity as a linguist, he may generate analogous knowledge at the personal level. But we are dealing with two different representations of the same (or analogous) information. We are not dealing with one instance of knowing, but with two. [49] See Kuczynski (2006d). [50] See Russell (1905) and Neale (1990). [51] There are other reasons for advocating Russell’s theory. These relate to issues having to do with variable-binding and anaphora. See Neale (1990). For reasons that I have given elsewhere (Kuczynski 2005c), I believe that these reasons for holding Russell’s theory are spurious. But a discussion of this would take us off our present course.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-357",
    "text": "[56] See Blackburn (1984: 308-310) and Neale (1990). In Kuczynski (2004) I discuss the viability of attempts to blame pragmatics for the apparent discrepancies between Russell’s theory and the data. [57] See Kuczynski (2004b, 2006d). [58] See Kuczynski (2004b, 2006d). [59] There is another problem Russell’s theory: it makes it more difficult than it would otherwise be to explain the obvious grammatical similarities between definite descriptions, on the one hand, and indexicals and proper names, on the other. Of course, Russell was acutely aware of the fact that, if his theory is correct, then the grammar of definite descriptions becomes very misleading as to what is actually meant by such utterances. He did not seem troubled by this consequence; and he seemed to hold that, in natural language, there was such a pervasive mismatch between grammatical and logical form that it didn’t redound to the discredit of his theory that 666 it put the grammatical properties of definite descriptions out of alignment with their semantic (or logical) properties. But it is a 666 controversial question whether semantic theories can embody such a deep disregard for grammatical facts. Jackendoff (1989) has argued compellingly that a sine qua non for a semantic theory’s correctness is that it have a certain consonance with grammatical facts. My own view is that Jackendoff is right. If we reject Jackendoff’s view, then (it seems to me) facts about grammar become free-wheels – wheels that turn independently (more or less) of semantics. But, it is not unreasonable to presume, grammatical facts are not entirely without semantic significance. In Kuczynski (2005c), I argue that grammatical facts are semantic facts, and that it is therefore self-contradictory to suppose that grammar might be independent of meaning. The basic idea is that the difference between “Smith sees Jones” and “Smith, the relation of seeing, Jones” is semantic and is also grammatical and that, consequently, we must suppose grammatical inflections to contribute material that connects the denotations of expressions. Grammatical material is connective semantic material. [60] In fact, Frege seems to have introduced this crucial notion to the study of semantics. [61] I actually think that they are truisms or tautologies. I have argued for this in Kuczynski (2005c). But we can leave that aside here. [62] Frege did not, at least not in this context, make any distinction between types and tokens. He did not distinguish between tokens of (2) and...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-358",
    "text": "The boldfacing is McCawley’s own. I don’t believe that McCawley’s definition is quite right. An utterance of “that man over there is bald” says that a certain member of a certain set (the set of men in a certain area) has a certain property (the property of being bald). So in virtue of having the form ┌…that man over there…┐ that sentence-token says which member of a certain set has a certain property, and thus qualifies as a quantifier according to McCawley’s definition. But, as Kaplan (1989) established, “that man over there” is not a quantifier. Nonetheless, McCawley’s is right to say that a quantifier is an expression that says how many members of a certain set have a certain property.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-359",
    "text": "[64] An argument very similar to this is given by Russell (1912). Barwise and Perry (1983, 1999) also present this argument, or one like it, in a clear and persuasive fashion; and, on the basis of this argument, they have made a powerful case for some significant semantic positions. But the philosophical community has been curiously unreceptive to their efforts. For example, Neale’s (2005) book Facing the Facts only references it in passing, even though it is clear that, if cogent, that argument is completely devastating to practically the entirety of Neale’s discussion. [65] McDowell (1998: Chapter 13) denies exactly this claim. But his justification for his rejection of this is predicated on the correctness of his extremely strong form of content-externalism. We have found reason to doubt whether any kind of content-externalism is correct, let alone McDowell’s extreme version of it. We will continue to find reasons to question content-externalism. [66] Kripke (1972: Lecture II). [67] Kripke (1972: Lecture II). [68] Before moving on, let us deal with one more criticism of our analysis: Contrary to what you say, the proposition meant by (1) is logically equivalent with:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-360",
    "text": "But there is a crucial respect in which (1*) and (2P) are not comparable. (1*) is equivalent with a singular proposition of the form: x is smart. (2 P) is not equivalent with any such proposition. The proposition meant by (1) can be collapsed into one that doesn’t involve the concept there is or is identical with. This is not true of the proposition meant by (2 P). Any perspicuous statement of its truth-conditions will involve such concepts. The same is true of (2), if indeed, Frege is right to hold that (2) and (2 P). So if Frege is right, (2) is (as we might put it) irreducibly equivalent with some quantified proposition, whereas (1) is only reducibly equivalent with such a proposition. [69] Davidson (1980b: Chapter 1) has ably argued that Frege’s position is incompatible with the fact that English (and other natural languages) learnable. Given how effectively Davidson presents his argument, I will not repeat it, and will merely refer to the reader to Davidson’s article. In Kuczynski (2005c), I deal with some of the objections that might be made to Davidson’s argument. [70] In any case, this is the traditional view. See Neale (1990). But, in actuality, what was just said is true only of indicative sentences containing definite descriptions. Given a sentence or imperative containing a definite description, Russell’s theory has the consequence that it is, on at least one disambiguation, ill-formed and thus without any coherent meaning. Neale (1990) considers only indicative sentences, and thus doesn’t confront this problem. In Kuczynski (2004d), I show that Russell’s theory wrongly predicts that any non-indicative sentence containing a definite description is ill-formed on at least one disambiguation. [71]",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-361",
    "text": "See Kripke (1977) for a classic discussion of why facts about cognitive significance shouldn’t be explained by positing semantic ambiguities if there is an available non-semantic explanation of those facts. [72] In any case, there is one, important disambiguation of the term “English” on which that language isn’t English. From a syntactician’s or phonetician’s standpoint, the two languages are not significantly different. But here we are doing semantics, not syntax or phonetics. In Chapter 16, we will discuss the various possible delineations of the term “English” and, thus, of “Chinese”, “French”, and so on. [73] McDowell (1998) says that Kripke’s arguments falsely presuppose that Russell’s and Frege’s views are ultimately the same. McDowell’s argument for this is tethered to his content-externalism, which we have seen to be false. In Chapter 7, we will discuss the underpinnings of McDowell’s claim at length. [74] The argument about to be given is found in Kripke (1972). But it is actually due to Quine (1953: 155). [75] See Kuczynski (2006d). [76] Much of what we just said is found in Boguslawski (1994).",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-362",
    "text": "Remember what we said earlier about “Julius” and “Newman I”. Unless one knows which individuals these terms refer to, one doesn’t know which propositions are encoded in “Julius was tall” and “Newman 1 will be a genius”; one has a simulated, but not an actual, understanding of what is meant by such sentences. One has knowledge of a description of the proposition that is encoded in such a sentence, but one doesn’t know which proposition is thus described. One knows that “Julius was tall” is true exactly if somebody x uniquely invented the zipper and x was tall. So it is clear that knowing who so and so is, and thus knowing the literal meanings of terms that refer to so and so, does not consist (merely) in knowing some uniquely individuating description that applies to so and so. What else is needed? The short, very approximate answer is: To identify is to re-identify. To know who so and so is, one must know of two existence-claims that are uniquely verified by so and so and, further, one must know that some one person uniquely verifies them. Suppose you meet Bob on Monday. Since you have just met him, there is a sense in which you don’t know who he is. If somebody asks you, “do you know who this is?”, you must say: “I am afraid I do not.” But, of course, in meeting him, you are uploading information that enables you to think about him – you are acquiring a concept of him. As we saw, this information is existential. Suppose that, a day later, you see Bob again. This time, there is a sense in which you know who you are seeing. As we saw earlier, your recognizing Bob consists in your knowing the truth of two existence claims of which he is the sole verifier, and in your also knowing that some one entity verifies both of them. That is the short answer to the question “what is it to know who somebody (or something) is?”. Here is the long answer. Identification is a contextual notion; it is always relative to some background question, or relative to some body of knowledge, that one knows, or fails to know, who somebody is. Suppose you have been living next door to Bob for years. You know very little about Bob. He doesn’t talk much. He politely waves at...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-363",
    "text": "[81] Except where a few scholars are concerned. But, even then, what is conscious is not the knowledge of which I am speaking. Rather, what is conscious is an analogue of that knowledge. When a cognitive scientist acquires conscious knowledge of the cognitive operations mediating between his retinal disturbances and his subsequent visual experiences, neither those operations, nor the knowledge they embody, become constituents of consciousness. Rather, they become objects of consciousness. In and of themselves, they no more become part of consciousness than the star which I am now seeing through my window. [82] See Searle (1983: 225-228) for a similar line of thought. [83] Alternatively, we would say that so far as x does have a concept of Smith, that concept is importantly different from his concept of something that x has personally seen or from which he was otherwise receiving information via some casual process (e.g. historical records, testimony, film). x’s concept of (say) his wife, or even of Socrates, has a robustness that his concept (if that word can even be used) of Smith lacks. [84] I repeat that, in this context, “conception” refers only to our conception of spatiotemporal entities – our concepts of abstracta are dealt with in Chapters 22 and 23.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-364",
    "text": "[85] Dretske (1982), Fodor (1990). [86] This is a point that pervades Evans (1982); and it is because of a reading of that work that I appreciate its significance. [87] See Kaplan (1989) for similar remarks. [88] Or, alternatively, that Jones’ concept is less robust than the concept Jones would have in virtue of knowing (*). [89] A similar line of thought is found in Frege (1918):",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-365",
    "text": "Kaplan (1989: 500-505) makes and develops this point. [90] His reasons for rejecting the photograph model are very different from ours. Evans seems to hold that, if the photograph model were correct, then one could exercise a given concept only in the context of a belief – and not in the context of a non-affirmative attitude towards a proposition (e.g. an attitude of questioning or supposing). See (Evans 1982: Chapter 3) and Grush (1999). The idea seems to be that my mental representation of a state of affairs just is a causal connection with that state of affairs, then I must always be mentally affirming the existence of that state of affairs, so long as my concept of it remains in existence. So far as it can express any kind of propositional attitude towards what it depicts, a photograph of a man on a horse can only affirm that there is a man on a horse. It cannot express a conditional proposition or a question or a supposition. This idea connects with independently corroborated and significant lines of thought. Freud (1965: 24) argued that visual imagery is incapable of expressing propositional attitudes other than mere affirmation:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-366",
    "text": "“The latent dream-thoughts are…transformed into a collection of sensory images and visual scenes. It is as they travel on this course that what seems to us so novel and so strange occurs to them. All the linguistic instruments by which we express the subtler relations of thought – the conjunctions and propositions, the changes in declension and conjugation – are dropped, because there are no means of representing them; just as in a primitive language without any grammar, only the raw material of thought is expressed and abstract terms are taken back to the concrete ones that are at their basis.” Because dreams are ideographic, as opposed to linguistic, means of representation, non-affirmative attitudes towards dreamt contents has to be expressed in highly indirect means. For example, an attitude of incredulity (“that would never happen: Lucille would never marry Bob”) has to be expressed by in some roundabout way (e.g. through an image of there being flying pigs or pink elephants at the marriage-ceremony). See Freud (1998: 346-366) for an extremely sophisticated discussion of the difficulties that are involved in giving a strictly pictorial representation to non-affirmative propositional attitudes. (This work of Freud’s was originally published in 1900.) More direct confirmation for Evans’ view is found in Rescorla (2003). Rescorla points out that you can’t form a “conditional map” by juxtaposing two maps. A juxtaposition of two maps doesn’t result in a single, complex representation: all that is left are 666 two semantically disconnected maps. So there is, as Rescorla says, no map-negation, map-conditionalization, and so on 666. Evans’ criticism thus seems to be a kind of extension of a criticism that, in private conversation with David Pears, I made of the “picture-theory” of thought advocated in the Tractatus. If a thought is just a picture or isomorph of the corresponding fact (or proposition), then how can one have conditional thoughts or negative thoughts? A purely pictorial language is thus a non-starter. (Egyptian hieroglyphs are not mere sequences of pictures; they are grammatically structured.) So Evans’ point has substance, as it point to a fundamental fact about ideation. (Purely visual – or, more generally, iconic – representation is fundamentally different from linguistic representation. Language can express a variety of different attitudes towards a different content, whereas iconic representation cannot.) But Evans doesn’t put his finger on what is fundamentally wrong with the photograph-model. What is fundamentally wrong with it is...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-367",
    "text": "But (^) doesn’t have any de re sense as a constituent. Further, to echo a point made a moment ago, (^) isn’t logically equivalent with the proposition that, according to Evans’ own stipulation, is meant by “Julius was tall.” More importantly, it is pretty clear that (^) isn’t what Evans had in mind. Also, if (^) were the meaning of “Julius was tall”, then “Julius” would be both a singular term – one that picks out x – and something that has a sense (unique zipper-inventor). But it would not have both of these properties by virtue of having a de re sense. It would have both those properties by being a device of singular reference and a quantifier. But these two roles wouldn’t fuse together into a de re sense. “Julius” would simply be an orthographically condensed representation of two entirely distinct functions. Of course, Evans didn’t think that (^) in particular was the meaning of “Julius was tall.” Nor did he believe that, if (^) were the meaning of that sentence, “Julius” would be of any particular theoretical interest. But what we said about (^) is true of any proposition that has both x and the concept unique zipper-inventor as constituents. Any such proposition will lack a de re sense. And if any such proposition is the meaning of “Julius was tall”, the result is not that “Julius” is a sense-bearing singular term – the result is not some kind of fusion of description with reference. Rather, the result is that “Julius” is a phonetically condensed way of encoding two quite separate semantic functions – reference and, separately from that, description – and fails to illustrate anything non-trivial concerning actual or possible languages. Let us sum up this preliminary argument. Evans wants to show that a kind of descriptive singular reference is possible, at least in principle. But he doesn’t show this. By his own stipulation, if P is the proposition meant by “Julius is tall”, P is true in a world w iff x is tall in w. So, with the irrelevant exceptions cited earlier, P isn’t logically equivalent with anything has the concept zipper-inventor (or even just zipper) as a component. If we stipulate that the meaning of “Julius is tall” does have that concept as a component, then “Julius” ends up either being a quantifier, contrary to Evans’ own stipulation, or it ends being a...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-368",
    "text": "[106] Wittgenstein (1958) seems to deny this, at least on one natural reading of his work. We will consider his views in Chapter 17. [107] This seems to be what Russell (1917: 152-167) says. That position also seems to be implicit in Frege’s (1892) view. [108] Of course, unless you are learning English as a second language, the second method is not going to be the one that is used. [109] In case this, this is what practically everyone believes. Wittgenstein (1958) famously denies it. In a moment, we will discuss why, in my view, Wittgenstein’s view is simply a muddle. [110] I think that (A) entails (B) and that, in fact, they are equivalent. If that is right, then (B) is technically redundant. But we needn’t investigate this subtlety here. [111] Freud made a good case that many of our propositional attitudes are unconscious. One can unconsciously hate (or love) someone 666. One can unconsciously yearn for a divorce or for the death of a good friend. Even though they are not denizens of consciousness, such attitudes often have pronounced effects on consciousness. Being expressions of attitudes that have no place within the structure of what we consciously believe about ourselves, special efforts on the subject’s part must be taken to reconcile those disturbances with his consciously held belief-system. Those efforts are what we refer to as rationalizations – spurious attempts to show that our conscious beliefs about ourselves are consistent with some occurrence that, in fact, is proof of their erroneousness. Once these rationalizations are constructed and thus come to have a place in consciousness, the conditions that an attitude must meet to be consistent with the contents of consciousness are even more stringent than before. After all, attitudes must now be consistent with those rationalizations, along with whatever was present in consciousness before they came along. So the existence of a 666 rationalization 666 tends to keep attitudes out of consciousness, and thus itself extends the very abridgments to self-knowledge that motivate them. The contents of the Freudian unconscious are basically of the same nature as the contents of consciousness. Those unconscious contents consist of loves, hates, yearnings, and so on. Further, those attitudes can become conscious. What was once an unconscious hatred of Smith can become a conscious hatred of him. So the contents of the Freudian unconscious are close to consciousness in two respects. First,...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-369",
    "text": "(i) and (ii) use the very same concepts, and they differ only in respect of the words they use to refer to X’s length. In general, MF and MY use the same concepts, and differ only in respect of the expressions they use to express those concepts. Not all differences between systems of measurement as trivial as the one just described. If the distance between x and y is small (but not too small), it can be measured in terms of how many rods of a given length are needed to connect x and y. But distances of considerable length, e.g. those between celestial bodies, cannot be measured with yard-sticks. For this reason, such distances must be measured in other ways, e.g. in terms of the amount of time it takes for light to travel from x to y. Here we are dealing with two genuinely different systems of measurement. But great care had to be taken to ensure that, where distances that can be measured in terms of either method are concerned, the measurements generated with the one system coincide with those generated with the other. Otherwise, the statement “the distance between the Earth and the Moon is over a thousand times greater than the distance between Santa Barbara and Los Angeles” would be meaningless. For exactly similar reasons, where moderate temperatures (such as those on the surface of the Earth) are concerned, the methods that are used to measure the temperature of a very hot body, such as the sun, must yield the same results as those generated by using a mercury-thermometer. Otherwise statements comparing the temperature of Santa Barbara with those on the surface of the Sun would be meaningless. Hempel (1952: 62-78, 1965: 123-134) cogently argues for these very points. For argument’s sake, suppose that there were no way of establishing a one-one correspondence between the amount of time needed for light to travel between two points and the number of times a meter-rod of a given length could be laid endwise XXX between those points. In that case, those two methods would measure different properties. Regardless of whether we use meter-rods or light beams, we can speak of length simpliciter only because empirical research has established that (within certain extremely narrow horizons) there is a one-one correspondence between statements reporting the results of the one method of measurement and statements reporting the results of the...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-370",
    "text": "Brown’s has provided a correct causal explanation of (PH). But how can this be, given that causes operate locally? Jackson and Pettit would say the following. Given (PH), it is guaranteed that (PA) is true; therefore (PH) gives a program-explanation of (PA)’s truth. But given obvious extensions of what we just said, the relationship between (PH) and (PA) isn’t comparable to the relationship between the peg is square and the peg won’t go into the hole. In the latter case, we have a state of affairs (the peg’s being square) which consists in various mass-energy displacements, which effectively cause some other state of affairs (the peg’s remaining in a certain place above the template with the hole in it, despite my pushing against the peg with all my might). We don’t have anything like this in the first case. After all, there is no state of affairs consisting in flames of equal intensities being put under the pans. Of course, the expression “the fact that flames of equal intensities were put under the pans” is not an empty one – it is not like “the king of France.” But that expression doesn’t denote a constituent of the spatiotemporal world; that expression thus isn’t like “the flame” or “the peg’s being square.” The real relationship between (PH) and (PA) is this. (PH) entails that, for some specific values of p1…pn, both of the following singular propositions are true:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-371",
    "text": "Notice that (F) describes a state of affairs (or event). Further, (F) describes what, given Jackson and Pettit’s own statements, must be described as a program-cause of P’s heating up by a certain amount. What is involved in this last fact? Among the constituents of the flame that is placed underneath P* are various events that effectively cause pan P to heat up by amount Q (by time t*). For exactly similar reasons, (F*) gives a program-cause of pan P*’s heating up by amount Q (by time t*); and this is because (F*) identifies a state of affairs (or event) among whose constituents are effective-causes of P*’s heating up by Q. Thus, given accepted principles of physics, (F) renders probable",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-372",
    "text": "Given that (FH) and (FH*) are both true, (PA) logically follows. Here two points deserve special mention. One is a point we have already emphasized, namely: neither (PA) nor (PH) describes a state of affairs. For reasons already discussed, that by itself makes it questionable whether we are dealing with anything comparable to the relationship between the squareness of the peg and the peg’s resistance to going into the hole. The other point is one we have not yet made. By Jackson and Pettit’s own lights – by their own explicit pronouncements – the fact that a flame with properties p1…pn is being placed beneath P programs for P’s heating up by a certain amount (after a certain interval). At the same time, Jackson and Pettit would also say that (PA) provides a program-explanation for (PH). Whether this constitutes vicious circularity is a question I will leave aside. But it seems clear that relationship between (PA) and (PH) is of a different logical-order from the relationship between P being put on a flame with certain properties and P’s subsequently heating up. The first relationship is given by a certain sequence of propositions, and the second is given by what is merely one small segment of that sequence. The first relationship has a very complicated structure. It starts with a generalization. It then transitions to two singular two singular propositions. From each of these singular propositions, it derives what is must be regarded as a program-explanation, given Jackson and Pettit’s own explicit statements. (So we are dealing with program-explanations embedded with what is supposedly a program-explanation.) From each of these two embedded program-explanations, it derives two cases explanation in terms of effective-causes. Finally, on the basis of these last two explanations, it logically derives another generalization. The embedded program-explanations obviously don’t have the same structure as the explanation of (PA) in terms of (PH). In fact, it seems that, on pain of vicious regressiveness, they couldn’t have that structure. (But, as I said before, I will not discuss this last point.) What is clear is that Jackson and Pettit have over-extended the term “program-cause” in using it to apply to both kinds of relationships. [130] This argument is similar to one made by Kripke (1982) and also to one made by Wittgenstein (1958). I will set aside the question whether it actually coincides with anything either of these authors said. See...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-373",
    "text": "Fodor (1981: 13-17, 226-227, 1987: 18-20, 1994: 294-298). [140] Fodor (1998: 13) writes: “For fear of circularity, I can’t both tell a computational story about inferences and tell an inferential story about what content is. Prima facie, at least, if I buy into Inferential Role Semantics, I undermine my theory of thinking.” [141] Fodor and Lepore (2002) write: “Inferentialism is prohibited from taking this route, since the inferentialist’s point in a nutshell is that meaning is a construct from inferential role, not the other way around.” [142] Kripke (1972), Fodor and Lepore (2002). [143] I believe that a version of this argument is found in Wittgenstein (1958) and (1983). [144] See Grice (1957) for a pithy discussion of the ambiguity of the word “meaning.” [145] Fodor (1981: 13-17, 1987: 18-20, 1990: 22, 1994: 294-298). [146] In any case, this is the philosophical conventional wisdom. It could be said that “Socrates snores” and “some man snores” are grammatically different and that it is only relative to a kind of “folk-grammar” – comparable to folk-physics or folk-medicine – that they have the same grammatical form. I believe that this is the conceit underlying Montague’s (1974) work. This general idea is validated by Chomsky’s work, since the latter shows how far “grammar” fails to reveal the true structure of natural-language sentences. I discuss this in Footnote 17 of Kuczynski (2006b). [147] This point is made clearly in Barwise and Perry (1999: 32-39) and Kaplan (1989: 508). [148] See Russell (1903: Chapter I) for a similar point. [149] Also, for reasons that cannot be discussed here, I don’t think that this objection can be accepted. So far as that objection is correct, it is because expressions “logical” and “formal” truth are used to refer to a number of different, non-equivalent notions, and are thus used in an incoherent manner. Given any coherent delineation of those terms, there is, for reasons outlined, no choice but to say that S’s being logico-formally true is identical with its being assigned truth by the semantic rules that assign it meaning. But it isn’t possible to go into this here. Nor is it necessary, since our argument against CTM goes through whether the objector is right or not.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-374",
    "text": "We’ve seen that a sentence’s syntax is bound up with its semantics: the former lies in how that sentence has the latter. So syntax is a meaning-involving affair. We can take my earlier statements to the effect that “syntax is an aspect of semantics” as an abbreviated way of saying this. It is readily seen that this will not have any negative effects on the arguments in which that statement figured, since those arguments depended on the thesis that syntax was an aspect of meaning – it being left open whether that aspect concerned the how, as opposed to the what, of meaning. So while I concede that, technically speaking, I have used the term “semantics” equivocally, the equivocation is merely terminological, and has no substantive bearing on any of our arguments. [153]",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-375",
    "text": "Of course, what counts as a “significant” proof-theoretic difference is a function of the dialectical context. This suggests that it probably isn’t possible to speak of the concept of syntactic structure, even if we confine ourselves to the logician’s disambiguation of the word “syntax.” Similar remarks hold in connection with the linguist’s disambiguation of that term. [154] Consider the following two scenarios. First scenario: nations A and B are engaged in a dispute. Jones, who is the dictator of nation A, responds by waging an all-out attack on B. The attack involves only foot-soldiers: no planes or long-range missiles are used. Second scenario: nations C and D are engaged in a dispute. Smith, who is the dictator of C, responds by waging on all-out attack on D. But Jones uses only long-range missiles: no foot-soldiers are involved. The question “how did Jones resolve the dispute between his nation and B?” may or may not receive the same answer as the question “how Smith Jones resolve the dispute between his nation and D?” A military strategist might say that those questions are to be given different answers, the reason being that, from his viewpoint, Smith and Jones behave in very different ways. (From a military strategist’s viewpoint, there is an important difference between using foot-soldiers and using long-range missiles.) But a psychologist might say that those questions are to be given the same answer, the reason being that, in every characterologically significant respect, Smith and Jones behaved in the same way. (Both used brute force instead of diplomacy or economic measures. The fact that one chose to use long-range missiles, while the other chose to use foot-soldiers, doesn’t indicate any fundamental difference in their characters.) Both linguists and mathematical logicians agree that syntax is meaning-how. But the question “how is (i) assigned the meaning that it has?” may or may not be given the same answer as the question “how is (ii) assigned the meaning that it has?” The linguist is interested in issues relating to learnability and mental representation; and from that viewpoint, these two questions are to given the same answer. The mathematician is interested in issues relating to provability; and from that viewpoint, those questions are to be given different answers. The linguist and the mathematical logician agree that syntax is meaning-how, even though, given the differences in their concerns, they operate with different contextualizations of that notion....",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-376",
    "text": "“The operations of the machine [on which I am modeling the human mind] consist entirely of transformations on symbols; in the course of performing these operations, the machine is sensitive solely to syntactic properties of the symbols; and the operations that the machine performs on the symbols are entirely confined to altering their shapes.” See also Fodor (1990: 22):",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-377",
    "text": "“You connect the causal properties of a symbol with its semantic properties via its syntax…To a first approximation, we can think of its syntactic structure as an abstract feature of its (geometrical or acoustic) shape [Fodor’s emphasis]. Because, to all intents and purposes, syntax reduces to shape [my emphasis], and because the shape of a symbol is a potential determinant of its causal role, it is fairly easy to see how there could be environments in which the causal role of a symbol correlates with its syntax. It’s easy, that is to say, to imagine symbol tokens interacting causally in virtue of [Fodor’s emphasis] their syntactic structures. The syntax of a symbol might determine the causes and effects of its tokenings in much the way that the geometry of a key determines which locks it will open. But, now, we know from modern logic that certain of the semantic relations among symbols can be, as it were, ‘mimicked’ by their syntactic relations; that, when seen from a very great distance, is what proof-theory is about. So, within certain famous limits, the semantic relation that holds between two symbols when the proposition expressed by the one is entailed by the proposition expressed by the other can be mimicked by syntactic relations in virtue of which one of the symbols is derivable from the other. We can therefore build machines which have, again within famous limits, the following property: The operations of the machine consist entirely in transformations of symbols; in the course of performing these operations, the machine is sensitive solely to syntactic properties of the symbols; and the operations that the machine performs on the symbols are entirely confined to altering their shapes.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-378",
    "text": "Yet the machine is so devised that it will transform one symbol into another if and only if the propositions expressed by the symbols that are so transformed stand in certain semantic relations – e.g. the relation that the premises bear to the conclusion in a valid argument. Such machines – computers, of course, -- just are [Fodor’s emphasis] environments in which the syntax of a symbol determines its causal role in a way that respects its content. This is, I think, a pretty terrific idea; not least because it works.” Fodor (1981: 226) writes.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-379",
    "text": "[158] Chomsky (1959) provides a cogent argument against a doctrine that is called “behaviorism.” But it is not exactly the kind of behaviorism that Fodor is arguing against. Chomsky’s argument is concerned with behavioristic theories of language-learning, i.e. with views according to which language-learning is a matter of being behaviorally conditioned to have certain verbal responses in response to certain situations. Fodor is concerned with the view that for somebody to have a mental state of type X is simply for that person to behave in certain ways or, at any rate, to have a disposition to so behave. These doctrines are obviously similar; and I believe that some of the criticisms that Chomsky makes of the one kind of behaviorism can be adapted to apply to apply to the other kind. But the kind of behaviorism that Chomsky is attacking isn’t necessarily committed to the view that all mental states are nothing but dispositions towards certain behaviors. An advocate of that view could hold that, for example, affective states (states of pleasure or pain) are not dispositions of that kind. [159] I would like to propose a psychological hypothesis as to why it is so widely held that thought can be mechanized. As we discussed in Chapter 1, our intuitions often ascribe too much to our sense-perceptions. We confuse data with meta-data. We confuse what we see with what we learn on the basis of what we see. We see a series of innocuous discolorations on a piece of paper or computer-screen. We happen to know a great deal about the socio-psychological conditions that gave rise to those discolorations and into which those discolorations are subsequently re-assimilated. Because of our tendency to confuse perceptual with meta-perceptual data, we end up saying about those discolorations what should really be reserved for those socio-psychological conditions. [160] Stich (1983: 79-81) sets forth a similar argument.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-380",
    "text": "[161] This brings us to another problem with attempts to understand psychological concepts in terms of the Ramsey-sentence. Such attempts explicitly liken psychological terms to theoretical terms. Of course, some psychological terms (e.g. “reaction formation”, “counter-cathexis”, “depth grammar”) are theoretical. But some (e.g. “tickle”, “feeling of sadness”) are not. The advocate of (AF) is quite right to say that, for a theoretical term to have meaning, it must have some links, however circuitous and theory-mediated, with non-theoretical phenomena; and it may (or may not: see below) follow from this that the meaning of a theoretical term (e.g. “electron”) is at least partially given by sentences linking the truth-values of sentences of the form “…electron…” with sentences describing non-theoretical (observable) states of affairs But it does not follow that the same is true of psychological terms. Obviously pain, tickles, and other psychological phenomena have behavioral expressions. But it is decidedly implausible to suppose that the sentences giving these linkages are constitutive of the meanings of terms like “pain”, “tickle”, and the like. (Wittgenstein disagrees. We will deal with this position in a moment.) I believe that, so far as philosophers have thought otherwise, it is because they were confusing the term “observable” with the term “publicly observable”, and were then equating the latter with the term “non-theoretical.” Your pains are not theoretical entities, at least not from your viewpoint. Further, your pains are observable – they are observable to you, though not to me. (Of course, you don’t observe them in the sense that you sense-perceive them. But you observe them in the sense that their existence is made directly known to you, at least in so far as anything is directly known to anyone.) These facts, by themselves, call into question (AF)’s categorical assimilation of psychological to theoretical terms. Most importantly, even though your pains and tickles are known to me only through hypothesis, and are therefore theoretical from my viewpoint, it doesn’t follow that the terms “tickle”, “pain”, and “sadness” are theoretical terms. Obviously they are not; “pain” is as non-theoretical a term as we’ll ever find. So the advocate of (AF) is simply wrong to say that, in order to have empirical significance, statements containing terms like “tickle” and “pain” must be linked with sentences referring to publicly observable facts. In any case, he is wrong to say this in so far as his grounds for it lie...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-381",
    "text": "Wittgenstein’s view involves a failure to distinguish between meaning-fixing and reference-giving and, therewith, to register the ambiguities of scope concealed in statements like (*). Much of what we just said about beliefs, and mental states generally, is true of all attempts to “Ramsify out” out theoretical terms. Here we must consider an argument given by Hempel (1965: 204-205). So far as its meaning can be given through the procedure that Ramsey and Lewis describe, the term “electron” is ends up being frozen. Every sentence containing the term “electron” now countenanced by physical science becomes constitutive of the meaning of that term, and is thus as incapable as any other tautology of being refuted by scientific progress. One might counter-respond by saying that the Ramsey-sentence is meant only to fix the referent of “electron”, not to give its meaning. But in that case, the idea that theoretical terms can be “Ramsified out” reduces to the triviality that observation terms help people to know what is meant by theoretical terms. A few pages back, we distinguished three different meanings of the word “proof”, and we argued that CTM involves a conflation of these meanings. The word “derivation” has three different meanings, and these correspond to the different meanings of the word “proof.” A “derivation” can be an abstract object: a relationship between two sentences. It can be the mental act of discovering such a structure. Finally, it can be the act of writing down or otherwise communicating such a discovery. Obviously overt behaviors can be effects of one’s having the relevant knowledge, and they are often partial causes of one’s having such knowledge. But under no circumstances are they constitutive of it. So far as it seems reasonable to think otherwise, that is because we are confusing the communication of a cognitive accomplishment with the accomplishment itself.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-382",
    "text": "[162] See Searle (1984) for a similar line of thought. [163] In his novel The Stand, Stephen King describes a situation where the government collapses and dollar bills become (as King himself puts it) “as worthless as Monopoly money.” I am borrowing his apt expression. [164] To simplify discussion, let us set aside all of the legal niceties relating to the authentication of duplicates of contracts. [165] This point is powerfully defended in Wittgenstein (1958).",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-383",
    "text": "[166] This is borrowed from Fodor and Pylyshin (1988: 35). [167] See Kuczynski (2002, 2005) for a detailed discussion of these reasons. See Russell (1950: 371) for a pithy and lucid discussion of some those reasons. [168] This is the position taken by Fodor (1975) and Lycan (1984: 237) in response to the regress-argument just given. [169] See Lycan (1984: 247), Kuczynski (2002, 2004d). [170] Fodor, private correspondence. The capitalizations are Fodor’s own. [171] See, for example, Fodor (1987: 18-20). See also Cain (2002: 135). [172] Incidentally, this line of thought suggests a certain approach to an old metaphysical question. It is often asked whether objects – rocks, trees, people, and so forth -- have essential properties. Is there such a thing as the essence of the rock or the essence of your friend Smith? The question would seem to be ill-formed, given that it is not objects, but states of affairs, that are causally and explanatorily important. When we talk about “essences” and “essential properties”, we are presumably referring to things that have some kind of causal or explanatory significance. As we’ve seen, Smith is a non-entity, as far as explanation and causation are concerned. What is not a non-entity is Smith’s having a million dollars or Smith’s resenting you for your good looks. Obviously it is essential to Smith’s having those properties that he have certain other properties. One does not just have a million dollars. One’s having a million dollars supervenes on one’s having various other properties -- for example, one has bits of green paper in a brief-case under one’s bed, where those bits of green paper play a certain role in the society of which one is a part. So Smith’s having a million dollars does have an essence. The same is true of Smith’s resenting you for your looks. But it doesn’t follow that Smith has an essence. And to the extent that essences are supposed to be explanatorily significant entities, it isn’t clear how he, as opposed to his having this or that property, could have an essence.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-384",
    "text": "[173] Strictly speaking, it isn’t quite right to say without qualification of that inscription that it is physically complex. Whether it is complex, and if so how, is a function of the explanatory context. But we needn’t pursue this. [174] Fodor (1998: Chapter 4). [175] Let us address a possible objection to our argument:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-385",
    "text": "[176] See, for example, Carnap (1966). [177] It is similar to an objection that George Rey (1996) makes of Peacocke’s (1992, 1996) analysis of conception. [178] Or, more likely, it refers to some kind of idealization of this information. As we discussed, the information through which one computes the meaning of tokens of “Hesperus”, and thus of sentence-tokens containing that term, varies from person to person. No two people will learn what is meant by “Hesperus” in quite the same way. Given any two people to whom that term is defined ostensively, their respective optical relations to Hesperus will probably not be exactly the same; and the same is true of any two people to whom it is defined indirectly or non-ostensively. So far as there is one “concepto of Hesperus” – i.e. so far as the term “the concepto of Hesperus” is not an improper, and thus non-referring, definite description -- that term seems to refer to some concepto that abstracts from all of these person-to-person variations, leaving only some core concepto like unique last body to disappear from the morning sky, or some such. (Of course, this is exactly what Frege and Russell, and all pre-Kripke semanticists, would have identified as “the concepto of Hesperus.”) What is important here is that if by “the concepto of Hesperus” one means the information through which people think about Hesperus – or, more exactly, through which they compute the semantics of occurrences of expressions like T – then the concepto of Hesperus is by no means conceptuallyo simple, as it consists of the conceptso morning, luminescent, and so on. [179] Dummett (1973: Chapter 17) presents a similar argument. [180] This was the thesis of my doctoral dissertation.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-386",
    "text": "[181] Wittgenstein (1975) deserves credit for making this point. In Kuczynski (2006) I discuss why, in my judgment, Wittgenstein’s insight warrants a non-atomistic conception of conception [182] An argument similar to the one just given is found in Dummett (1978: Chapter 22). [183] See Hempel (1965: 123-134). [184] Fodor (1998: Chapter 3). [185] A similar point is urged by Evans (1982). [186] This is a point that Berkeley made long ago in his A Treatise Concerning the Principles of Human Knowledge. [187] Incidentally, this discussion doesn’t presuppose a Lockean-empiricist conception of conception. (Fodor 1981 has done an admirably good job of showing why such a conception is untenable.) It could well be that it is in virtue of our innate cognitive endowment that we human beings are able to hone in on the property that is had in common by all and only those situations that instantiate the property of redness. It could be that experience has only a “triggering” role in our grasping this concepto. But that is of no importance in this context. What is important is that, however it is that we come to grasp that concepto, doing so involves our seeing what different situations have in common.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-387",
    "text": "[188] See Langford (1942). This conception of conceptualo analysis pervades the view advocated in Fodor (1998), as I discuss in my article “Another argument against the thesis that there is a language of thought” (Kuczynski 2004). [189] In light of the points made in this section, a case can be made that Fodor’s first argument for atomism is question-begging. Fodor starts with the assumption that there is analytic structure only where there is the possibility of a biconditional of the kind just mentioned. This is tantamount to the assumption that, for any concepto C, there is some set of conceptso C1…Cn such that x falls under C iff x falls under C1…Cn is analytically true and non-trivial. Assuming that those conceptso don’t have infinitely complex decompositions, we sooner or later arrive at a set of conceptso that are not decomposable. And from this it follows that there is some set of simple and unanalyzable conceptso out of which all other conceptso are composed. It is hard to believe that there is a set of conceptso of the kind just described. It is also hard to believe that any given concepto has an infinitely complex conceptual decomposition. Given how implausible both of these views are, it seems reasonable to seek alternatives to the assumptions that led to them. In this case, such alternatives are not hard to find. We reject Fodor’s assumption that conceptualo analyses give the decompositions of conceptso, and we say that such an analysis identifies different ways of conceptualizing a single content. Given that there different, but equally adequate analyses of many conceptso, this is a position we would wish to take anyway. Leaving aside the – in this context – question-begging belief that conceptso are either analytically unstructured or decompose into analytically unstructured conceptso, it becomes unclear what reason there could be for holding onto the view that analyzing a concepto consists in showing how it decomposes into other conceptso. Basically, Fodor’s conception of analysis has such counter-intuitive consequences that one would hold onto it only if one had a pre-existing wish to validate those very consequences. To this extent, Fodor’s first argument for atomism is question-begging. [190] Astonishingly, this position has been taken. It has often been said that what we know cannot exceed what we can say. See Blackburn (1984: 140) for a discussion of this problem. [191] Of course, some musical dictionaries contain a...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-388",
    "text": "[193] Churchland (1981) argues for this point very effectively. [194] See, for example, Lewicki et al. (1992). [195] That said, there seem to be at least some instances of innate (and thus “instinctive”) declarative knowledge. The stock example is that infants know that breasts provide milk. Whether this is a bona fide case of declarative knowledge is a question that lies outside the scope of the present work. [196] See Lewicki et al. (1992).",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-389",
    "text": "[197] Many philosophers – e.g. Hacker and Baker (1984) -- ridicule the idea that abilities – e.g. the ability to speak English or ride a bicycle – involve sub-personal knowledge of conceptso like NP-deletion. So far as this scorn is not based merely on the view that such views simply must be false, given how at variance they are with common-sense, they are generally based on arguments found in Wittgenstein and, to a lesser extent, in Searle. We will consider those arguments in the next chapter. It should be pointed out that Fodor (1975) does a superb job of diminishing the plausibility of the common-sense-based rejection of sub-personal cognition by showing how the details of theories that posit such cognition are extremely well-supported by experimental evidence. [198] See Fodor (1975). [199] Fodor (1998: Chapter 2).",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-390",
    "text": "[200] Actually, given the points made in Chapter 9, it isn’t clear whether this much agreement is necessary. What is necessary that, for some x such that x=2, you accept some sentence whose truth-maker (not content) has the form x has phi and that I accept some sentence – not necessarily the same as yours – satisfying the same condition. [201] I say “more or less like”, and not “identical with”, in acknowledgement of the fact that, for reasons we’ve discussed, the passage of time demands that the indexicals in the sentences expressing one’s concept change so as to reflect changes in one’s spatiotemporal relation to the object in question. So, for example, if (6) gives my concept of Socrates on Monday, then on Tuesday, the sentence expressing that concept will contain the word “yesterday” in the place where, on Monday, the corresponding sentence contained the word “now.” [202] IRA is an extremely popular doctrine. It is advocated by Sellars (1963), Peacocke (1992, 1996), and Brandom (1998), to name but a few of its exponents. Brandom (1998: 94--97) argues that Frege held an inferential conception of propositional content. In defense of this, Brandom (1998: 94) cites the following passage from Frege:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-391",
    "text": "[203] Of course, it isn’t always clear what counts as a viable permutation of the concepts composing a given thought, and this makes it unclear whether our thinking is unlimitedly systematic. Is the thought the property of being loving is ambivalent towards Bob’s ambivalence towards Mary a viable permutation of Bob is ambivalent towards Mary and Mary loves Ted? If it is, then there seem to be some limitations as to how systematic thought is, given that one can probably grasp the second proposition without grasping the first. But, first of all, this objection may fail to take into account the distinction between performance and competence. Second, and more importantly, given our purposes, it is enough that thought be approximately systematic and that we have an approximate understanding of what involves. Delicate issues like the ones just raised needn’t be resolved. [204] My use of the term “module” is not necessarily meant to correspond precisely to what that term has come to mean in cognitive psychology. (So I am not using that term in the sense in which it is used in, for example, Fodor 1983.) I am using that term in a more generic sense. [205] See Churchland (1981). [206] Searle (1992: 212-214). [207] Of course, this view is due to Hume. It is now extremely unpopular in philosophical circles. (See Merrick (2001: 122). Merrick points out that Strawson (1959: Chapter 3), Shoemaker (1997: 139), and Lowe (1989, 1996: 25 ff.) are also opponents of the Humean view.) This is probably because it is generally interpreted more narrowly than I am interpreting it. But a rejection of it seems to involve the idea that there is something beneath various property instances. Even if there are such things, they don’t do any work, except in so far as they instantiate the relevant properties. But in that case, as we just said, it is really the property-instances that are doing the work. Also we must distinguish the question “what is it for two thoughts to belong to the same mind?” from the question “what is personal identity, i.e. under what circumstance are two events or states of affairs constitutive of the same person?” The Humean view that selves are mere “bundles” of thoughts and perceptions is vulnerable to non-trivial criticisms. In general, psychological conceptions of personal identity, such as Hume’s, are deeply problematic; and, at least arguably, should be replaced by...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-392",
    "text": "[208] This is exactly the position that Russell (1940: 226-235) took. I am not claiming any originality here. [209] Of course, it is not the case that, given any two thoughts T and T* had by a single person, the one R-causes the other. First of all, there are simultaneous thoughts, and simultaneous thoughts obviously don’t generate one another; second, there are thoughts T1 and Tn that belong to the same mind such that T1 doesn’t R-cause Tn, even though, for each i (1≤i≤n), Ti R-causes Ti+1; and, finally, there are non-simultaneous thoughts T1 and Tn such that the condition just met is not fulfilled. (What I am saying borrows heavily from Russell (1940: 226-235), and my use of the term “R-connected” is obviously an echo of his term “R-sequence.”) Given any two thoughts T1 and Tn, let us say that they are R-connected iff for each i (1≤i≤n), Ti R-causes Ti+1. Given this, two thoughts belong to the same person iff there is some thought Tm such that both are R-connected to Tm (it doesn’t matter what direction the connecting goes in). Here is an illustration. I think grass is green at time t. A moment later, I think I want milk. There is no special connection between these two occurrences. But there would be no difficulty finding a thought Tm such that both of these thoughts were R-connected to Tm. Tm might be a memory that I had thought grass is green and then subsequently wanted milk. Here some might make the following objection to our analysis:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-393",
    "text": "No. As we’ve discussed, different modules of a person interact. Of course, by definition, information doesn’t flow as freely between modules as it does within molecules. But they do exchange information. (In any case, there would be no reason to posit their existence if they didn’t.) The information in my visual module obviously interacts with the information in my language module (I am supposing, for expository reasons, that there is a single visual module and a single language module). If those modules didn’t interact, then I couldn’t read and I couldn’t say anything, at least not anything worth saying (I couldn’t say, upon seeing a fire, “call the fire-department!”). Further, the way in which information is exchanged between those two modules is obviously vastly more direct than the way in which information is exchanged between two different people. The difference between intra- and inter-personal communication is that in the former case the flow of information is mediated by relatively directly connected neural (and cognitive) pathways, whereas in the latter case the transmission of information involves neurally and cognitively “dead” intermediaries (inanimate sounds, ink-marks, and so forth). The difference, in other words, lies in the mode of causation. In the one case, causation is relatively direct. In the other case, it is not. The difference does have anything to do with the fact that, in the one case, there is some one underlying entity that “has” both sets of thoughts, whereas in the other case, the sets of thoughts are had by two such mysterious entities. It is true, of course, that one person is involved in the one case, and that two people are involved in the other. But what this, in its turn, consists in is a different in the causal mechanisms involved, not in anything having to do with the involvement of a mysterious, unpropertied cognitive substrate. What about cases of split personality? So far as such cases really do involve a complete separation of two systems of thought from one another – so far as there really is no cognitive communication at all between Jekyll and Hyde – we are dealing with two people who happen to share a body. (Of course, in this context, the term “communication” is meant to refer to communication of the intra-personal type described a moment ago. Obviously if those two systems communicate in the way in which two different people communicate...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-394",
    "text": "Let us start with a comparison. Simultaneous events cannot affect each other. But non-simultaneous events can stand in this relation – indeed, they must. More exactly, events E and E* are non-simultaneous if there is a (nomically possible) causal sequence beginning with one of them and ending with the other, and simultaneous otherwise. Of course, our awareness of this principle was triggered by empirical developments in physics (in particular, by the astonishing discovery that the speed of light is framework-invariant). But is it itself an empirical proposition? Can we imagine two non-simultaneous, but spatiotemporally related events E and E* that are necessarily completely causally isolated from each other? It seems not. It seems that being in the same “causal space” is constitutive of spatiotemporal relatedness. That may or may not mean that non-simultaneous events must be connected by some actual causal sequence. (In my view, it does mean that. Causal connections consist in disruptions of fields of energy. They do not, contrary to what Hume seemed to believe, consist in sequences of discrete events. A field’s intensity decreases continuously, and never reaches zero. It follows that any two non-simultaneous events are in fact causally connected. Reichenbach (1958) gave what I believe to be a completely cogent argument to the effect that spatio-temporal order is to be defined in terms of causality. We must also remember Schlick’s (1919) point that, given a field-conception of causality, what we would ordinarily described as the location of an event is better described as the location of the center of that event. Here, of course, the word “center” has both a geographic and a temporal meaning. Given what we said a moment ago, there is no part of the universe that isn’t involved in a disruption of a field. So a field-conception demands that every event be seen as being spread out through all of space-time. It follows vacuously that any two events occupy the same region of space-time. But the center of one event, i.e. the region of space-time where the disruption is greatest, may not coincide with the center of some other event.) Similarly, if two thoughts are to belong to the same person, they must belong to the same “R-causal space.” Maybe the objector is right; maybe two non-simultaneous co-personal thoughts don’t have to be connected by an actual R-sequence. But given what we’ve said, it seems not unreasonable to say that...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-395",
    "text": "[210] Searle (1992: 187-190, 227-254). [211] In my view, aptitudes – e.g. the ability to play the piano – are expressions of sub-personal conception. But this is a debatable point, and I won’t insist on it here. I provide some argument for it at the end of Chapter 16. Chomsky’s work can be seen as an attempt to show that our knowledge of language expresses sub-personal knowledge of various rules, and thus expresses a sub-personal grasp of various concepts. (I am now in the process of trying to show that this attempt on Chomsky’s part does not have the shortcoming that are sometimes ascribed to it.)",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-396",
    "text": "[212] In the movie Rain Man, Dustin Hoffman plays an idiot savant (named “Raymond”) who can do extraordinarily difficult math problems, but is totally incapable of the most rudimentary applications of that knowledge. If asked “what is 87,067 divided by 546?”, he can instantly come up with the answer. But he draws a blank if asked “if Bob has one house, and Larry has two houses, how many houses do they have altogether?” To my limited knowledge, that movie is clinically accurate. How do cases such as this one bear on Evans’ point that concepts are not frozen – that a genuine understanding of (say) addition or anything else is not going to be expressed in just one way? I would suggest that what is going on is as follows. A grasp of the concepts of addition, multiplication, and so on, is present at one stratum of Raymond’s mind. Further, that knowledge is not frozen with respect to the other contents of that stratum of cognition. But even though it is unfrozen vis-à-vis the other concepts in the stratum just mentioned, that knowledge is frozen vis-à-vis the contents of other strata of cognition. In particular, that knowledge can interact only to a limited degree with the contents of the personal stratum of cognition. The mind is divided into different modules. (In any case, this is what Fodor (1983) asserts, and I find his arguments compelling.) Those modules communicate. But the amount of communication between modules is miniscule compared to the amount of communication within a module. So a piece of knowledge may be frozen vis-à-vis the bodies of knowledge that don’t belong to the same module as that knowledge. But no piece of knowledge is frozen vis-à-vis the body of knowledge that does belong to the same module as that knowledge. In any case, this is not an entirely unreasonable conjecture. And if it is correct, it is consistent with Evans’ contention that it is of the very nature of knowledge that it not be frozen. [213] This point is clearly articulated and powerfully argued in Hacker (1999: 52-55). Hacker plausibly attributes it to Wittgenstein. [214] This is the title of one of the chapters of Searle (1992). [215] A similar argument is found in Chomsky (1998: 166-224). [216] Baker and Hacker usually work together. Their books are usually co-authored. [217] My reconstructions of Wittgenstein’s arguments owe much to Kripke’s...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-397",
    "text": "[222] See my article “Can one grasp propositions without knowing a language?” (Kuczynski 2005b) for an argument similar to that just given. [223] For example, see Dennett (1978: 39-52, 90-108). [224] See Fodor (1975).",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-398",
    "text": "[225] See Brandom (1998). [226] See Kripke (1982). [227] The Rule-following argument is given in Wittgenstein (1958: §§ 138-238, 1983: §§ 5-111). Before we present Wittgenstein’s argument (or, in any case, my reconstruction of it), a preliminary point is in order. There are different kinds of rules. The function F(x)=x2 can be described as a “rule”, and the same is true of the law requiring one to stop one’s vehicle at certain kinds of signs (red, hexagonal signs on street-corners, with the word STOP on them). The second describes an obligation, and thus has a normative component. The first has no such component and merely describes an abstract pairing of numbers. These two “rules” are thus in very different categories. In fact, given that it applies to such different things, the word “rule” is arguably ambiguous. In his rule-following argument, Wittgenstein appears not to clearly distinguish rules like F(x)=x2 from rules like you must stop at stop-signs. In fact, it seems as though part of what he is arguing is that there is no distinction – that the first class of rules is a sub-set of the second. Wittgenstein sometimes seems to be saying that rules of the first kind are ultimately social rules, and are thus in the same category as rules of the second kind. In any case, in keeping with Wittgenstein’s own usage, we will use the word “rule” indiscriminately in our reconstruction of Wittgenstein’s argument, and will not worry about any pluralities of meaning that might characterize it. [228] This argument is found in Searle (1992: Chapter 7). Freud (1915: 116-121) considers that very argument, and provides counter-arguments that are at least prima facie compelling. Searle acknowledges those arguments, but dismisses them summarily. [229] Incidentally, Wittgenstein (1980, 1980b) said that Freud wasn’t producing a substantive theory, and that he was really only suggesting that we play a new “language game” – that the rules to which expressions such as “mental state” and “unconscious” are subject be changed. I believe that Wittgenstein’s point is quite absurd. For reasons that I am now in the process of explicating, the question whether Freud’s theories are right is a strictly empirical one, and is not a question of preferring one mode of speech to another. [230] See Searle (1992). Searle adopts a dispositionalist view of many cognitive abilities. Searle also rejects functionalism. But dispositionalism is a form of functionalism. So,...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-399",
    "text": "[233] Fodor and Pylyshin (1988) argue that CTM is preferable to a doctrine known as “connectionism” on the grounds that connectionism is harder to reconcile than CTM with the systematic character of thought. Whether connectionism is a correct or otherwise meritorious doctrine falls outside the scope of the present work. But given what we’ve said, it is clear that CTM doesn’t explain the systematic character of thought and that it therefore doesn’t explain it any better than connectionism. [234] Fodor and Pylyshin (1988) make this point. [235] Robert Brandom (1998) makes and ably defends this point. [236] Writes Fodor (1975: 39-40): “[S]o far as anyone can tell, simplicity metrics must be sensitive to the form of the hypotheses that they apply to, i.e. to their syntax and vocabulary. That is, so far as anyone can tell, we get an a priori ordering of hypotheses [a simplicity metric] only if we take account of the way in which the hypotheses are expressed. We need such an ordering if we are to provide a coherent account of the order in which values of P are selected in the concepto-learning [and induction-forming] situation. But this means that a theory of concepto-learning [and induction-formation] will have to be sensitive to the way that the organism represents its hypotheses. But the notion of the organism representing its hypotheses in one way or another (e.g. in one or another vocabulary or syntax) just is the notion of the organism possessing a representational system.”",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-400",
    "text": "[237] In Kuczynski (2007b). [238] In the argument being considered, Fodor seems to be alluding to Carnap’s (1950) efforts to formalize induction. It is worth noting that Carnap’s system, along with all other efforts to formalize induction, have radically counter-intuitive results. (See (Pap 1962: Chapters 11-13) for a discussion of this.) 666 For this reason, it is no longer widely held that induction can be formalized. It should be pointed out that, given only that induction cannot be formalized, it doesn’t follow that there is no analytic, non-trivial characterization of inductive rationality. Let L be any language that is capable of expressing all inductively reasonable inferences. To say any that induction cannot be formalized is to deny that, for any sentence S of L that expresses an inductively reasonable inference, it is a theorem of L’s semantic rules that S has that property. But we know that the category of formal truth is a small sub-category of the category of analytic (i.e. strictly conceptual, non-empirical) truth. This is to be expected, given that the concept of formal truth must be understood in terms of concepts (such as theorem and consequence) that are themselves to be understood in terms of the concept of analytic truth. So given only that induction cannot be formalized, it doesn’t follow that induction defies rational analysis any more than mathematics. [239] See Dennett (1978: Chapter 6), Lycan (1984: 237), Kuczynski (2002, 2005), Searle (1984, 1992).",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-401",
    "text": "[240] Putnam (1996) later changed his position on this. As we’ve seen, Burge (1979, 1982) and others have argued that extensions of Putnam’s arguments for semantic externalism could establish the truth of content externalism. Putnam came to regard these arguments as cogent, and thus came to be a content-externalist: he came to hold that Bob and Twin-Bob are having different thoughts. As we’ve seen, those arguments are not cogent; and, given a few basic distinctions, content-externalism loses any plausibility that it might otherwise have had. [241] Some linguists – so-called “discourse-theorists” – think that languages are just patterns of behavior and thought. For the reasons just outlined, I believe this to be false. But given only that discourse-theory is (so I believe) false, and that there are such things as semantic rules, it doesn’t follow that semantic rules are platonic entities. [242] A similar argument is found in Strawson (1969). [243] See Salmon (2005) for a similar argument.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-402",
    "text": "[245] See, for example, Kaplan (1989: 494), R. Moore (1995: 100-115). This view is found in Russell (1904: Chapter V). [246] There is an obvious challenge to the idea that propositions must have structures similar to the sentences that express them. “Caesar killed Brutus” and “Brutus was killed by Caesar” presumably express the same proposition; but those sentences differ structurally. Also, the syntax of the Albanian translation of “Caesar killed Brutus” is (for all I know) syntactically different from its English counterpart. This challenge is not hard to deal with. “Caesar killed Brutus” and “Brutus was killed by Caesar” have different derivation-trees. This shows that the way in which Caesar is assigned to the constituency of what is meant by the one sentence differs from the way in which it is the constituency of what is meant by the other sentence. But it doesn’t show that those constituencies themselves differ, either in respect of their membership or their internal organization. It may be true that the syntax of Albanian translation of “Caesar killed Brutus” is different from its English counterpart. But the discoveries of depth-grammarians show that these differences are more apparent than actual – that they hold only if the term “syntax” is taken in a folk-grammatical and pre-scientific sense. In Russian, the present tense of the verb “to be” is seldom used. One doesn’t say “I am thirsty”, but merely “I thirsty.” On this basis, one might conclude that the proposition meant by “I am thirsty” cannot resemble the English sentence that expresses it, given that the corresponding Russian sentence has a different structure (though, admittedly, not a very different structure). Chomskyan linguistics has made a strong case that Russian sentence does contain an occurrence of the verb “to be”, i.e. the equivalent of “am”, but that it contains it “aphonically” (i.e. it isn’t realized at the level of acoustics of orthographics). If this is right, then there is no reason to believe that “I am thirsty” is syntactically different from its Russian translation, given only that the latter does not overtly contain an expression corresponding to “am.” But even if the argument just given turns out to be fallacious, it is undeniable that sentences have a certain non-trivial similarity with the propositions they express. Leaving aside the grammatical differences between languages, and between different sentences within a language that express the same proposition, it is clear that...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-403",
    "text": "[248] I used to find this argument of McDowell’s compelling. For this reason, in Kuczynski (2003), I advocated the view that all content was propositional in nature. [249] The argument given in this paragraph and the next is clearly stated in an unpublished dissertation by Michael Rescorla (Rescorla, 2003). In 1995, I provided the same argument in a paper on Wittgenstein’s “picture-theory” of meaning. As I later discovered, that argument is found in much of the literature on the Tractatus. [250] Again, this point is made very clearly in Rescorla (2003), and also in much of the literature on the Tractatus. In his work in dreams, Freud often makes a similar point. See, for example, Freud (1965: 24). [251] Here we must head off an objection to the line of thought just presented:",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-404",
    "text": "Your analysis confuses the concept of an instance with that of a sub-category. R2 is not an instance of the concept of redness. Rather, it is a sub-category of that property. Let r2 be the specific instance of redness associated with the rose. r2 is not, whereas R2 is, something of which there can be instances. r2 is an instance both of R2 and of redness. Redness is a property not of R2, but of r2. R2 is a sub-category of the category (or property) of redness, not an instance of it. And contrary to what you say, and to what is patently obvious, r2 does instantiate redness no less than instantiates R2. So redness is not a property of properties. It is just a property. A property is something of which there could multiple instances. It is a “way that things are”, to use David Armstrong’s (1989) expression. In any case, it is a way that things could be. (There are some subtle – and, in this context, irrelevant -- qualifications to this platitude, relating to the supposed existence of properties that cannot possibly be had and that, consequently, cannot correspond to ways that things might be. An example would be the property picked out by the predicate “round square.” That predicate, I propose, is best thought of as expressing a concept that fails to pick out a property. So rather than saying that “round square” picks out a property that nothing could have, we should say that, although its grammatical function is to pick out a property, it fails to do so – just as we say that “the rational square root of two” fails to pick anything out, even though its grammatical function is to do so.) So far as any spatiotemporal thing X is red, it is because X has R1 or R2 or…There is thus a clear-cut sense in which R1 is a way that spatiotemporal things can be. But there is only a circuitous sense in which redness is a way that such things can be. At the same time, there is a non-circuitous sense in which “red” describes a way that a property could be. There is, no doubt, some property R that each of R1…Rn has and that specific shades of blue or specific temperatures do not have. (When I say “specific shades of blue or specific temperatures”, I am referring to...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-405",
    "text": "[261] Of course, a person could know what is meant by “Jones punched Smith” without knowing what is meant by “Smith punched Jones.” An example of such a person would be someone who doesn’t speak English but has been told what “Smith punched Jones” means. But, as we discussed in Chapter 13, such a person doesn’t really understand that sentence. [262] As we saw, all expressions – even “Socrates” and “Plato” – are to be defined contextually. To say that “Socrates” refers to x is to say that expressions of the form ┌Socrates has phi ┐ are true iff x has phi. To point to an object x and say “that is Socrates” is to say, implicitly, that an utterance of the form ┌Socrates has phi┐ is true iff x has phi. So denotative definition collapses into contextual definition. [263] The essential idea behind PWS – a sentence’s content is the class of worlds where it is true – is found in C. Lewis and Carnap. Lewis writes (1946: 56).: “[W]e might say that the intension of a proposition comprises whatever must be true of any possible world in order that this proposition should be true of or apply to it.” And Carnap (1956) writes: “Hence it seems plausible to define the content of a sentence as the class of possible cases in which it does not hold…” Ultimately, the conceit behind PWS goes back to Wittgenstein (1922). [264] In Kuczynski (2006), I try to give a relatively complete account of what the problems are with PWS, and also how PWS could try to circumvent them. [265] This is only the beginning of a statement as to what is wrong with PWS. In Kuczynski (2006), I provide a more detailed assessment of PWS. But for our purposes, the remarks made in the preceding paragraph ought to be enough to show that, in this context, PWS does not provide a viable answer to the question “what is a proposition?” I leave it open whether there are contexts – e.g. contexts of a purely logical or mathematical kind – where PWS is adequate. [266] In this context, we will, for brevity’s sake, ignore the distinctions between properties and hyper-properties and hyper-hyper-properties…and will simply use the term “property.” Also, in this context, we will speak rather naively about the nature of property instantiation and of propertyhood. We will, in our exposition, not always...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-406",
    "text": "[267] Here it would be more convenient if we were writing in a richly inflected language, such as Russian or Latin. It would then be clearer how grammar unifies expressions into more complex expressions. In English, there is quite as much grammar as there is in Russian. But English-grammar is largely realized through word-order or, if Chomsky and other depth-grammarians are right, is without any acoustic (or orthographic) representation. So, where English sentences are concerned, its presence is less likely to be discerned than it would be if we were dealing with Russian sentences. [268] I mention intonation because where some languages are concerned, e.g. Mandarin, given two utterances that differ in intonation but are otherwise identical, one may be grammatical while the other is ungrammatical. Even in English, it is, at least arguably, ungrammatical not to end questions with a certain kind of intonation. So in some cases, intonation is a way of rendering grammatical an otherwise ungrammatical utterance. This is not always the case, of course. [269] Here is another illustration of Peacocke’s analysis. Let there be some concepto C satisfying the following condition. For any proposition P, if you believe P, then you are primitively compelled to disbelieve CP (read: “C of P”). Under those circumstances, C is the concepto of negation, and you grasp that concepto because you satisfy its possession-conditions. [270] See Peacocke (1989, 1992). [271] Given that the former is itself an experience, it would make little sense to say that it was itself, in its entirety, a conceptualization of experiences. Also, If we say that the former is a conceptualization of sorts, then we will only render the term “conceptualization” ambiguous. If we came up with a new pair of terms to mark the distinction that we just obliterated, then the very problems that we’ve been discussing would arise in connection with that pair. This shows that we are simply re-labeling conceptso, not analyzing them, by saying that my seeing Tom is a case of conceptualization. [272] Fodor (1990, 1998) argues that one’s grasp of a concept – e.g. the concept of justice or of redness or of sentience – is completely non-descriptive. In Fodor’s view, for me to have a concept of justice just is for some instance of justice to have a certain causal connection to my present neural state. Fodor’s view has the radically implausible consequence that an otherwise conceptless...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-407",
    "text": "[279] The same is true of sentences having other moods, e.g. optatives (“would that she were here!”) and exhortatives (“let’s go!”). But obvious adaptations of what we say about assertions, questions, and orders apply to sentences of these other moods, and we therefore needn’t discuss them explicitly. [280] Versions of this point are made by Tughendat (1970), Dummett (1973: 196-203) and also – as both of those authors point out – in Frege (1884). [281] See Tughendat (1970) and Dummett (1973: 196-202).",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-408",
    "text": "[283] See Chomsky (1980: 83) and Platts (1979: 89-90). Chomsky and Platts are making what at first appears to be a different point. They are not saying that Grice’s view is incompatible with the compositional nature of sentence-meaning. Rather, they are saying that Grice’s view is incompatible with the fact that sentences that have never been uttered already have a definite meaning, given that nobody has ever meant anything by such a sentence. But these two points are equivalent, or nearly so. Why do unuttered sentences already have fixed meanings? Because their constituents already have meanings, and there are recursive rules saying how those meanings fix the meanings of sentences in which they occur. Where there is no semantic complexity, there is no possibility of there being expressions that are never used but have fixed meanings. And where there is such complexity, such expressions can exist. So the point objection that Chomsky and Platts are making to Grice’s theory is equivalent with the objection that I am making to it. Blackburn (1984: 127-130) discusses this objection, and says that it is null and void. We are now going to consider Blackburn’s explanation as to why Grice’s theory is consistent with the compositional character of meaning. [284] This is Blackburn’s (1984: 129) position.",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  },
  {
    "id": "CATOM-409",
    "text": "[285] This example is borrowed from Blackburn (1984: 119). Blackburn (1984: Chapter 4) provides an illuminating discussion with of the problems relating to how mere verbal regularities could give rise to rules governing word-usage. [286] As a matter of historical fact, the English word “Socrates” did not come into existence as a result of people producing sounds of the form…socrates…with the intention of making statements about Socrates. English-speaker’s didn’t go around producing such noises until “Socrates” (or some other similar word) already referred to Socrates. That English word was borrowed from a word of another language (Medieval French, we may suppose). In its turn, that word was derived from a word of another language (Latin, we may suppose). And that word was derived from a word of yet another language (Ancient Greek, we may suppose). Obviously the Ancient Greek word for Socrates didn’t come about in a way that validates the hypothesis under consideration. Suppose that sukrat is the sound of the Ancient Greek word in question. It isn’t as though the Ancient Greeks first went around uttering noises of the form…sukrat…and their word for Socrates eventually arose out of those pre-linguistic noises. No sooner was Socrates given a name than that name already had the semantic and recursive properties associated with “Socrates” or any other well-formed expression of an already completely developed language. So the hypothesis in question obviously doesn’t apply to “Socrates” or, for exactly similar reasons, to any expression constitutive of any language that we know of. If that hypothesis applies to anything, it is to primordial events that pre-date recorded history. This underscores the fact that, if correct, Grice’s theory only identifies the historical precursors of semantic facts, and thus fails to analyze those facts themselves. It also shows how improbable it is that Grice’s theory is correct even as a hypothesis as to what those precursors are. [287] Strictly speaking, there is some proposition P such that my utterance is a success exactly if, in response to that utterance, you affirm either P or its negation. Suppose that you truthfully say either “Smith went to the store” or “Smith did not go to the store”, but that you were not prompted to do so by my utterance. Suppose, for example, that I foolishly ask somebody who is giving a speech on T.V. whether or not Smith to the store and that, by sheer coincidence, that...",
    "source": "Conceptual Atomism and the Computational Theory of Mind",
    "topic": "Philosophy of Mind/AI/CTM",
    "keywords": []
  }
]